{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Westminster Ground Truth Analysis\n",
    "\n",
    "This notebook demonstrates the complete workflow for creating orthomosaics from DJI drone imagery and evaluating their accuracy:\n",
    "\n",
    "1. **Data Loading**: Load images, GCPs, and DJI metadata\n",
    "2. **Feature Detection & Matching**: Detect and match features across images\n",
    "3. **Camera Pose Estimation**: Estimate initial camera poses\n",
    "4. **Bundle Adjustment**: Refine poses to minimize reprojection error\n",
    "5. **Orthomosaic Creation**: Generate orthomosaics with and without GCPs\n",
    "6. **Basemap Comparison**: Download basemaps and quantify absolute accuracy\n",
    "7. **Visualization**: Visualize matches, errors, and results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Install Dependencies\n",
    "\n",
    "First, install the required packages if they're not already installed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing packages from requirements.txt...\n",
      "✓ Packages installed from requirements.txt\n",
      "\n",
      "Setup complete!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Try to install from requirements.txt first\n",
    "requirements_file = Path(\"requirements.txt\")\n",
    "if requirements_file.exists():\n",
    "    print(\"Installing packages from requirements.txt...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"-r\", str(requirements_file)])\n",
    "    print(\"✓ Packages installed from requirements.txt\")\n",
    "else:\n",
    "    # Fallback: install packages individually\n",
    "    print(\"requirements.txt not found. Installing packages individually...\")\n",
    "    packages = [\n",
    "        \"numpy>=1.24.0\",\n",
    "        \"opencv-python>=4.8.0\",\n",
    "        \"scipy>=1.11.0\",\n",
    "        \"scikit-image>=0.21.0\",\n",
    "        \"rasterio>=1.3.0\",\n",
    "        \"pillow>=10.0.0\",\n",
    "        \"matplotlib>=3.7.0\",\n",
    "        \"pandas>=2.0.0\",\n",
    "        \"pyproj>=3.6.0\",\n",
    "        \"shapely>=2.0.0\",\n",
    "        \"requests>=2.31.0\",\n",
    "        \"tqdm>=4.66.0\",\n",
    "        \"exifread>=3.0.0\",\n",
    "        \"utm>=0.7.0\"\n",
    "    ]\n",
    "    for package in packages:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
    "    print(\"✓ All packages installed\")\n",
    "\n",
    "print(\"\\nSetup complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add package to path\n",
    "sys.path.insert(0, str(Path.cwd()))\n",
    "\n",
    "from westminster_ground_truth_analysis import (\n",
    "    GCPParser,\n",
    "    DJIMetadataParser,\n",
    "    OrthomosaicPipeline,\n",
    "    download_basemap,\n",
    "    compare_orthomosaic_to_basemap,\n",
    "    visualize_matches,\n",
    "    visualize_reprojection_errors,\n",
    "    visualize_camera_poses,\n",
    "    create_match_quality_report\n",
    ")\n",
    "\n",
    "# Set up paths\n",
    "data_dir = Path(\"/Users/mauriciohessflores/Documents/Code/Data/New Westminster Oct _25\")\n",
    "output_dir = Path(\"outputs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Setup complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Ground Control Points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 23 ground control points\n",
      "  GCP1: X=5450945.53, Y=506914.12, Z=77.45\n",
      "  GCP2: X=5450730.01, Y=506657.79, Z=79.22\n",
      "  GCP3: X=5450480.01, Y=506577.77, Z=59.40\n",
      "  GCP4: X=5450578.63, Y=506765.03, Z=65.59\n",
      "  GCP5: X=5450715.96, Y=506926.13, Z=63.10\n",
      "\n",
      "GCP Bounds: X=[5450109.82, 5450992.66], Y=[506577.77, 507315.01]\n"
     ]
    }
   ],
   "source": [
    "# Parse GCP file\n",
    "gcp_file = data_dir / \"25-3288-CONTROL-NAD83-UTM10N-EGM2008.csv\"\n",
    "gcp_parser = GCPParser(str(gcp_file))\n",
    "\n",
    "gcps = gcp_parser.get_gcps()\n",
    "print(f\"Loaded {len(gcps)} ground control points\")\n",
    "\n",
    "# Display first few GCPs\n",
    "for gcp in gcps[:5]:\n",
    "    print(f\"  {gcp.name}: X={gcp.x:.2f}, Y={gcp.y:.2f}, Z={gcp.z:.2f}\")\n",
    "\n",
    "# Get bounds\n",
    "min_x, min_y, max_x, max_y = gcp_parser.get_bounds()\n",
    "print(f\"\\nGCP Bounds: X=[{min_x:.2f}, {max_x:.2f}], Y=[{min_y:.2f}, {max_y:.2f}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Process First Dataset (DJI_202510060955_017_25-3288)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing timestamp file: /Users/mauriciohessflores/Documents/Code/Data/New Westminster Oct _25/DJI_202510060955_017_25-3288/DJI_202510060955_017_25-3288_Timestamp.MRK\n",
      "Parsing navigation file: /Users/mauriciohessflores/Documents/Code/Data/New Westminster Oct _25/DJI_202510060955_017_25-3288/DJI_202510060955_017_25-3288_PPKNAV.nav\n",
      "Processing dataset 1 (without GCPs)...\n",
      "============================================================\n",
      "Starting Orthomosaic Pipeline\n",
      "============================================================\n",
      "Found 543 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 543/543 [01:12<00:00,  7.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 543 images\n",
      "Loading features from cache: outputs/dataset1_no_gcp/cache/features.pkl\n",
      "Loaded features for 543 images\n",
      "Loading matches from cache: outputs/dataset1_no_gcp/cache/matches.pkl\n",
      "Loaded 100 matches\n",
      "Estimating initial camera poses...\n",
      "Initialized poses for 2 cameras\n",
      "Performing bundle adjustment...\n",
      "Bundle adjustment: 1905 3D points, 3810 observations, 2 cameras\n",
      "Initial mean reprojection error: 0.33 pixels\n",
      "Note: Using simplified bundle adjustment. For production, consider OpenSfM or COLMAP.\n",
      "\n",
      "Reprojection Errors:\n",
      "  Mean: 0.33 pixels\n",
      "  Median: 0.06 pixels\n",
      "  Max: 382.70 pixels\n",
      "Creating orthomosaic (resolution: 0.1m/pixel)...\n",
      "Orthomosaic size: 1000x1004 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projecting images: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 543/543 [00:01<00:00, 478.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orthomosaic saved to outputs/dataset1_no_gcp/dataset1_no_gcp.tif\n",
      "============================================================\n",
      "Pipeline Complete\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup for first dataset\n",
    "dataset1_dir = data_dir / \"DJI_202510060955_017_25-3288\"\n",
    "\n",
    "# Try to parse DJI metadata\n",
    "dji_metadata1 = DJIMetadataParser(str(dataset1_dir))\n",
    "\n",
    "# Create pipeline without GCPs first\n",
    "pipeline1_no_gcp = OrthomosaicPipeline(\n",
    "    image_dir=str(dataset1_dir),\n",
    "    output_dir=str(output_dir / \"dataset1_no_gcp\"),\n",
    "    feature_detector=\"sift\",\n",
    "    max_features=5000,\n",
    "    match_ratio=0.7,\n",
    "    use_gcps=False,\n",
    "    dji_metadata=dji_metadata1\n",
    ")\n",
    "\n",
    "print(\"Processing dataset 1 (without GCPs)...\")\n",
    "output1_no_gcp = pipeline1_no_gcp.run_full_pipeline(output_name=\"dataset1_no_gcp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset 1 (with GCPs)...\n",
      "============================================================\n",
      "Starting Orthomosaic Pipeline\n",
      "============================================================\n",
      "Found 543 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 543/543 [01:14<00:00,  7.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 543 images\n",
      "Loading features from cache: outputs/dataset1_with_gcp/cache/features.pkl\n",
      "Loaded features for 543 images\n",
      "Loading matches from cache: outputs/dataset1_with_gcp/cache/matches.pkl\n",
      "Loaded 100 matches\n",
      "Estimating initial camera poses...\n",
      "Initialized poses for 2 cameras\n",
      "Performing bundle adjustment...\n",
      "Bundle adjustment: 1905 3D points, 3810 observations, 2 cameras\n",
      "Initial mean reprojection error: 0.33 pixels\n",
      "Note: Using simplified bundle adjustment. For production, consider OpenSfM or COLMAP.\n",
      "\n",
      "Reprojection Errors:\n",
      "  Mean: 0.33 pixels\n",
      "  Median: 0.06 pixels\n",
      "  Max: 382.70 pixels\n",
      "Creating orthomosaic (resolution: 0.1m/pixel)...\n",
      "Orthomosaic size: 1000x1004 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projecting images: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 543/543 [00:01<00:00, 479.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orthomosaic saved to outputs/dataset1_with_gcp/dataset1_with_gcp.tif\n",
      "============================================================\n",
      "Pipeline Complete\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create pipeline with GCPs\n",
    "pipeline1_with_gcp = OrthomosaicPipeline(\n",
    "    image_dir=str(dataset1_dir),\n",
    "    output_dir=str(output_dir / \"dataset1_with_gcp\"),\n",
    "    feature_detector=\"sift\",\n",
    "    max_features=5000,\n",
    "    match_ratio=0.7,\n",
    "    use_gcps=True,\n",
    "    gcp_parser=gcp_parser,\n",
    "    dji_metadata=dji_metadata1\n",
    ")\n",
    "\n",
    "print(\"Processing dataset 1 (with GCPs)...\")\n",
    "output1_with_gcp = pipeline1_with_gcp.run_full_pipeline(output_name=\"dataset1_with_gcp\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Results for Dataset 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match visualization saved to outputs/dataset1_match_example.png\n",
      "Reprojection error visualization saved to outputs/dataset1_reprojection_errors.png\n",
      "Camera pose visualization saved to outputs/dataset1_camera_poses.png\n",
      "Creating match quality report...\n",
      "Match visualization saved to outputs/dataset1_matches/match_visualization_1.png\n",
      "Match visualization saved to outputs/dataset1_matches/match_visualization_2.png\n",
      "Match visualization saved to outputs/dataset1_matches/match_visualization_3.png\n",
      "Match visualization saved to outputs/dataset1_matches/match_visualization_4.png\n",
      "Match visualization saved to outputs/dataset1_matches/match_visualization_5.png\n",
      "Match visualization saved to outputs/dataset1_matches/match_visualization_worst_96.png\n",
      "Match visualization saved to outputs/dataset1_matches/match_visualization_worst_97.png\n",
      "Match visualization saved to outputs/dataset1_matches/match_visualization_worst_98.png\n",
      "Match visualization saved to outputs/dataset1_matches/match_visualization_worst_99.png\n",
      "Match visualization saved to outputs/dataset1_matches/match_visualization_worst_100.png\n",
      "Match quality report saved to outputs/dataset1_matches\n"
     ]
    }
   ],
   "source": [
    "# Visualize feature matches\n",
    "if len(pipeline1_no_gcp.matches) > 0:\n",
    "    visualize_matches(\n",
    "        pipeline1_no_gcp,\n",
    "        match_idx=0,\n",
    "        output_path=str(output_dir / \"dataset1_match_example.png\"),\n",
    "        max_matches=100\n",
    "    )\n",
    "\n",
    "# Visualize reprojection errors\n",
    "visualize_reprojection_errors(\n",
    "    pipeline1_no_gcp,\n",
    "    output_path=str(output_dir / \"dataset1_reprojection_errors.png\")\n",
    ")\n",
    "\n",
    "# Visualize camera poses\n",
    "visualize_camera_poses(\n",
    "    pipeline1_no_gcp,\n",
    "    output_path=str(output_dir / \"dataset1_camera_poses.png\")\n",
    ")\n",
    "\n",
    "# Create match quality report\n",
    "create_match_quality_report(\n",
    "    pipeline1_no_gcp,\n",
    "    output_dir=str(output_dir / \"dataset1_matches\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Process Second Dataset (DJI_202510060955_019_25-3288)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing timestamp file: /Users/mauriciohessflores/Documents/Code/Data/New Westminster Oct _25/DJI_202510060955_019_25-3288/DJI_202510060955_019_Timestamp.MRK\n",
      "Parsing navigation file: /Users/mauriciohessflores/Documents/Code/Data/New Westminster Oct _25/DJI_202510060955_019_25-3288/DJI_202510060955_019_PPKNAV.nav\n",
      "Processing dataset 2 (without GCPs)...\n",
      "============================================================\n",
      "Starting Orthomosaic Pipeline\n",
      "============================================================\n",
      "Found 528 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 528/528 [01:08<00:00,  7.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 528 images\n",
      "Loading features from cache: outputs/dataset2_no_gcp/cache/features.pkl\n",
      "Loaded features for 528 images\n",
      "Loading matches from cache: outputs/dataset2_no_gcp/cache/matches.pkl\n",
      "Loaded 100 matches\n",
      "Estimating initial camera poses...\n",
      "Initialized poses for 2 cameras\n",
      "Performing bundle adjustment...\n",
      "Bundle adjustment: 10 3D points, 20 observations, 2 cameras\n",
      "Initial mean reprojection error: 894.77 pixels\n",
      "Note: Using simplified bundle adjustment. For production, consider OpenSfM or COLMAP.\n",
      "\n",
      "Reprojection Errors:\n",
      "  Mean: 894.77 pixels\n",
      "  Median: 0.00 pixels\n",
      "  Max: 8186.22 pixels\n",
      "Creating orthomosaic (resolution: 0.1m/pixel)...\n",
      "Orthomosaic size: 1000x1000 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projecting images: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 528/528 [00:01<00:00, 436.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orthomosaic saved to outputs/dataset2_no_gcp/dataset2_no_gcp.tif\n",
      "============================================================\n",
      "Pipeline Complete\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup for second dataset\n",
    "dataset2_dir = data_dir / \"DJI_202510060955_019_25-3288\"\n",
    "\n",
    "# Try to parse DJI metadata\n",
    "dji_metadata2 = DJIMetadataParser(str(dataset2_dir))\n",
    "\n",
    "# Create pipeline without GCPs\n",
    "pipeline2_no_gcp = OrthomosaicPipeline(\n",
    "    image_dir=str(dataset2_dir),\n",
    "    output_dir=str(output_dir / \"dataset2_no_gcp\"),\n",
    "    feature_detector=\"sift\",\n",
    "    max_features=5000,\n",
    "    match_ratio=0.7,\n",
    "    use_gcps=False,\n",
    "    dji_metadata=dji_metadata2\n",
    ")\n",
    "\n",
    "print(\"Processing dataset 2 (without GCPs)...\")\n",
    "output2_no_gcp = pipeline2_no_gcp.run_full_pipeline(output_name=\"dataset2_no_gcp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset 2 (with GCPs)...\n",
      "============================================================\n",
      "Starting Orthomosaic Pipeline\n",
      "============================================================\n",
      "Found 528 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 528/528 [01:08<00:00,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 528 images\n",
      "Loading features from cache: outputs/dataset2_with_gcp/cache/features.pkl\n",
      "Loaded features for 528 images\n",
      "Loading matches from cache: outputs/dataset2_with_gcp/cache/matches.pkl\n",
      "Loaded 100 matches\n",
      "Estimating initial camera poses...\n",
      "Initialized poses for 2 cameras\n",
      "Performing bundle adjustment...\n",
      "Bundle adjustment: 10 3D points, 20 observations, 2 cameras\n",
      "Initial mean reprojection error: 894.77 pixels\n",
      "Note: Using simplified bundle adjustment. For production, consider OpenSfM or COLMAP.\n",
      "\n",
      "Reprojection Errors:\n",
      "  Mean: 894.77 pixels\n",
      "  Median: 0.00 pixels\n",
      "  Max: 8186.22 pixels\n",
      "Creating orthomosaic (resolution: 0.1m/pixel)...\n",
      "Orthomosaic size: 1000x1000 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projecting images: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 528/528 [00:01<00:00, 467.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orthomosaic saved to outputs/dataset2_with_gcp/dataset2_with_gcp.tif\n",
      "============================================================\n",
      "Pipeline Complete\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create pipeline with GCPs\n",
    "pipeline2_with_gcp = OrthomosaicPipeline(\n",
    "    image_dir=str(dataset2_dir),\n",
    "    output_dir=str(output_dir / \"dataset2_with_gcp\"),\n",
    "    feature_detector=\"sift\",\n",
    "    max_features=5000,\n",
    "    match_ratio=0.7,\n",
    "    use_gcps=True,\n",
    "    gcp_parser=gcp_parser,\n",
    "    dji_metadata=dji_metadata2\n",
    ")\n",
    "\n",
    "print(\"Processing dataset 2 (with GCPs)...\")\n",
    "output2_with_gcp = pipeline2_with_gcp.run_full_pipeline(output_name=\"dataset2_with_gcp\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Download Basemap for Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default data_dir: /Users/mauriciohessflores/Documents/Code/Data/New Westminster Oct _25\n",
      "Created GCP parser from /Users/mauriciohessflores/Documents/Code/Data/New Westminster Oct _25/25-3288-CONTROL-NAD83-UTM10N-EGM2008.csv\n",
      "Retrieved GCP bounds: X=[5450109.82, 5450992.66], Y=[506577.77, 507315.01]\n",
      "Basemap bounding box: (np.float64(49.20374809577927), np.float64(-122.90970020449743), np.float64(49.21168116673544), np.float64(-122.89956337139125))\n",
      "Using default output_dir: outputs\n",
      "Downloading basemap at zoom level 18...\n",
      "Tile range: X [41571, 41579], Y [89790, 89799]\n",
      "Downloading tiles: 9 columns x 10 rows\n",
      "Basemap saved to outputs/basemap.tif\n"
     ]
    }
   ],
   "source": [
    "# Convert UTM bounds to lat/lon for basemap download\n",
    "import utm\n",
    "from pathlib import Path\n",
    "\n",
    "# Import required modules if not already imported\n",
    "try:\n",
    "    _ = GCPParser\n",
    "    _ = download_basemap\n",
    "except NameError:\n",
    "    import sys\n",
    "    sys.path.insert(0, str(Path.cwd()))\n",
    "    from westminster_ground_truth_analysis import GCPParser, download_basemap\n",
    "\n",
    "# Get GCP bounds if not already defined\n",
    "try:\n",
    "    # Check if bounds are already defined\n",
    "    _ = min_x, min_y, max_x, max_y\n",
    "    print(\"Using existing GCP bounds\")\n",
    "except NameError:\n",
    "    # Get bounds from GCP parser (create parser if needed)\n",
    "    try:\n",
    "        _ = gcp_parser\n",
    "    except NameError:\n",
    "        # Create GCP parser if it doesn't exist\n",
    "        # Check if data_dir is defined, if not use default path\n",
    "        try:\n",
    "            _ = data_dir\n",
    "        except NameError:\n",
    "            data_dir = Path(\"/Users/mauriciohessflores/Documents/Code/Data/New Westminster Oct _25\")\n",
    "            print(f\"Using default data_dir: {data_dir}\")\n",
    "        \n",
    "        gcp_file = data_dir / \"25-3288-CONTROL-NAD83-UTM10N-EGM2008.csv\"\n",
    "        gcp_parser = GCPParser(str(gcp_file))\n",
    "        print(f\"Created GCP parser from {gcp_file}\")\n",
    "    \n",
    "    # Get bounds from GCP parser\n",
    "    min_x, min_y, max_x, max_y = gcp_parser.get_bounds()\n",
    "    print(f\"Retrieved GCP bounds: X=[{min_x:.2f}, {max_x:.2f}], Y=[{min_y:.2f}, {max_y:.2f}]\")\n",
    "\n",
    "# Convert GCP bounds from UTM to lat/lon\n",
    "# UTM Zone 10N (based on GCP file name)\n",
    "# NOTE: In the CSV, X column is actually Northing (~5.45M) and Y column is Easting (~500k)\n",
    "# utm.to_latlon expects (easting, northing), so we need to swap them\n",
    "center_easting = (min_y + max_y) / 2  # Y column is easting\n",
    "center_northing = (min_x + max_x) / 2  # X column is northing\n",
    "\n",
    "# Convert center point\n",
    "lat_center, lon_center = utm.to_latlon(center_easting, center_northing, 10, 'N')\n",
    "\n",
    "# Approximate bounds in lat/lon (rough conversion)\n",
    "# For more accuracy, convert all corners\n",
    "# Swap X and Y: Y is easting, X is northing\n",
    "lat_min, lon_min = utm.to_latlon(min_y, min_x, 10, 'N')\n",
    "lat_max, lon_max = utm.to_latlon(max_y, max_x, 10, 'N')\n",
    "\n",
    "bbox = (min(lat_min, lat_max), min(lon_min, lon_max), \n",
    "        max(lat_min, lat_max), max(lon_min, lon_max))\n",
    "\n",
    "print(f\"Basemap bounding box: {bbox}\")\n",
    "\n",
    "# Check if output_dir is defined, if not use default\n",
    "try:\n",
    "    _ = output_dir\n",
    "except NameError:\n",
    "    output_dir = Path(\"outputs\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    print(f\"Using default output_dir: {output_dir}\")\n",
    "\n",
    "# Download basemap\n",
    "basemap_path = download_basemap(\n",
    "    bbox=bbox,\n",
    "    output_path=str(output_dir / \"basemap.tif\"),\n",
    "    source=\"esri_world_imagery\",\n",
    "    target_resolution=0.1  # 0.1m per pixel\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare Orthomosaics to Basemap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found orthomosaic: outputs/dataset1_no_gcp/dataset1_no_gcp.tif\n",
      "============================================================\n",
      "Dataset 1 - Without GCPs\n",
      "============================================================\n",
      "Comparing orthomosaic to basemap...\n",
      "Using feature matching approach for 2D displacement calculation...\n",
      "Computing 2D displacement via feature matching...\n",
      "Resized basemap to 1669x2000 for matching\n",
      "Detecting features in orthomosaic and basemap...\n",
      "  Found 0 features in orthomosaic, 5000 features in basemap\n",
      "  Warning: Insufficient features (need at least 10 in each image)\n",
      "Warning: Insufficient features for matching\n",
      "Feature matching could not find enough correspondences between orthomosaic and basemap.\n",
      "\n",
      "============================================================\n",
      "Dataset 1 - With GCPs\n",
      "============================================================\n",
      "Comparing orthomosaic to basemap...\n",
      "Using feature matching approach for 2D displacement calculation...\n",
      "Computing 2D displacement via feature matching...\n",
      "Resized basemap to 1669x2000 for matching\n",
      "Detecting features in orthomosaic and basemap...\n",
      "  Found 0 features in orthomosaic, 5000 features in basemap\n",
      "  Warning: Insufficient features (need at least 10 in each image)\n",
      "Warning: Insufficient features for matching\n",
      "Feature matching could not find enough correspondences between orthomosaic and basemap.\n"
     ]
    }
   ],
   "source": [
    "# Import compare_orthomosaic_to_basemap if not already imported\n",
    "try:\n",
    "    _ = compare_orthomosaic_to_basemap\n",
    "except NameError:\n",
    "    import sys\n",
    "    from pathlib import Path\n",
    "    sys.path.insert(0, str(Path.cwd()))\n",
    "    from westminster_ground_truth_analysis import compare_orthomosaic_to_basemap\n",
    "\n",
    "# Check if output variables are defined, if not try to find output files\n",
    "try:\n",
    "    _ = output1_no_gcp\n",
    "except NameError:\n",
    "    # Try to find the output file\n",
    "    try:\n",
    "        _ = output_dir\n",
    "    except NameError:\n",
    "        output_dir = Path(\"outputs\")\n",
    "    \n",
    "    output1_no_gcp = output_dir / \"dataset1_no_gcp\" / \"dataset1_no_gcp.tif\"\n",
    "    if not output1_no_gcp.exists():\n",
    "        raise FileNotFoundError(f\"Orthomosaic file not found: {output1_no_gcp}. Please run the pipeline first.\")\n",
    "    print(f\"Found orthomosaic: {output1_no_gcp}\")\n",
    "\n",
    "try:\n",
    "    _ = output1_with_gcp\n",
    "except NameError:\n",
    "    output1_with_gcp = output_dir / \"dataset1_with_gcp\" / \"dataset1_with_gcp.tif\"\n",
    "    if not output1_with_gcp.exists():\n",
    "        print(f\"Warning: Orthomosaic with GCPs not found: {output1_with_gcp}\")\n",
    "\n",
    "try:\n",
    "    _ = basemap_path\n",
    "except NameError:\n",
    "    basemap_path = output_dir / \"basemap.tif\"\n",
    "    if not basemap_path.exists():\n",
    "        raise FileNotFoundError(f\"Basemap file not found: {basemap_path}. Please download basemap first.\")\n",
    "\n",
    "# Compare dataset 1 without GCPs\n",
    "print(\"=\" * 60)\n",
    "print(\"Dataset 1 - Without GCPs\")\n",
    "print(\"=\" * 60)\n",
    "metrics1_no_gcp = compare_orthomosaic_to_basemap(\n",
    "    str(output1_no_gcp),\n",
    "    str(basemap_path),\n",
    "    output_dir=str(output_dir / \"comparison1_no_gcp\")\n",
    ")\n",
    "\n",
    "# Compare dataset 1 with GCPs\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Dataset 1 - With GCPs\")\n",
    "print(\"=\" * 60)\n",
    "metrics1_with_gcp = compare_orthomosaic_to_basemap(\n",
    "    str(output1_with_gcp),\n",
    "    str(basemap_path),\n",
    "    output_dir=str(output_dir / \"comparison1_with_gcp\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Dataset 2 - Without GCPs\n",
      "============================================================\n",
      "Comparing orthomosaic to basemap...\n",
      "Using feature matching approach for 2D displacement calculation...\n",
      "Computing 2D displacement via feature matching...\n",
      "Resized basemap to 1669x2000 for matching\n",
      "Detecting features in orthomosaic and basemap...\n",
      "  Found 0 features in orthomosaic, 5000 features in basemap\n",
      "  Warning: Insufficient features (need at least 10 in each image)\n",
      "Warning: Insufficient features for matching\n",
      "Feature matching could not find enough correspondences between orthomosaic and basemap.\n",
      "\n",
      "============================================================\n",
      "Dataset 2 - With GCPs\n",
      "============================================================\n",
      "Comparing orthomosaic to basemap...\n",
      "Using feature matching approach for 2D displacement calculation...\n",
      "Computing 2D displacement via feature matching...\n",
      "Resized basemap to 1669x2000 for matching\n",
      "Detecting features in orthomosaic and basemap...\n",
      "  Found 0 features in orthomosaic, 5000 features in basemap\n",
      "  Warning: Insufficient features (need at least 10 in each image)\n",
      "Warning: Insufficient features for matching\n",
      "Feature matching could not find enough correspondences between orthomosaic and basemap.\n"
     ]
    }
   ],
   "source": [
    "# Check if dataset 2 output variables are defined\n",
    "try:\n",
    "    _ = output2_no_gcp\n",
    "except NameError:\n",
    "    output2_no_gcp = output_dir / \"dataset2_no_gcp\" / \"dataset2_no_gcp.tif\"\n",
    "    if not output2_no_gcp.exists():\n",
    "        print(f\"Warning: Dataset 2 orthomosaic without GCPs not found: {output2_no_gcp}\")\n",
    "\n",
    "try:\n",
    "    _ = output2_with_gcp\n",
    "except NameError:\n",
    "    output2_with_gcp = output_dir / \"dataset2_with_gcp\" / \"dataset2_with_gcp.tif\"\n",
    "    if not output2_with_gcp.exists():\n",
    "        print(f\"Warning: Dataset 2 orthomosaic with GCPs not found: {output2_with_gcp}\")\n",
    "\n",
    "# Compare dataset 2 without GCPs (only if file exists)\n",
    "if output2_no_gcp.exists():\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Dataset 2 - Without GCPs\")\n",
    "    print(\"=\" * 60)\n",
    "    metrics2_no_gcp = compare_orthomosaic_to_basemap(\n",
    "        str(output2_no_gcp),\n",
    "        str(basemap_path),\n",
    "        output_dir=str(output_dir / \"comparison2_no_gcp\")\n",
    "    )\n",
    "else:\n",
    "    print(\"Skipping Dataset 2 - Without GCPs (file not found)\")\n",
    "\n",
    "# Compare dataset 2 with GCPs (only if file exists)\n",
    "if output2_with_gcp.exists():\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Dataset 2 - With GCPs\")\n",
    "    print(\"=\" * 60)\n",
    "    metrics2_with_gcp = compare_orthomosaic_to_basemap(\n",
    "        str(output2_with_gcp),\n",
    "        str(basemap_path),\n",
    "        output_dir=str(output_dir / \"comparison2_with_gcp\")\n",
    "    )\n",
    "else:\n",
    "    print(\"Skipping Dataset 2 - With GCPs (file not found)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SUMMARY COMPARISON\n",
      "============================================================\n",
      "  Dataset GCPs Used  RMSE  MAE  Correlation  SSIM  Displacement (pixels)  Num Matches\n",
      "Dataset 1        No   0.0  0.0          0.0   0.0                    0.0            0\n",
      "Dataset 1       Yes   0.0  0.0          0.0   0.0                    0.0            0\n",
      "Dataset 2        No   0.0  0.0          0.0   0.0                    0.0            0\n",
      "Dataset 2       Yes   0.0  0.0          0.0   0.0                    0.0            0\n",
      "No metrics available for visualization\n",
      "\n",
      "============================================================\n",
      "Converting all .tif files to PNG format...\n",
      "============================================================\n",
      "Found 6 .tif file(s) to convert\n",
      "  Converting basemap.tif...\n",
      "    Data type: uint8, Shape: (3, 2263, 1889), Range: [0.00, 255.00]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/45/msyhv5rs7xb6v19f926jmt_h0000gp/T/ipykernel_97142/3337865715.py:204: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  img = Image.fromarray(img_data, mode='RGB')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ Saved to basemap.png\n",
      "  Converting dataset2_no_gcp/dataset2_no_gcp.tif...\n",
      "    Data type: uint8, Shape: (3, 1000, 1000), Range: [0.00, 107.00]\n",
      "    ✓ Saved to dataset2_no_gcp/dataset2_no_gcp.png\n",
      "  Converting dataset1_with_gcp/dataset1_with_gcp.tif...\n",
      "    Data type: uint8, Shape: (3, 1004, 1000), Range: [0.00, 0.00]\n",
      "    ✓ Saved to dataset1_with_gcp/dataset1_with_gcp.png\n",
      "  Converting dataset2_with_gcp/dataset2_with_gcp.tif...\n",
      "    Data type: uint8, Shape: (3, 1000, 1000), Range: [0.00, 107.00]\n",
      "    ✓ Saved to dataset2_with_gcp/dataset2_with_gcp.png\n",
      "  Converting dataset1_no_gcp/dataset1_no_gcp.tif...\n",
      "    Data type: uint8, Shape: (3, 1004, 1000), Range: [0.00, 0.00]\n",
      "    ✓ Saved to dataset1_no_gcp/dataset1_no_gcp.png\n",
      "  Skipping dataset1_no_gcp/.ipynb_checkpoints/dataset1_no_gcp-checkpoint.tif (checkpoint file)\n",
      "\n",
      "Conversion complete: 5 converted, 1 skipped\n"
     ]
    }
   ],
   "source": [
    "# Create comparison summary\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Helper function to extract metric value, handling both feature matching and pixel-based metrics\n",
    "def get_metric(metrics_dict, key, fallback_key=None):\n",
    "    \"\"\"Extract metric value, trying primary key first, then fallback.\"\"\"\n",
    "    if key in metrics_dict:\n",
    "        return metrics_dict[key]\n",
    "    if fallback_key and fallback_key in metrics_dict:\n",
    "        return metrics_dict[fallback_key]\n",
    "    # Check pixel_based sub-dict\n",
    "    if 'pixel_based' in metrics_dict and isinstance(metrics_dict['pixel_based'], dict):\n",
    "        if key in metrics_dict['pixel_based']:\n",
    "            return metrics_dict['pixel_based'][key]\n",
    "    return None\n",
    "\n",
    "# Check if metrics are defined, if not try to find them or create empty placeholders\n",
    "def get_metrics_or_none(var_name):\n",
    "    \"\"\"Try to get metrics variable, return None if not defined.\"\"\"\n",
    "    try:\n",
    "        return globals()[var_name]\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "# Collect all metrics (use None if not defined)\n",
    "metrics1_no_gcp = get_metrics_or_none('metrics1_no_gcp')\n",
    "metrics1_with_gcp = get_metrics_or_none('metrics1_with_gcp')\n",
    "metrics2_no_gcp = get_metrics_or_none('metrics2_no_gcp')\n",
    "metrics2_with_gcp = get_metrics_or_none('metrics2_with_gcp')\n",
    "\n",
    "all_metrics = [\n",
    "    metrics1_no_gcp,\n",
    "    metrics1_with_gcp,\n",
    "    metrics2_no_gcp,\n",
    "    metrics2_with_gcp\n",
    "]\n",
    "\n",
    "# Check if any metrics are available\n",
    "if all(m is None for m in all_metrics):\n",
    "    print(\"Warning: No metrics found. Please run the comparison cells first.\")\n",
    "    print(\"Creating empty summary with placeholder values.\")\n",
    "    # Create empty metrics dictionaries\n",
    "    empty_metrics = {\n",
    "        'displacement_x_pixels': 0.0,\n",
    "        'displacement_y_pixels': 0.0,\n",
    "        'displacement_magnitude_pixels': 0.0,\n",
    "        'num_matches': 0,\n",
    "        'rmse_pixels': 0.0,\n",
    "        'note': 'Metrics not available - run comparison cells first'\n",
    "    }\n",
    "    all_metrics = [empty_metrics] * 4\n",
    "    metrics1_no_gcp = metrics1_with_gcp = metrics2_no_gcp = metrics2_with_gcp = empty_metrics\n",
    "else:\n",
    "    # Replace None with empty dict\n",
    "    all_metrics = [m if m is not None else {} for m in all_metrics]\n",
    "\n",
    "# Build summary data, handling both metric types\n",
    "summary_data = {\n",
    "    'Dataset': ['Dataset 1', 'Dataset 1', 'Dataset 2', 'Dataset 2'],\n",
    "    'GCPs Used': ['No', 'Yes', 'No', 'Yes'],\n",
    "}\n",
    "\n",
    "# Try to get pixel-based metrics first, fallback to feature matching metrics\n",
    "summary_data['RMSE'] = [\n",
    "    get_metric(m, 'rmse', 'rmse_pixels') or 0.0\n",
    "    for m in all_metrics\n",
    "]\n",
    "\n",
    "summary_data['MAE'] = [\n",
    "    get_metric(m, 'mae') or 0.0\n",
    "    for m in all_metrics\n",
    "]\n",
    "\n",
    "summary_data['Correlation'] = [\n",
    "    get_metric(m, 'correlation') or 0.0\n",
    "    for m in all_metrics\n",
    "]\n",
    "\n",
    "summary_data['SSIM'] = [\n",
    "    get_metric(m, 'ssim') or 0.0\n",
    "    for m in all_metrics\n",
    "]\n",
    "\n",
    "# Add displacement metrics if available (from feature matching)\n",
    "if any('displacement_magnitude_pixels' in m for m in all_metrics):\n",
    "    summary_data['Displacement (pixels)'] = [\n",
    "        get_metric(m, 'displacement_magnitude_pixels') or 0.0\n",
    "        for m in all_metrics\n",
    "    ]\n",
    "    \n",
    "if any('displacement_magnitude_meters' in m and m.get('displacement_magnitude_meters') is not None for m in all_metrics):\n",
    "    summary_data['Displacement (meters)'] = [\n",
    "        get_metric(m, 'displacement_magnitude_meters') or 0.0\n",
    "        for m in all_metrics\n",
    "    ]\n",
    "\n",
    "# Add number of matches if available\n",
    "if any('num_matches' in m for m in all_metrics):\n",
    "    summary_data['Num Matches'] = [\n",
    "        get_metric(m, 'num_matches') or 0\n",
    "        for m in all_metrics\n",
    "    ]\n",
    "\n",
    "df = pd.DataFrame(summary_data)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SUMMARY COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# Visualize comparison\n",
    "# Determine which metrics are available and non-zero\n",
    "available_metrics = [col for col in df.columns if col not in ['Dataset', 'GCPs Used'] and df[col].sum() > 0]\n",
    "\n",
    "# Create subplots based on available metrics\n",
    "n_metrics = len(available_metrics)\n",
    "if n_metrics == 0:\n",
    "    print(\"No metrics available for visualization\")\n",
    "else:\n",
    "    n_cols = 2\n",
    "    n_rows = (n_metrics + n_cols - 1) // n_cols\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(14, 5 * n_rows))\n",
    "    if n_metrics == 1:\n",
    "        axes = [axes]\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "    \n",
    "    for idx, metric in enumerate(available_metrics):\n",
    "        ax = axes[idx]\n",
    "        x = np.arange(2)  # Two datasets\n",
    "        width = 0.35\n",
    "        \n",
    "        no_gcp_values = df[df['GCPs Used'] == 'No'][metric].values\n",
    "        with_gcp_values = df[df['GCPs Used'] == 'Yes'][metric].values\n",
    "        \n",
    "        # Only plot if we have values for both datasets\n",
    "        if len(no_gcp_values) >= 2 and len(with_gcp_values) >= 2:\n",
    "            ax.bar(x - width/2, no_gcp_values[:2], width, label='Without GCPs', alpha=0.7)\n",
    "            ax.bar(x + width/2, with_gcp_values[:2], width, label='With GCPs', alpha=0.7)\n",
    "            \n",
    "            ax.set_xlabel('Dataset')\n",
    "            ax.set_ylabel(metric)\n",
    "            ax.set_title(f'{metric} Comparison')\n",
    "            ax.set_xticks(x)\n",
    "            ax.set_xticklabels(['Dataset 1', 'Dataset 2'])\n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3, axis='y')\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, f'Insufficient data for {metric}', \n",
    "                   ha='center', va='center', transform=ax.transAxes)\n",
    "            ax.set_title(f'{metric} Comparison')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for idx in range(n_metrics, len(axes)):\n",
    "        axes[idx].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Check if output_dir is defined\n",
    "    try:\n",
    "        _ = output_dir\n",
    "    except NameError:\n",
    "        output_dir = Path(\"outputs\")\n",
    "        output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    plt.savefig(output_dir / \"accuracy_comparison.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nComparison visualization saved to {output_dir / 'accuracy_comparison.png'}\")\n",
    "\n",
    "# Convert all .tif files to PNG for easier browser viewing\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Diagnosing TIF files before conversion...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# First, diagnose the TIF files to see what's in them\n",
    "try:\n",
    "    _ = output_dir\n",
    "except NameError:\n",
    "    output_dir = Path(\"outputs\")\n",
    "\n",
    "import rasterio\n",
    "\n",
    "# Find all .tif files in output directories\n",
    "tif_files = list(output_dir.rglob(\"*.tif\")) + list(output_dir.rglob(\"*.TIF\"))\n",
    "\n",
    "# Filter out checkpoint files\n",
    "tif_files = [f for f in tif_files if '.ipynb_checkpoints' not in str(f)]\n",
    "\n",
    "if tif_files:\n",
    "    print(f\"Found {len(tif_files)} .tif file(s) to diagnose:\")\n",
    "    for tif_path in tif_files:\n",
    "        try:\n",
    "            with rasterio.open(tif_path) as src:\n",
    "                data = src.read()\n",
    "                print(f\"\\n  {tif_path.relative_to(output_dir)}:\")\n",
    "                print(f\"    Shape: {data.shape}\")\n",
    "                print(f\"    Dtype: {data.dtype}\")\n",
    "                print(f\"    Min: {data.min()}, Max: {data.max()}\")\n",
    "                print(f\"    Mean: {data.mean():.2f}, Std: {data.std():.2f}\")\n",
    "                \n",
    "                # Check if data is all zeros or very dark\n",
    "                if data.max() == 0:\n",
    "                    print(f\"    ⚠️  WARNING: All pixels are zero (black image)\")\n",
    "                elif data.max() < 10:\n",
    "                    print(f\"    ⚠️  WARNING: Very dark image (max value: {data.max()})\")\n",
    "                elif data.max() <= 1.0 and data.dtype in [np.float32, np.float64]:\n",
    "                    print(f\"    ⚠️  WARNING: Data appears to be normalized to [0,1] range\")\n",
    "                    print(f\"    Suggestion: Multiply by 255 for display\")\n",
    "                else:\n",
    "                    print(f\"    ✓ Data looks reasonable\")\n",
    "                    \n",
    "                # Check non-zero pixels\n",
    "                non_zero = np.count_nonzero(data)\n",
    "                total_pixels = data.size\n",
    "                print(f\"    Non-zero pixels: {non_zero}/{total_pixels} ({100*non_zero/total_pixels:.1f}%)\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error reading {tif_path.name}: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Converting all .tif files to PNG format...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    _ = output_dir\n",
    "except NameError:\n",
    "    output_dir = Path(\"outputs\")\n",
    "\n",
    "import rasterio\n",
    "from PIL import Image\n",
    "\n",
    "def convert_tif_to_png(tif_path: Path, png_path: Path, max_size: int = 4000):\n",
    "    \"\"\"Convert a GeoTIFF to PNG format, handling different band configurations.\"\"\"\n",
    "    try:\n",
    "        with rasterio.open(tif_path) as src:\n",
    "            # Read all bands\n",
    "            data = src.read()\n",
    "            \n",
    "            # Get data type info\n",
    "            dtype = data.dtype\n",
    "            data_min, data_max = data.min(), data.max()\n",
    "            print(f\"    Data type: {dtype}, Shape: {data.shape}, Range: [{data_min:.2f}, {data_max:.2f}]\")\n",
    "            \n",
    "            # If data is already uint8 and in valid range, use directly\n",
    "            img = None\n",
    "            if dtype == np.uint8 and data_max <= 255 and data_min >= 0:\n",
    "                # Data is already in correct format, just need to reshape\n",
    "                if len(data.shape) == 3 and data.shape[0] == 3:\n",
    "                    img_data = np.transpose(data, (1, 2, 0))\n",
    "                    img = Image.fromarray(img_data, mode='RGB')\n",
    "                elif len(data.shape) == 3 and data.shape[0] == 1:\n",
    "                    img = Image.fromarray(data[0], mode='L')\n",
    "                elif len(data.shape) == 2:\n",
    "                    img = Image.fromarray(data, mode='L')\n",
    "            \n",
    "            # Check if data is normalized to [0,1] range (common in some workflows)\n",
    "            elif dtype in [np.float32, np.float64] and data_max <= 1.0 and data_min >= 0.0:\n",
    "                print(f\"    Note: Data appears normalized to [0,1], scaling to [0,255]\")\n",
    "                # Scale to 0-255\n",
    "                if len(data.shape) == 3 and data.shape[0] == 3:\n",
    "                    img_data = (np.transpose(data, (1, 2, 0)) * 255).astype(np.uint8)\n",
    "                    img = Image.fromarray(img_data, mode='RGB')\n",
    "                elif len(data.shape) == 3 and data.shape[0] == 1:\n",
    "                    img = Image.fromarray((data[0] * 255).astype(np.uint8), mode='L')\n",
    "                elif len(data.shape) == 2:\n",
    "                    img = Image.fromarray((data * 255).astype(np.uint8), mode='L')\n",
    "            \n",
    "            # If we didn't create img from uint8 data, do normalization\n",
    "            if img is None:\n",
    "                # Convert to float for processing\n",
    "                if dtype != np.float32 and dtype != np.float64:\n",
    "                    data = data.astype(np.float32)\n",
    "                \n",
    "                # Handle different band configurations\n",
    "                if len(data.shape) == 2:\n",
    "                    # Single band - convert to grayscale\n",
    "                    img_data = data.copy()\n",
    "                    # Use percentile-based normalization to handle outliers\n",
    "                    p2, p98 = np.percentile(img_data[img_data > 0] if (img_data > 0).any() else img_data, [2, 98])\n",
    "                    if p98 > p2:\n",
    "                        img_data = np.clip((img_data - p2) / (p98 - p2) * 255, 0, 255).astype(np.uint8)\n",
    "                    else:\n",
    "                        img_data = np.clip(img_data, 0, 255).astype(np.uint8)\n",
    "                    img = Image.fromarray(img_data, mode='L')\n",
    "                elif len(data.shape) == 3:\n",
    "                    # Multi-band\n",
    "                    if data.shape[0] == 1:\n",
    "                        # Single band in 3D array\n",
    "                        img_data = data[0].copy()\n",
    "                        p2, p98 = np.percentile(img_data[img_data > 0] if (img_data > 0).any() else img_data, [2, 98])\n",
    "                        if p98 > p2:\n",
    "                            img_data = np.clip((img_data - p2) / (p98 - p2) * 255, 0, 255).astype(np.uint8)\n",
    "                        else:\n",
    "                            img_data = np.clip(img_data, 0, 255).astype(np.uint8)\n",
    "                        img = Image.fromarray(img_data, mode='L')\n",
    "                    elif data.shape[0] == 3:\n",
    "                        # RGB\n",
    "                        img_data = np.transpose(data, (1, 2, 0)).copy()\n",
    "                        # Normalize each band using percentiles\n",
    "                        for i in range(3):\n",
    "                            band = img_data[:, :, i]\n",
    "                            # Use percentile-based normalization\n",
    "                            p2, p98 = np.percentile(band[band > 0] if (band > 0).any() else band, [2, 98])\n",
    "                            if p98 > p2:\n",
    "                                img_data[:, :, i] = np.clip((band - p2) / (p98 - p2) * 255, 0, 255).astype(np.uint8)\n",
    "                            else:\n",
    "                                img_data[:, :, i] = np.clip(band, 0, 255).astype(np.uint8)\n",
    "                        img = Image.fromarray(img_data, mode='RGB')\n",
    "                    elif data.shape[0] == 4:\n",
    "                        # RGBA\n",
    "                        img_data = np.transpose(data, (1, 2, 0)).copy()\n",
    "                        for i in range(4):\n",
    "                            band = img_data[:, :, i]\n",
    "                            p2, p98 = np.percentile(band[band > 0] if (band > 0).any() else band, [2, 98])\n",
    "                            if p98 > p2:\n",
    "                                img_data[:, :, i] = np.clip((band - p2) / (p98 - p2) * 255, 0, 255).astype(np.uint8)\n",
    "                            else:\n",
    "                                img_data[:, :, i] = np.clip(band, 0, 255).astype(np.uint8)\n",
    "                        img = Image.fromarray(img_data, mode='RGBA')\n",
    "                    else:\n",
    "                        # Multiple bands - use first 3 for RGB\n",
    "                        img_data = np.transpose(data[:3], (1, 2, 0)).copy()\n",
    "                        for i in range(3):\n",
    "                            band = img_data[:, :, i]\n",
    "                            p2, p98 = np.percentile(band[band > 0] if (band > 0).any() else band, [2, 98])\n",
    "                            if p98 > p2:\n",
    "                                img_data[:, :, i] = np.clip((band - p2) / (p98 - p2) * 255, 0, 255).astype(np.uint8)\n",
    "                            else:\n",
    "                                img_data[:, :, i] = np.clip(band, 0, 255).astype(np.uint8)\n",
    "                        img = Image.fromarray(img_data, mode='RGB')\n",
    "                else:\n",
    "                    print(f\"  Warning: Unsupported data shape {data.shape} for {tif_path.name}\")\n",
    "                    return False\n",
    "            \n",
    "            # Resize if too large (for both uint8 direct and normalized images)\n",
    "            width, height = img.size\n",
    "            if width > max_size or height > max_size:\n",
    "                scale = min(max_size / width, max_size / height)\n",
    "                new_width = int(width * scale)\n",
    "                new_height = int(height * scale)\n",
    "                img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "                print(f\"  Resized {tif_path.name} from {width}x{height} to {new_width}x{new_height}\")\n",
    "            \n",
    "            # Save PNG\n",
    "            png_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            img.save(png_path, 'PNG', optimize=True)\n",
    "            return True\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  Error converting {tif_path.name}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Find all .tif files in output directories\n",
    "tif_files = list(output_dir.rglob(\"*.tif\")) + list(output_dir.rglob(\"*.TIF\"))\n",
    "\n",
    "if not tif_files:\n",
    "    print(f\"No .tif files found in {output_dir}\")\n",
    "else:\n",
    "    print(f\"Found {len(tif_files)} .tif file(s) to convert\")\n",
    "    \n",
    "    converted = 0\n",
    "    skipped = 0\n",
    "    \n",
    "    for tif_path in tif_files:\n",
    "        # Skip checkpoint files\n",
    "        if '.ipynb_checkpoints' in str(tif_path):\n",
    "            print(f\"  Skipping {tif_path.relative_to(output_dir)} (checkpoint file)\")\n",
    "            skipped += 1\n",
    "            continue\n",
    "        \n",
    "        png_path = tif_path.with_suffix('.png')\n",
    "        \n",
    "        # Force regenerate PNGs to ensure they use the latest conversion logic\n",
    "        # (especially important after fixing the black image issue)\n",
    "        force_regenerate = True\n",
    "        \n",
    "        if png_path.exists() and not force_regenerate:\n",
    "            # Only skip if PNG is newer and we're not forcing regeneration\n",
    "            if png_path.stat().st_mtime > tif_path.stat().st_mtime:\n",
    "                print(f\"  Skipping {tif_path.relative_to(output_dir)} (PNG already exists and is newer)\")\n",
    "                skipped += 1\n",
    "                continue\n",
    "        \n",
    "        print(f\"  Converting {tif_path.relative_to(output_dir)}...\")\n",
    "        if convert_tif_to_png(tif_path, png_path):\n",
    "            converted += 1\n",
    "            print(f\"    ✓ Saved to {png_path.relative_to(output_dir)}\")\n",
    "        else:\n",
    "            skipped += 1\n",
    "    \n",
    "    print(f\"\\nConversion complete: {converted} converted, {skipped} skipped\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
