{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Westminster Ground Truth Analysis\n",
    "\n",
    "This notebook demonstrates the complete workflow for creating orthomosaics from DJI drone imagery and evaluating their accuracy:\n",
    "\n",
    "1. **Data Loading**: Load images, GCPs, and DJI metadata\n",
    "2. **Feature Detection & Matching**: Detect and match features across images\n",
    "3. **Camera Pose Estimation**: Estimate initial camera poses\n",
    "4. **Bundle Adjustment**: Refine poses to minimize reprojection error\n",
    "5. **Orthomosaic Creation**: Generate orthomosaics with and without GCPs\n",
    "6. **Basemap Comparison**: Download basemaps and quantify absolute accuracy\n",
    "7. **Visualization**: Visualize matches, errors, and results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Install Dependencies\n",
    "\n",
    "First, install the required packages if they're not already installed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing packages from requirements.txt...\n",
      "✓ Packages installed from requirements.txt\n",
      "\n",
      "Setup complete!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Try to install from requirements.txt first\n",
    "requirements_file = Path(\"requirements.txt\")\n",
    "if requirements_file.exists():\n",
    "    print(\"Installing packages from requirements.txt...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"-r\", str(requirements_file)])\n",
    "    print(\"✓ Packages installed from requirements.txt\")\n",
    "else:\n",
    "    # Fallback: install packages individually\n",
    "    print(\"requirements.txt not found. Installing packages individually...\")\n",
    "    packages = [\n",
    "        \"numpy>=1.24.0\",\n",
    "        \"opencv-python>=4.8.0\",\n",
    "        \"scipy>=1.11.0\",\n",
    "        \"scikit-image>=0.21.0\",\n",
    "        \"rasterio>=1.3.0\",\n",
    "        \"pillow>=10.0.0\",\n",
    "        \"matplotlib>=3.7.0\",\n",
    "        \"pandas>=2.0.0\",\n",
    "        \"pyproj>=3.6.0\",\n",
    "        \"shapely>=2.0.0\",\n",
    "        \"requests>=2.31.0\",\n",
    "        \"tqdm>=4.66.0\",\n",
    "        \"exifread>=3.0.0\",\n",
    "        \"utm>=0.7.0\"\n",
    "    ]\n",
    "    for package in packages:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
    "    print(\"✓ All packages installed\")\n",
    "\n",
    "print(\"\\nSetup complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add package to path\n",
    "sys.path.insert(0, str(Path.cwd()))\n",
    "\n",
    "from westminster_ground_truth_analysis import (\n",
    "    GCPParser,\n",
    "    DJIMetadataParser,\n",
    "    OrthomosaicPipeline,\n",
    "    download_basemap,\n",
    "    compare_orthomosaic_to_basemap,\n",
    "    visualize_matches,\n",
    "    visualize_reprojection_errors,\n",
    "    visualize_camera_poses,\n",
    "    create_match_quality_report\n",
    ")\n",
    "\n",
    "# Set up paths\n",
    "data_dir = Path(\"/Users/mauriciohessflores/Documents/Code/Data/New Westminster Oct _25\")\n",
    "output_dir = Path(\"outputs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Setup complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Ground Control Points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 23 ground control points\n",
      "  GCP1: X=5450945.53, Y=506914.12, Z=77.45\n",
      "  GCP2: X=5450730.01, Y=506657.79, Z=79.22\n",
      "  GCP3: X=5450480.01, Y=506577.77, Z=59.40\n",
      "  GCP4: X=5450578.63, Y=506765.03, Z=65.59\n",
      "  GCP5: X=5450715.96, Y=506926.13, Z=63.10\n",
      "\n",
      "GCP Bounds: X=[5450109.82, 5450992.66], Y=[506577.77, 507315.01]\n"
     ]
    }
   ],
   "source": [
    "# Parse GCP file\n",
    "gcp_file = data_dir / \"25-3288-CONTROL-NAD83-UTM10N-EGM2008.csv\"\n",
    "gcp_parser = GCPParser(str(gcp_file))\n",
    "\n",
    "gcps = gcp_parser.get_gcps()\n",
    "print(f\"Loaded {len(gcps)} ground control points\")\n",
    "\n",
    "# Display first few GCPs\n",
    "for gcp in gcps[:5]:\n",
    "    print(f\"  {gcp.name}: X={gcp.x:.2f}, Y={gcp.y:.2f}, Z={gcp.z:.2f}\")\n",
    "\n",
    "# Get bounds\n",
    "min_x, min_y, max_x, max_y = gcp_parser.get_bounds()\n",
    "print(f\"\\nGCP Bounds: X=[{min_x:.2f}, {max_x:.2f}], Y=[{min_y:.2f}, {max_y:.2f}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Process First Dataset (DJI_202510060955_017_25-3288)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing timestamp file: /Users/mauriciohessflores/Documents/Code/Data/New Westminster Oct _25/DJI_202510060955_017_25-3288/DJI_202510060955_017_25-3288_Timestamp.MRK\n",
      "Parsing navigation file: /Users/mauriciohessflores/Documents/Code/Data/New Westminster Oct _25/DJI_202510060955_017_25-3288/DJI_202510060955_017_25-3288_PPKNAV.nav\n",
      "Processing dataset 1 (without GCPs)...\n",
      "============================================================\n",
      "Starting Orthomosaic Pipeline\n",
      "============================================================\n",
      "Found 543 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 543/543 [01:12<00:00,  7.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 543 images\n",
      "Loading features from cache: outputs/dataset1_no_gcp/cache/features.pkl\n",
      "Loaded features for 543 images\n",
      "Loading matches from cache: outputs/dataset1_no_gcp/cache/matches.pkl\n",
      "Loaded 100 matches\n",
      "Estimating initial camera poses...\n",
      "Initialized poses for 2 cameras\n",
      "Performing bundle adjustment...\n",
      "Bundle adjustment: 1905 3D points, 3810 observations, 2 cameras\n",
      "Initial mean reprojection error: 0.33 pixels\n",
      "Note: Using simplified bundle adjustment. For production, consider OpenSfM or COLMAP.\n",
      "\n",
      "Reprojection Errors:\n",
      "  Mean: 0.33 pixels\n",
      "  Median: 0.06 pixels\n",
      "  Max: 382.70 pixels\n",
      "Creating orthomosaic (resolution: 0.1m/pixel)...\n",
      "Orthomosaic size: 1000x1004 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projecting images: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 543/543 [00:01<00:00, 478.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orthomosaic saved to outputs/dataset1_no_gcp/dataset1_no_gcp.tif\n",
      "============================================================\n",
      "Pipeline Complete\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup for first dataset\n",
    "dataset1_dir = data_dir / \"DJI_202510060955_017_25-3288\"\n",
    "\n",
    "# Try to parse DJI metadata\n",
    "dji_metadata1 = DJIMetadataParser(str(dataset1_dir))\n",
    "\n",
    "# Create pipeline without GCPs first\n",
    "pipeline1_no_gcp = OrthomosaicPipeline(\n",
    "    image_dir=str(dataset1_dir),\n",
    "    output_dir=str(output_dir / \"dataset1_no_gcp\"),\n",
    "    feature_detector=\"sift\",\n",
    "    max_features=5000,\n",
    "    match_ratio=0.7,\n",
    "    use_gcps=False,\n",
    "    dji_metadata=dji_metadata1\n",
    ")\n",
    "\n",
    "print(\"Processing dataset 1 (without GCPs)...\")\n",
    "output1_no_gcp = pipeline1_no_gcp.run_full_pipeline(output_name=\"dataset1_no_gcp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset 1 (with GCPs)...\n",
      "============================================================\n",
      "Starting Orthomosaic Pipeline\n",
      "============================================================\n",
      "Found 543 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 543/543 [01:14<00:00,  7.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 543 images\n",
      "Loading features from cache: outputs/dataset1_with_gcp/cache/features.pkl\n",
      "Loaded features for 543 images\n",
      "Loading matches from cache: outputs/dataset1_with_gcp/cache/matches.pkl\n",
      "Loaded 100 matches\n",
      "Estimating initial camera poses...\n",
      "Initialized poses for 2 cameras\n",
      "Performing bundle adjustment...\n",
      "Bundle adjustment: 1905 3D points, 3810 observations, 2 cameras\n",
      "Initial mean reprojection error: 0.33 pixels\n",
      "Note: Using simplified bundle adjustment. For production, consider OpenSfM or COLMAP.\n",
      "\n",
      "Reprojection Errors:\n",
      "  Mean: 0.33 pixels\n",
      "  Median: 0.06 pixels\n",
      "  Max: 382.70 pixels\n",
      "Creating orthomosaic (resolution: 0.1m/pixel)...\n",
      "Orthomosaic size: 1000x1004 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projecting images: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 543/543 [00:01<00:00, 479.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orthomosaic saved to outputs/dataset1_with_gcp/dataset1_with_gcp.tif\n",
      "============================================================\n",
      "Pipeline Complete\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create pipeline with GCPs\n",
    "pipeline1_with_gcp = OrthomosaicPipeline(\n",
    "    image_dir=str(dataset1_dir),\n",
    "    output_dir=str(output_dir / \"dataset1_with_gcp\"),\n",
    "    feature_detector=\"sift\",\n",
    "    max_features=5000,\n",
    "    match_ratio=0.7,\n",
    "    use_gcps=True,\n",
    "    gcp_parser=gcp_parser,\n",
    "    dji_metadata=dji_metadata1\n",
    ")\n",
    "\n",
    "print(\"Processing dataset 1 (with GCPs)...\")\n",
    "output1_with_gcp = pipeline1_with_gcp.run_full_pipeline(output_name=\"dataset1_with_gcp\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Results for Dataset 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match visualization saved to outputs/dataset1_match_example.png\n",
      "Reprojection error visualization saved to outputs/dataset1_reprojection_errors.png\n",
      "Camera pose visualization saved to outputs/dataset1_camera_poses.png\n",
      "Creating match quality report...\n",
      "Match visualization saved to outputs/dataset1_matches/match_visualization_1.png\n",
      "Match visualization saved to outputs/dataset1_matches/match_visualization_2.png\n",
      "Match visualization saved to outputs/dataset1_matches/match_visualization_3.png\n",
      "Match visualization saved to outputs/dataset1_matches/match_visualization_4.png\n",
      "Match visualization saved to outputs/dataset1_matches/match_visualization_5.png\n",
      "Match visualization saved to outputs/dataset1_matches/match_visualization_worst_96.png\n",
      "Match visualization saved to outputs/dataset1_matches/match_visualization_worst_97.png\n",
      "Match visualization saved to outputs/dataset1_matches/match_visualization_worst_98.png\n",
      "Match visualization saved to outputs/dataset1_matches/match_visualization_worst_99.png\n",
      "Match visualization saved to outputs/dataset1_matches/match_visualization_worst_100.png\n",
      "Match quality report saved to outputs/dataset1_matches\n"
     ]
    }
   ],
   "source": [
    "# Visualize feature matches\n",
    "if len(pipeline1_no_gcp.matches) > 0:\n",
    "    visualize_matches(\n",
    "        pipeline1_no_gcp,\n",
    "        match_idx=0,\n",
    "        output_path=str(output_dir / \"dataset1_match_example.png\"),\n",
    "        max_matches=100\n",
    "    )\n",
    "\n",
    "# Visualize reprojection errors\n",
    "visualize_reprojection_errors(\n",
    "    pipeline1_no_gcp,\n",
    "    output_path=str(output_dir / \"dataset1_reprojection_errors.png\")\n",
    ")\n",
    "\n",
    "# Visualize camera poses\n",
    "visualize_camera_poses(\n",
    "    pipeline1_no_gcp,\n",
    "    output_path=str(output_dir / \"dataset1_camera_poses.png\")\n",
    ")\n",
    "\n",
    "# Create match quality report\n",
    "create_match_quality_report(\n",
    "    pipeline1_no_gcp,\n",
    "    output_dir=str(output_dir / \"dataset1_matches\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Process Second Dataset (DJI_202510060955_019_25-3288)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing timestamp file: /Users/mauriciohessflores/Documents/Code/Data/New Westminster Oct _25/DJI_202510060955_019_25-3288/DJI_202510060955_019_Timestamp.MRK\n",
      "Parsing navigation file: /Users/mauriciohessflores/Documents/Code/Data/New Westminster Oct _25/DJI_202510060955_019_25-3288/DJI_202510060955_019_PPKNAV.nav\n",
      "Processing dataset 2 (without GCPs)...\n",
      "============================================================\n",
      "Starting Orthomosaic Pipeline\n",
      "============================================================\n",
      "Found 528 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 528/528 [01:08<00:00,  7.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 528 images\n",
      "Loading features from cache: outputs/dataset2_no_gcp/cache/features.pkl\n",
      "Loaded features for 528 images\n",
      "Loading matches from cache: outputs/dataset2_no_gcp/cache/matches.pkl\n",
      "Loaded 100 matches\n",
      "Estimating initial camera poses...\n",
      "Initialized poses for 2 cameras\n",
      "Performing bundle adjustment...\n",
      "Bundle adjustment: 10 3D points, 20 observations, 2 cameras\n",
      "Initial mean reprojection error: 894.77 pixels\n",
      "Note: Using simplified bundle adjustment. For production, consider OpenSfM or COLMAP.\n",
      "\n",
      "Reprojection Errors:\n",
      "  Mean: 894.77 pixels\n",
      "  Median: 0.00 pixels\n",
      "  Max: 8186.22 pixels\n",
      "Creating orthomosaic (resolution: 0.1m/pixel)...\n",
      "Orthomosaic size: 1000x1000 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projecting images: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 528/528 [00:01<00:00, 436.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orthomosaic saved to outputs/dataset2_no_gcp/dataset2_no_gcp.tif\n",
      "============================================================\n",
      "Pipeline Complete\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup for second dataset\n",
    "dataset2_dir = data_dir / \"DJI_202510060955_019_25-3288\"\n",
    "\n",
    "# Try to parse DJI metadata\n",
    "dji_metadata2 = DJIMetadataParser(str(dataset2_dir))\n",
    "\n",
    "# Create pipeline without GCPs\n",
    "pipeline2_no_gcp = OrthomosaicPipeline(\n",
    "    image_dir=str(dataset2_dir),\n",
    "    output_dir=str(output_dir / \"dataset2_no_gcp\"),\n",
    "    feature_detector=\"sift\",\n",
    "    max_features=5000,\n",
    "    match_ratio=0.7,\n",
    "    use_gcps=False,\n",
    "    dji_metadata=dji_metadata2\n",
    ")\n",
    "\n",
    "print(\"Processing dataset 2 (without GCPs)...\")\n",
    "output2_no_gcp = pipeline2_no_gcp.run_full_pipeline(output_name=\"dataset2_no_gcp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset 2 (with GCPs)...\n",
      "============================================================\n",
      "Starting Orthomosaic Pipeline\n",
      "============================================================\n",
      "Found 528 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 528/528 [01:08<00:00,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 528 images\n",
      "Loading features from cache: outputs/dataset2_with_gcp/cache/features.pkl\n",
      "Loaded features for 528 images\n",
      "Loading matches from cache: outputs/dataset2_with_gcp/cache/matches.pkl\n",
      "Loaded 100 matches\n",
      "Estimating initial camera poses...\n",
      "Initialized poses for 2 cameras\n",
      "Performing bundle adjustment...\n",
      "Bundle adjustment: 10 3D points, 20 observations, 2 cameras\n",
      "Initial mean reprojection error: 894.77 pixels\n",
      "Note: Using simplified bundle adjustment. For production, consider OpenSfM or COLMAP.\n",
      "\n",
      "Reprojection Errors:\n",
      "  Mean: 894.77 pixels\n",
      "  Median: 0.00 pixels\n",
      "  Max: 8186.22 pixels\n",
      "Creating orthomosaic (resolution: 0.1m/pixel)...\n",
      "Orthomosaic size: 1000x1000 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projecting images: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 528/528 [00:01<00:00, 467.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orthomosaic saved to outputs/dataset2_with_gcp/dataset2_with_gcp.tif\n",
      "============================================================\n",
      "Pipeline Complete\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create pipeline with GCPs\n",
    "pipeline2_with_gcp = OrthomosaicPipeline(\n",
    "    image_dir=str(dataset2_dir),\n",
    "    output_dir=str(output_dir / \"dataset2_with_gcp\"),\n",
    "    feature_detector=\"sift\",\n",
    "    max_features=5000,\n",
    "    match_ratio=0.7,\n",
    "    use_gcps=True,\n",
    "    gcp_parser=gcp_parser,\n",
    "    dji_metadata=dji_metadata2\n",
    ")\n",
    "\n",
    "print(\"Processing dataset 2 (with GCPs)...\")\n",
    "output2_with_gcp = pipeline2_with_gcp.run_full_pipeline(output_name=\"dataset2_with_gcp\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Download Basemap for Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basemap bounding box: (np.float64(49.20374809577927), np.float64(-122.90970020449743), np.float64(49.21168116673544), np.float64(-122.89956337139125))\n",
      "Downloading basemap at zoom level 18...\n",
      "Tile range: X [41571, 41579], Y [89799, 89790]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBasemap bounding box: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbbox\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Download basemap\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m basemap_path \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_basemap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbasemap.tif\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mesri_world_imagery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_resolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 0.1m per pixel\u001b[39;49;00m\n\u001b[1;32m     31\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Code/MyCode/westminster_ground_truth_analysis/westminster_ground_truth_analysis/basemap_downloader.py:178\u001b[0m, in \u001b[0;36mdownload_basemap\u001b[0;34m(bbox, output_path, source, zoom, target_resolution)\u001b[0m\n\u001b[1;32m    175\u001b[0m     tiles\u001b[38;5;241m.\u001b[39mappend(row)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# Stitch tiles together\u001b[39;00m\n\u001b[0;32m--> 178\u001b[0m tile_height \u001b[38;5;241m=\u001b[39m \u001b[43mtiles\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mheight\n\u001b[1;32m    179\u001b[0m tile_width \u001b[38;5;241m=\u001b[39m tiles[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mwidth\n\u001b[1;32m    181\u001b[0m stitched \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mnew(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m    182\u001b[0m                     ((xtile_max \u001b[38;5;241m-\u001b[39m xtile_min \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m tile_width,\n\u001b[1;32m    183\u001b[0m                      (ytile_max \u001b[38;5;241m-\u001b[39m ytile_min \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m tile_height))\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Convert UTM bounds to lat/lon for basemap download\n",
    "import utm\n",
    "from pathlib import Path\n",
    "\n",
    "# Import GCPParser if not already imported\n",
    "try:\n",
    "    _ = GCPParser\n",
    "except NameError:\n",
    "    import sys\n",
    "    sys.path.insert(0, str(Path.cwd()))\n",
    "    from westminster_ground_truth_analysis import GCPParser\n",
    "\n",
    "# Get GCP bounds if not already defined\n",
    "try:\n",
    "    # Check if bounds are already defined\n",
    "    _ = min_x, min_y, max_x, max_y\n",
    "    print(\"Using existing GCP bounds\")\n",
    "except NameError:\n",
    "    # Get bounds from GCP parser (create parser if needed)\n",
    "    try:\n",
    "        _ = gcp_parser\n",
    "    except NameError:\n",
    "        # Create GCP parser if it doesn't exist\n",
    "        # Check if data_dir is defined, if not use default path\n",
    "        try:\n",
    "            _ = data_dir\n",
    "        except NameError:\n",
    "            data_dir = Path(\"/Users/mauriciohessflores/Documents/Code/Data/New Westminster Oct _25\")\n",
    "            print(f\"Using default data_dir: {data_dir}\")\n",
    "        \n",
    "        gcp_file = data_dir / \"25-3288-CONTROL-NAD83-UTM10N-EGM2008.csv\"\n",
    "        gcp_parser = GCPParser(str(gcp_file))\n",
    "        print(f\"Created GCP parser from {gcp_file}\")\n",
    "    \n",
    "    # Get bounds from GCP parser\n",
    "    min_x, min_y, max_x, max_y = gcp_parser.get_bounds()\n",
    "    print(f\"Retrieved GCP bounds: X=[{min_x:.2f}, {max_x:.2f}], Y=[{min_y:.2f}, {max_y:.2f}]\")\n",
    "\n",
    "# Convert GCP bounds from UTM to lat/lon\n",
    "# UTM Zone 10N (based on GCP file name)\n",
    "# NOTE: In the CSV, X column is actually Northing (~5.45M) and Y column is Easting (~500k)\n",
    "# utm.to_latlon expects (easting, northing), so we need to swap them\n",
    "center_easting = (min_y + max_y) / 2  # Y column is easting\n",
    "center_northing = (min_x + max_x) / 2  # X column is northing\n",
    "\n",
    "# Convert center point\n",
    "lat_center, lon_center = utm.to_latlon(center_easting, center_northing, 10, 'N')\n",
    "\n",
    "# Approximate bounds in lat/lon (rough conversion)\n",
    "# For more accuracy, convert all corners\n",
    "# Swap X and Y: Y is easting, X is northing\n",
    "lat_min, lon_min = utm.to_latlon(min_y, min_x, 10, 'N')\n",
    "lat_max, lon_max = utm.to_latlon(max_y, max_x, 10, 'N')\n",
    "\n",
    "bbox = (min(lat_min, lat_max), min(lon_min, lon_max), \n",
    "        max(lat_min, lat_max), max(lon_min, lon_max))\n",
    "\n",
    "print(f\"Basemap bounding box: {bbox}\")\n",
    "\n",
    "# Download basemap\n",
    "basemap_path = download_basemap(\n",
    "    bbox=bbox,\n",
    "    output_path=str(output_dir / \"basemap.tif\"),\n",
    "    source=\"esri_world_imagery\",\n",
    "    target_resolution=0.1  # 0.1m per pixel\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare Orthomosaics to Basemap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare dataset 1 without GCPs\n",
    "print(\"=\" * 60)\n",
    "print(\"Dataset 1 - Without GCPs\")\n",
    "print(\"=\" * 60)\n",
    "metrics1_no_gcp = compare_orthomosaic_to_basemap(\n",
    "    str(output1_no_gcp),\n",
    "    str(basemap_path),\n",
    "    output_dir=str(output_dir / \"comparison1_no_gcp\")\n",
    ")\n",
    "\n",
    "# Compare dataset 1 with GCPs\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Dataset 1 - With GCPs\")\n",
    "print(\"=\" * 60)\n",
    "metrics1_with_gcp = compare_orthomosaic_to_basemap(\n",
    "    str(output1_with_gcp),\n",
    "    str(basemap_path),\n",
    "    output_dir=str(output_dir / \"comparison1_with_gcp\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare dataset 2 without GCPs\n",
    "print(\"=\" * 60)\n",
    "print(\"Dataset 2 - Without GCPs\")\n",
    "print(\"=\" * 60)\n",
    "metrics2_no_gcp = compare_orthomosaic_to_basemap(\n",
    "    str(output2_no_gcp),\n",
    "    str(basemap_path),\n",
    "    output_dir=str(output_dir / \"comparison2_no_gcp\")\n",
    ")\n",
    "\n",
    "# Compare dataset 2 with GCPs\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Dataset 2 - With GCPs\")\n",
    "print(\"=\" * 60)\n",
    "metrics2_with_gcp = compare_orthomosaic_to_basemap(\n",
    "    str(output2_with_gcp),\n",
    "    str(basemap_path),\n",
    "    output_dir=str(output_dir / \"comparison2_with_gcp\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison summary\n",
    "import pandas as pd\n",
    "\n",
    "summary_data = {\n",
    "    'Dataset': ['Dataset 1', 'Dataset 1', 'Dataset 2', 'Dataset 2'],\n",
    "    'GCPs Used': ['No', 'Yes', 'No', 'Yes'],\n",
    "    'RMSE': [\n",
    "        metrics1_no_gcp['rmse'],\n",
    "        metrics1_with_gcp['rmse'],\n",
    "        metrics2_no_gcp['rmse'],\n",
    "        metrics2_with_gcp['rmse']\n",
    "    ],\n",
    "    'MAE': [\n",
    "        metrics1_no_gcp['mae'],\n",
    "        metrics1_with_gcp['mae'],\n",
    "        metrics2_no_gcp['mae'],\n",
    "        metrics2_with_gcp['mae']\n",
    "    ],\n",
    "    'Correlation': [\n",
    "        metrics1_no_gcp['correlation'],\n",
    "        metrics1_with_gcp['correlation'],\n",
    "        metrics2_no_gcp['correlation'],\n",
    "        metrics2_with_gcp['correlation']\n",
    "    ],\n",
    "    'SSIM': [\n",
    "        metrics1_no_gcp['ssim'],\n",
    "        metrics1_with_gcp['ssim'],\n",
    "        metrics2_no_gcp['ssim'],\n",
    "        metrics2_with_gcp['ssim']\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(summary_data)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SUMMARY COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "metrics_to_plot = ['RMSE', 'MAE', 'Correlation', 'SSIM']\n",
    "for idx, metric in enumerate(metrics_to_plot):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    x = np.arange(len(df))\n",
    "    width = 0.35\n",
    "    \n",
    "    no_gcp_values = df[df['GCPs Used'] == 'No'][metric].values\n",
    "    with_gcp_values = df[df['GCPs Used'] == 'Yes'][metric].values\n",
    "    \n",
    "    ax.bar(x - width/2, no_gcp_values, width, label='Without GCPs', alpha=0.7)\n",
    "    ax.bar(x + width/2, with_gcp_values, width, label='With GCPs', alpha=0.7)\n",
    "    \n",
    "    ax.set_xlabel('Dataset')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_title(f'{metric} Comparison')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(['Dataset 1', 'Dataset 2'])\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / \"accuracy_comparison.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nComparison visualization saved to {output_dir / 'accuracy_comparison.png'}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
