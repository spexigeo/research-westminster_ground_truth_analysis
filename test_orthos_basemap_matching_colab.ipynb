{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orthomosaic-Basemap Feature Matching and Registration\n",
    "\n",
    "This notebook performs feature matching between orthomosaics (with/without GCPs) and a ground control basemap using SIFT and evaluates 2D shifting and registration.\n",
    "\n",
    "## Goals:\n",
    "1. **Feature Matching**: Use SIFT to find corresponding features between orthos and basemap\n",
    "2. **Multi-Resolution Analysis**: Evaluate matching at full, half, and quarter resolution\n",
    "3. **2D Registration**: Apply computed shifts to register orthos to basemap\n",
    "4. **Visualization**: Create visualizations of matches and registered orthos\n",
    "\n",
    "## Inputs:\n",
    "- **Ground Control Basemap**: `TestsiteNewWest_Spexigeo_RTK.tiff`\n",
    "- **Orthomosaic (No GCPs)**: `outputs/orthomosaics/orthomosaic_no_gcps.tif`\n",
    "- **Orthomosaic (With GCPs)**: `outputs/orthomosaics/orthomosaic_with_gcps.tif`\n",
    "\n",
    "## Outputs:\n",
    "- All outputs saved to `outputs/test_matching/`\n",
    "- Match visualizations at different resolutions\n",
    "- Registered orthomosaics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Set working directory\n",
    "import os\n",
    "os.chdir('/content/drive/MyDrive/Colab Notebooks')\n",
    "# Or adjust path as needed\n",
    "print('\u2713 Google Drive mounted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Install Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if needed\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "packages = ['opencv-python', 'scikit-image', 'rasterio', 'numpy', 'matplotlib', 'pillow', 'scipy']\n",
    "for package in packages:\n",
    "    try:\n",
    "        if package == 'opencv-python':\n",
    "            __import__('cv2')\n",
    "        elif package == 'scikit-image':\n",
    "            __import__('skimage')\n",
    "        elif package == 'pillow':\n",
    "            __import__('PIL')\n",
    "        else:\n",
    "            __import__(package)\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "print(\"\u2713 Dependencies installed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling, transform_bounds\n",
    "from rasterio import Affine\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import warnings\n",
    "import json\n",
    "from typing import Dict, Tuple, Optional, List\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"\u2713 Imports successful!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup Paths and Output Directories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "data_dir = Path(\"/Users/mauriciohessflores/Documents/Code/Data/New Westminster Oct _25\")\n",
    "output_dir = Path(\"outputs\")\n",
    "\n",
    "# Input files\n",
    "basemap_path = data_dir / \"Michael_RTK_orthos\" / \"TestsiteNewWest_Spexigeo_RTK.tiff\"\n",
    "ortho_no_gcps_path = output_dir / \"orthomosaics\" / \"orthomosaic_no_gcps.tif\"\n",
    "ortho_with_gcps_path = output_dir / \"orthomosaics\" / \"orthomosaic_with_gcps.tif\"\n",
    "\n",
    "# Output directory structure\n",
    "matching_output_dir = output_dir / \"test_matching\"\n",
    "matching_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Subdirectories\n",
    "reprojected_dir = matching_output_dir / \"reprojected\"\n",
    "reprojected_dir.mkdir(exist_ok=True)\n",
    "\n",
    "converted_dir = matching_output_dir / \"converted\"\n",
    "converted_dir.mkdir(exist_ok=True)\n",
    "\n",
    "matches_dir = matching_output_dir / \"matches\"\n",
    "matches_dir.mkdir(exist_ok=True)\n",
    "\n",
    "registered_dir = matching_output_dir / \"registered\"\n",
    "registered_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"\u2713 Output directory: {matching_output_dir}\")\n",
    "print(f\"  - Reprojected: {reprojected_dir}\")\n",
    "print(f\"  - Converted: {converted_dir}\")\n",
    "print(f\"  - Matches: {matches_dir}\")\n",
    "print(f\"  - Registered: {registered_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load and Check Input Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if files exist\n",
    "if not basemap_path.exists():\n",
    "    raise FileNotFoundError(f\"Basemap not found: {basemap_path}\")\n",
    "if not ortho_no_gcps_path.exists():\n",
    "    raise FileNotFoundError(f\"Orthomosaic (no GCPs) not found: {ortho_no_gcps_path}\")\n",
    "if not ortho_with_gcps_path.exists():\n",
    "    raise FileNotFoundError(f\"Orthomosaic (with GCPs) not found: {ortho_with_gcps_path}\")\n",
    "\n",
    "print(\"\u2713 All input files found\")\n",
    "\n",
    "# Get basic info about each file\n",
    "print(\"\\n\ud83d\udcca File Information:\")\n",
    "for name, path in [(\"Basemap\", basemap_path), (\"Ortho (No GCPs)\", ortho_no_gcps_path), (\"Ortho (With GCPs)\", ortho_with_gcps_path)]:\n",
    "    with rasterio.open(path) as src:\n",
    "        file_size_mb = path.stat().st_size / (1024 * 1024)\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"  Path: {path}\")\n",
    "        print(f\"  Size: {file_size_mb:.2f} MB\")\n",
    "        print(f\"  CRS: {src.crs}\")\n",
    "        print(f\"  Dimensions: {src.width} x {src.height}\")\n",
    "        print(f\"  Bands: {src.count}\")\n",
    "        print(f\"  Bounds: {src.bounds}\")\n",
    "        if src.crs:\n",
    "            pixel_size_x = abs(src.transform[0])\n",
    "            pixel_size_y = abs(src.transform[4])\n",
    "            print(f\"  Pixel size: {pixel_size_x:.4f} m (X), {pixel_size_y:.4f} m (Y)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Reproject Orthomosaics to Match Basemap CRS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting files to JPEG at different resolutions...\n",
      "\n",
      "Converting basemap at half resolution...\n",
      "    Processing 90129x90188 -> 45064x45094 (factor: 0.5)\n",
      "    Using tile-based processing (tile size: 2048)...\n",
      "    Computing image statistics for normalization...\n",
      "      Processed 10/45 tile rows...\n",
      "      Processed 20/45 tile rows...\n",
      "      Processed 30/45 tile rows...\n",
      "      Processed 40/45 tile rows...\n",
      "    \u2713 Saved JPEG: outputs/test_matching/converted/basemap_half.jpg (45064x45094, 612.24 MB)\n",
      "\n",
      "Converting basemap at quarter resolution...\n",
      "    Processing 90129x90188 -> 22532x22547 (factor: 0.25)\n",
      "    Using tile-based processing (tile size: 2048)...\n",
      "    Computing image statistics for normalization...\n",
      "      Processed 10/45 tile rows...\n",
      "      Processed 20/45 tile rows...\n",
      "      Processed 30/45 tile rows...\n",
      "      Processed 40/45 tile rows...\n",
      "    \u2713 Saved JPEG: outputs/test_matching/converted/basemap_quarter.jpg (22532x22547, 158.40 MB)\n",
      "\n",
      "Converting no_gcps at half resolution...\n",
      "    Processing 88515x89120 -> 44257x44560 (factor: 0.5)\n",
      "    Using tile-based processing (tile size: 2048)...\n",
      "    Computing image statistics for normalization...\n",
      "      Processed 10/44 tile rows...\n",
      "      Processed 20/44 tile rows...\n",
      "      Processed 30/44 tile rows...\n",
      "      Processed 40/44 tile rows...\n",
      "    \u2713 Saved JPEG: outputs/test_matching/converted/no_gcps_half.jpg (44257x44560, 413.17 MB)\n",
      "\n",
      "Converting no_gcps at quarter resolution...\n",
      "    Processing 88515x89120 -> 22128x22280 (factor: 0.25)\n",
      "    Using tile-based processing (tile size: 2048)...\n",
      "    Computing image statistics for normalization...\n",
      "      Processed 10/44 tile rows...\n",
      "      Processed 20/44 tile rows...\n",
      "      Processed 30/44 tile rows...\n",
      "      Processed 40/44 tile rows...\n",
      "    \u2713 Saved JPEG: outputs/test_matching/converted/no_gcps_quarter.jpg (22128x22280, 141.40 MB)\n",
      "\n",
      "Converting with_gcps at half resolution...\n",
      "    Processing 88586x89028 -> 44293x44514 (factor: 0.5)\n",
      "    Using tile-based processing (tile size: 2048)...\n",
      "    Computing image statistics for normalization...\n",
      "      Processed 10/44 tile rows...\n",
      "      Processed 20/44 tile rows...\n",
      "      Processed 30/44 tile rows...\n",
      "      Processed 40/44 tile rows...\n",
      "    \u2713 Saved JPEG: outputs/test_matching/converted/with_gcps_half.jpg (44293x44514, 411.65 MB)\n",
      "\n",
      "Converting with_gcps at quarter resolution...\n",
      "    Processing 88586x89028 -> 22146x22257 (factor: 0.25)\n",
      "    Using tile-based processing (tile size: 2048)...\n",
      "    Computing image statistics for normalization...\n",
      "      Processed 10/44 tile rows...\n",
      "      Processed 20/44 tile rows...\n",
      "      Processed 30/44 tile rows...\n",
      "      Processed 40/44 tile rows...\n",
      "    \u2713 Saved JPEG: outputs/test_matching/converted/with_gcps_quarter.jpg (22146x22257, 140.93 MB)\n",
      "\n",
      "\u2713 Conversion complete!\n"
     ]
    }
   ],
   "source": [
    "# Ensure imports are available\n",
    "try:\n",
    "    from pathlib import Path\n",
    "    import numpy as np\n",
    "    import rasterio\n",
    "    from rasterio import Affine\n",
    "    from PIL import Image\n",
    "# Increase PIL image size limit to handle large images\n",
    "    import cv2\n",
    "    from typing import Tuple, Dict\n",
    "except (NameError, ImportError):\n",
    "    # Re-import if not available\n",
    "    from pathlib import Path\n",
    "    import numpy as np\n",
    "    import rasterio\n",
    "    from rasterio import Affine\n",
    "    import cv2\n",
    "    from typing import Tuple, Dict\n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = None  # Disable decompression bomb protection\n",
    "\n",
    "def convert_geotiff_to_jpeg(geotiff_path: Path, output_path: Path, downsample_factor: float = 1.0) -> Tuple[np.ndarray, Dict]:\n",
    "    \"\"\"\n",
    "    Convert GeoTIFF to JPEG format at specified resolution.\n",
    "    \n",
    "    Args:\n",
    "        geotiff_path: Path to input GeoTIFF\n",
    "        output_path: Path to save JPEG\n",
    "        downsample_factor: Factor to downsample (1.0 = full res, 0.5 = half, 0.25 = quarter)\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (image array, metadata dict with transform info)\n",
    "    \"\"\"\n",
    "    with rasterio.open(geotiff_path) as src:\n",
    "        # Get metadata\n",
    "        metadata = {\n",
    "            'transform': src.transform,\n",
    "            'crs': src.crs,\n",
    "            'bounds': src.bounds,\n",
    "            'width': src.width,\n",
    "            'height': src.height\n",
    "        }\n",
    "        \n",
    "        # Calculate output dimensions\n",
    "        if downsample_factor < 1.0:\n",
    "            new_height = int(src.height * downsample_factor)\n",
    "            new_width = int(src.width * downsample_factor)\n",
    "        else:\n",
    "            new_height = src.height\n",
    "            new_width = src.width\n",
    "        \n",
    "        print(f\"    Processing {src.width}x{src.height} -> {new_width}x{new_height} (factor: {downsample_factor})\")\n",
    "        \n",
    "        # For very large images, process in tiles to avoid memory issues\n",
    "        # Use tile-based processing for images > 10k pixels\n",
    "        use_tiles = src.width > 10000 or src.height > 10000\n",
    "        \n",
    "        if use_tiles:\n",
    "            # Process in tiles with downsampling\n",
    "            print(f\"    Using tile-based processing (tile size: 2048)...\")\n",
    "            \n",
    "            # Compute global statistics for normalization\n",
    "            # Use a sample-based approach for memory efficiency\n",
    "            print(f\"    Computing image statistics for normalization...\")\n",
    "            \n",
    "            # Read a representative sample (center region) to estimate min/max\n",
    "            sample_size = min(5000, src.width, src.height)\n",
    "            center_x = src.width // 2\n",
    "            center_y = src.height // 2\n",
    "            sample_x = max(0, center_x - sample_size // 2)\n",
    "            sample_y = max(0, center_y - sample_size // 2)\n",
    "            sample_w = min(sample_size, src.width - sample_x)\n",
    "            sample_h = min(sample_size, src.height - sample_y)\n",
    "            \n",
    "            window = rasterio.windows.Window(sample_x, sample_y, sample_w, sample_h)\n",
    "            \n",
    "            if src.count >= 3:\n",
    "                sample_data = src.read([1, 2, 3], window=window)  # Shape: (3, H, W)\n",
    "                data_min = sample_data.min(axis=(1, 2), keepdims=True)  # Shape: (3, 1, 1)\n",
    "                data_max = sample_data.max(axis=(1, 2), keepdims=True)  # Shape: (3, 1, 1)\n",
    "            else:\n",
    "                sample_data = src.read(1, window=window)  # Shape: (H, W)\n",
    "                data_min_val = sample_data.min()\n",
    "                data_max_val = sample_data.max()\n",
    "                data_min = np.array([[[data_min_val]]])  # Shape: (1, 1, 1)\n",
    "                data_max = np.array([[[data_max_val]]])  # Shape: (1, 1, 1)\n",
    "                # Expand to 3 channels\n",
    "                data_min = np.repeat(data_min, 3, axis=0)  # Shape: (3, 1, 1)\n",
    "                data_max = np.repeat(data_max, 3, axis=0)  # Shape: (3, 1, 1)\n",
    "            \n",
    "            data_range = data_max - data_min\n",
    "            data_range[data_range == 0] = 1\n",
    "            \n",
    "            # Create output array\n",
    "            output_array = np.zeros((new_height, new_width, 3), dtype=np.uint8)\n",
    "            tile_size = 2048\n",
    "            \n",
    "            # Process in tiles\n",
    "            num_tiles_x = (src.width + tile_size - 1) // tile_size\n",
    "            num_tiles_y = (src.height + tile_size - 1) // tile_size\n",
    "            \n",
    "            for tile_y in range(num_tiles_y):\n",
    "                for tile_x in range(num_tiles_x):\n",
    "                    # Calculate tile window\n",
    "                    col_off = tile_x * tile_size\n",
    "                    row_off = tile_y * tile_size\n",
    "                    width = min(tile_size, src.width - col_off)\n",
    "                    height = min(tile_size, src.height - row_off)\n",
    "                    \n",
    "                    window = rasterio.windows.Window(col_off, row_off, width, height)\n",
    "                    \n",
    "                    # Read tile\n",
    "                    if src.count >= 3:\n",
    "                        tile_data = src.read([1, 2, 3], window=window)\n",
    "                    else:\n",
    "                        tile_data = src.read(1, window=window)\n",
    "                        tile_data = np.stack([tile_data] * 3)\n",
    "                    \n",
    "                    # Normalize\n",
    "                    tile_normalized = ((tile_data - data_min) / data_range * 255).astype(np.uint8)\n",
    "                    \n",
    "                    # Ensure tile_normalized has correct shape (3, H, W)\n",
    "                    if len(tile_normalized.shape) == 2:\n",
    "                        # Single band, convert to 3 channels\n",
    "                        tile_normalized = np.stack([tile_normalized] * 3)\n",
    "                    elif tile_normalized.shape[0] != 3:\n",
    "                        # Wrong number of channels, fix it\n",
    "                        if tile_normalized.shape[0] == 1:\n",
    "                            tile_normalized = np.repeat(tile_normalized, 3, axis=0)\n",
    "                        else:\n",
    "                            tile_normalized = tile_normalized[:3]  # Take first 3 channels\n",
    "                    \n",
    "                    # Downsample tile\n",
    "                    if downsample_factor < 1.0:\n",
    "                        tile_h, tile_w = tile_normalized.shape[1], tile_normalized.shape[2]\n",
    "                        new_tile_h = int(tile_h * downsample_factor)\n",
    "                        new_tile_w = int(tile_w * downsample_factor)\n",
    "                        \n",
    "                        if new_tile_h > 0 and new_tile_w > 0:\n",
    "                            tile_resized = np.zeros((3, new_tile_h, new_tile_w), dtype=np.uint8)\n",
    "                            for i in range(3):\n",
    "                                tile_resized[i] = cv2.resize(tile_normalized[i], (new_tile_w, new_tile_h), interpolation=cv2.INTER_AREA)\n",
    "                            tile_normalized = tile_resized\n",
    "                    \n",
    "                    # Calculate output position\n",
    "                    out_col_off = int(col_off * downsample_factor)\n",
    "                    out_row_off = int(row_off * downsample_factor)\n",
    "                    tile_h, tile_w = tile_normalized.shape[1], tile_normalized.shape[2]\n",
    "                    \n",
    "                    # Ensure we don't exceed output bounds\n",
    "                    out_h = min(tile_h, new_height - out_row_off)\n",
    "                    out_w = min(tile_w, new_width - out_col_off)\n",
    "                    \n",
    "                    if out_h > 0 and out_w > 0 and out_row_off >= 0 and out_col_off >= 0:\n",
    "                        # Ensure we don't exceed tile dimensions\n",
    "                        slice_h = min(out_h, tile_h)\n",
    "                        slice_w = min(out_w, tile_w)\n",
    "                        \n",
    "                        # Verify tile_normalized has correct shape\n",
    "                        if len(tile_normalized.shape) == 3 and tile_normalized.shape[0] == 3:\n",
    "                            # Slice tile to fit output bounds, then convert to (H, W, C) and place in output\n",
    "                            tile_slice = tile_normalized[:, :slice_h, :slice_w]  # Shape: (3, slice_h, slice_w)\n",
    "                            tile_rgb = tile_slice.transpose(1, 2, 0)  # Shape: (slice_h, slice_w, 3)\n",
    "                            # Place in output array (use actual slice dimensions)\n",
    "                            output_array[out_row_off:out_row_off+slice_h, out_col_off:out_col_off+slice_w] = tile_rgb\n",
    "                        else:\n",
    "                            print(f\"      Warning: Unexpected tile shape {tile_normalized.shape}, skipping tile\")\n",
    "                \n",
    "                if (tile_y + 1) % 10 == 0:\n",
    "                    print(f\"      Processed {tile_y + 1}/{num_tiles_y} tile rows...\")\n",
    "            \n",
    "            img_array = output_array\n",
    "            \n",
    "        else:\n",
    "            # For smaller images, read normally\n",
    "            if src.count >= 3:\n",
    "                data = src.read([1, 2, 3])\n",
    "            else:\n",
    "                data = src.read(1)\n",
    "                data = np.stack([data, data, data])\n",
    "            \n",
    "            # Normalize to 0-255\n",
    "            if data.dtype != np.uint8:\n",
    "                data_min = data.min(axis=(1, 2), keepdims=True)\n",
    "                data_max = data.max(axis=(1, 2), keepdims=True)\n",
    "                data_range = data_max - data_min\n",
    "                data_range[data_range == 0] = 1\n",
    "                data = ((data - data_min) / data_range * 255).astype(np.uint8)\n",
    "            \n",
    "            # Downsample if needed\n",
    "            if downsample_factor < 1.0:\n",
    "                height, width = data.shape[1], data.shape[2]\n",
    "                new_height = int(height * downsample_factor)\n",
    "                new_width = int(width * downsample_factor)\n",
    "                \n",
    "                data_resized = np.zeros((3, new_height, new_width), dtype=np.uint8)\n",
    "                for i in range(3):\n",
    "                    data_resized[i] = cv2.resize(data[i], (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "                data = data_resized\n",
    "            \n",
    "            # Convert to PIL Image format (H, W, C)\n",
    "            img_array = data.transpose(1, 2, 0)\n",
    "        \n",
    "        # Update metadata\n",
    "        metadata['width'] = new_width\n",
    "        metadata['height'] = new_height\n",
    "        if downsample_factor < 1.0:\n",
    "            old_transform = metadata['transform']\n",
    "            metadata['transform'] = Affine(\n",
    "                old_transform[0] / downsample_factor, old_transform[1], old_transform[2],\n",
    "                old_transform[3], old_transform[4] / downsample_factor, old_transform[5]\n",
    "            )\n",
    "        \n",
    "        # Save as JPEG (only if within PIL limits) or PNG\n",
    "        # Validate array before saving\n",
    "        if img_array.dtype != np.uint8:\n",
    "            print(f\"    \u26a0\ufe0f  Converting array from {img_array.dtype} to uint8...\")\n",
    "            img_array = np.clip(img_array, 0, 255).astype(np.uint8)\n",
    "        \n",
    "        if len(img_array.shape) != 3 or img_array.shape[2] != 3:\n",
    "            raise ValueError(f\"Invalid image array shape: {img_array.shape}, expected (H, W, 3)\")\n",
    "        \n",
    "        try:\n",
    "            img = Image.fromarray(img_array, 'RGB')\n",
    "            \n",
    "            if new_width <= 65500 and new_height <= 65500:\n",
    "                # Save as JPEG\n",
    "                img.save(output_path, 'JPEG', quality=95, optimize=True)\n",
    "                \n",
    "                # Verify file was written correctly\n",
    "                if output_path.exists() and output_path.stat().st_size > 0:\n",
    "                    print(f\"    \u2713 Saved JPEG: {output_path} ({new_width}x{new_height}, {output_path.stat().st_size / 1024 / 1024:.2f} MB)\")\n",
    "                else:\n",
    "                    raise IOError(f\"JPEG file was not written correctly: {output_path}\")\n",
    "            else:\n",
    "                # Save as PNG for very large images (PNG has no dimension limit)\n",
    "                print(f\"    \u26a0\ufe0f  Image too large for JPEG (PIL limit: 65500), saving as PNG...\")\n",
    "                output_path_png = output_path.with_suffix('.png')\n",
    "                img.save(output_path_png, 'PNG', compress_level=6)\n",
    "                \n",
    "                # Verify file was written correctly\n",
    "                if output_path_png.exists() and output_path_png.stat().st_size > 0:\n",
    "                    print(f\"    \u2713 Saved PNG: {output_path_png} ({new_width}x{new_height}, {output_path_png.stat().st_size / 1024 / 1024:.2f} MB)\")\n",
    "                    output_path = output_path_png\n",
    "                else:\n",
    "                    raise IOError(f\"PNG file was not written correctly: {output_path_png}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"    \u274c Error saving image: {e}\")\n",
    "            raise\n",
    "        \n",
    "        return img_array, metadata\n",
    "\n",
    "# Check if required variables are defined\n",
    "try:\n",
    "    from pathlib import Path\n",
    "except ImportError:\n",
    "    from pathlib import Path\n",
    "\n",
    "try:\n",
    "    _ = converted_dir\n",
    "except NameError:\n",
    "    try:\n",
    "        _ = output_dir\n",
    "    except NameError:\n",
    "        output_dir = Path(\"outputs\")\n",
    "    converted_dir = output_dir / \"test_matching\" / \"converted\"\n",
    "    converted_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"\u2139\ufe0f  converted_dir not defined, using default: {converted_dir}\")\n",
    "\n",
    "try:\n",
    "    _ = basemap_path\n",
    "except NameError:\n",
    "    try:\n",
    "        _ = data_dir\n",
    "    except NameError:\n",
    "        data_dir = Path(\"/Users/mauriciohessflores/Documents/Code/Data/New Westminster Oct _25\")\n",
    "    basemap_path = data_dir / \"Michael_RTK_orthos\" / \"TestsiteNewWest_Spexigeo_RTK.tiff\"\n",
    "    if not basemap_path.exists():\n",
    "        raise FileNotFoundError(f\"Basemap not found: {basemap_path}\")\n",
    "\n",
    "try:\n",
    "    _ = reprojected_paths\n",
    "except NameError:\n",
    "    try:\n",
    "        _ = reprojected_dir\n",
    "    except NameError:\n",
    "        try:\n",
    "            _ = output_dir\n",
    "        except NameError:\n",
    "            output_dir = Path(\"outputs\")\n",
    "        reprojected_dir = output_dir / \"test_matching\" / \"reprojected\"\n",
    "    \n",
    "    # Try to find reprojected files\n",
    "    reprojected_paths = {}\n",
    "    for ortho_name in ['no_gcps', 'with_gcps']:\n",
    "        reproj_path = reprojected_dir / f\"{ortho_name}_reprojected.tif\"\n",
    "        if reproj_path.exists():\n",
    "            reprojected_paths[ortho_name] = reproj_path\n",
    "            print(f\"\u2139\ufe0f  Found existing reprojected file: {reproj_path}\")\n",
    "        else:\n",
    "            print(f\"\u26a0\ufe0f  Reprojected file not found: {reproj_path}\")\n",
    "            print(f\"   Please run Step 3 first to create reprojected files\")\n",
    "\n",
    "# Convert basemap and reprojected orthos at different resolutions\n",
    "# Skip full resolution for now (too large, causes kernel crashes)\n",
    "# Can enable later if needed\n",
    "resolutions = {\n",
    "    # 'full': 1.0,  # Skipped - too large for memory\n",
    "    'half': 0.5,\n",
    "    'quarter': 0.25\n",
    "}\n",
    "\n",
    "converted_files = {}\n",
    "\n",
    "print(\"Converting files to JPEG at different resolutions...\")\n",
    "\n",
    "# Convert basemap at all resolutions\n",
    "for res_name, factor in resolutions.items():\n",
    "    basemap_jpeg = converted_dir / f\"basemap_{res_name}.jpg\"\n",
    "    if not basemap_jpeg.exists():\n",
    "        print(f\"\\nConverting basemap at {res_name} resolution...\")\n",
    "        basemap_img, basemap_meta = convert_geotiff_to_jpeg(basemap_path, basemap_jpeg, downsample_factor=factor)\n",
    "        if res_name not in converted_files:\n",
    "            converted_files[res_name] = {}\n",
    "        converted_files[res_name]['basemap'] = {'path': basemap_jpeg, 'img': basemap_img, 'meta': basemap_meta}\n",
    "    else:\n",
    "        # Check if PNG was saved instead (for very large images)\n",
    "        basemap_png = basemap_jpeg.with_suffix('.png')\n",
    "        if basemap_png.exists():\n",
    "            print(f\"\\nBasemap PNG ({res_name}) already exists: {basemap_png}\")\n",
    "            basemap_img = np.array(Image.open(basemap_png))\n",
    "            basemap_jpeg = basemap_png  # Update path\n",
    "        else:\n",
    "            print(f\"\\nBasemap JPEG ({res_name}) already exists: {basemap_jpeg}\")\n",
    "            basemap_img = np.array(Image.open(basemap_jpeg))\n",
    "        with rasterio.open(basemap_path) as src:\n",
    "            basemap_meta = {\n",
    "                'transform': src.transform,\n",
    "                'crs': src.crs,\n",
    "                'bounds': src.bounds,\n",
    "                'width': basemap_img.shape[1],\n",
    "                'height': basemap_img.shape[0]\n",
    "            }\n",
    "        if res_name not in converted_files:\n",
    "            converted_files[res_name] = {}\n",
    "        converted_files[res_name]['basemap'] = {'path': basemap_jpeg, 'img': basemap_img, 'meta': basemap_meta}\n",
    "\n",
    "# Convert reprojected orthos at all resolutions\n",
    "for ortho_name, reprojected_path in reprojected_paths.items():\n",
    "    for res_name, factor in resolutions.items():\n",
    "        ortho_jpeg = converted_dir / f\"{ortho_name}_{res_name}.jpg\"\n",
    "        if not ortho_jpeg.exists():\n",
    "            print(f\"\\nConverting {ortho_name} at {res_name} resolution...\")\n",
    "            ortho_img, ortho_meta = convert_geotiff_to_jpeg(reprojected_path, ortho_jpeg, downsample_factor=factor)\n",
    "            converted_files[res_name][ortho_name] = {'path': ortho_jpeg, 'img': ortho_img, 'meta': ortho_meta}\n",
    "        else:\n",
    "            # Check if PNG was saved instead (for very large images)\n",
    "            ortho_png = ortho_jpeg.with_suffix('.png')\n",
    "            if ortho_png.exists():\n",
    "                print(f\"\\n{ortho_name} PNG ({res_name}) already exists: {ortho_png}\")\n",
    "                ortho_img = np.array(Image.open(ortho_png))\n",
    "                ortho_jpeg = ortho_png  # Update path\n",
    "            else:\n",
    "                print(f\"\\n{ortho_name} JPEG ({res_name}) already exists: {ortho_jpeg}\")\n",
    "                ortho_img = np.array(Image.open(ortho_jpeg))\n",
    "            with rasterio.open(reprojected_path) as src:\n",
    "                ortho_meta = {\n",
    "                    'transform': src.transform,\n",
    "                    'crs': src.crs,\n",
    "                    'bounds': src.bounds,\n",
    "                    'width': ortho_img.shape[1],\n",
    "                    'height': ortho_img.shape[0]\n",
    "                }\n",
    "            if res_name not in converted_files:\n",
    "                converted_files[res_name] = {}\n",
    "            converted_files[res_name][ortho_name] = {'path': ortho_jpeg, 'img': ortho_img, 'meta': ortho_meta}\n",
    "\n",
    "print(f\"\\n\u2713 Conversion complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Matching no_gcps to basemap\n",
      "============================================================\n",
      "\n",
      "\ud83d\udcca Resolution: quarter (factor: 0.25)\n",
      "  Basemap: 22532x22547\n",
      "  Ortho: 22128x22280\n",
      "    Processing 19x19 tiles for img1, 19x19 tiles for img2\n"
     ]
    }
   ],
   "source": [
    "def perform_tile_based_orb_matching(img1: np.ndarray, img2: np.ndarray, tile_size: int = 4000, overlap: int = 800, max_features: int = 2000) -> Dict:\n",
    "    \"\"\"\n",
    "    Perform ORB feature matching using tile-based approach for memory efficiency.\n",
    "    \n",
    "    Args:\n",
    "        img1: First image (numpy array)\n",
    "        img2: Second image (numpy array)\n",
    "        tile_size: Size of each tile in pixels (default: 4000)\n",
    "        overlap: Overlap between tiles in pixels (default: 800)\n",
    "        max_features: Maximum features per tile (default: 2000)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with matching results aggregated from all tiles\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Matching no_gcps to basemap\n",
      "============================================================\n",
      "\n",
      "\ud83d\udcca Resolution: quarter (factor: 0.25)\n",
      "  Basemap: 22532x22547\n",
      "  Ortho: 22128x22280\n",
      "    Processing 19x19 tiles for img1, 19x19 tiles for img2\n"
     ]
    }
   ],
   "source": [
    "def perform_tile_based_orb_matching(img1: np.ndarray, img2: np.ndarray, tile_size: int = 4000, overlap: int = 800, max_features: int = 2000) -> Dict:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    Perform ORB feature matching using tile-based approach for memory efficiency.\n",
    "    \n",
    "    Args:\n",
    "        img1: First image (numpy array)\n",
    "        img2: Second image (numpy array)\n",
    "        tile_size: Size of each tile in pixels (default: 4000)\n",
    "        overlap: Overlap between tiles in pixels (default: 800)\n",
    "        max_features: Maximum features per tile (default: 2000)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with matching results aggregated from all tiles\n",
    "    \"\"\"\n",
    "    # Convert to grayscale if needed\n",
    "    if len(img1.shape) == 3:\n",
    "        gray1 = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray1 = img1\n",
    "    \n",
    "    if len(img2.shape) == 3:\n",
    "        gray2 = cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray2 = img2\n",
    "    \n",
    "    h1, w1 = gray1.shape\n",
    "    h2, w2 = gray2.shape\n",
    "    \n",
    "    # Calculate number of tiles\n",
    "    step = tile_size - overlap\n",
    "    tiles_x1 = max(1, (w1 + step - 1) // step)\n",
    "    tiles_y1 = max(1, (h1 + step - 1) // step)\n",
    "    tiles_x2 = max(1, (w2 + step - 1) // step)\n",
    "    tiles_y2 = max(1, (h2 + step - 1) // step)\n",
    "    \n",
    "    print(f\"    Processing {tiles_y1}x{tiles_x1} tiles for img1, {tiles_y2}x{tiles_x2} tiles for img2\")\n",
    "    \n",
    "    all_offsets_x = []\n",
    "    all_offsets_y = []\n",
    "    all_matches = []\n",
    "    total_keypoints1 = 0\n",
    "    total_keypoints2 = 0\n",
    "    \n",
    "    # Process tiles from img1\n",
    "    for ty1 in range(tiles_y1):\n",
    "        for tx1 in range(tiles_x1):\n",
    "            y1_start = ty1 * step\n",
    "            y1_end = min(y1_start + tile_size, h1)\n",
    "            x1_start = tx1 * step\n",
    "            x1_end = min(x1_start + tile_size, w1)\n",
    "            \n",
    "            tile1 = gray1[y1_start:y1_end, x1_start:x1_end]\n",
    "            \n",
    "            # Find corresponding region in img2 (use center of tile1 as reference)\n",
    "            # For now, match against all tiles in img2 and take best match\n",
    "            best_match_count = 0\n",
    "            best_offset_x = None\n",
    "            best_offset_y = None\n",
    "            \n",
    "            # Try matching against tiles in img2\n",
    "            for ty2 in range(tiles_y2):\n",
    "                for tx2 in range(tiles_x2):\n",
    "                    y2_start = ty2 * step\n",
    "                    y2_end = min(y2_start + tile_size, h2)\n",
    "                    x2_start = tx2 * step\n",
    "                    x2_end = min(x2_start + tile_size, w2)\n",
    "                    \n",
    "                    tile2 = gray2[y2_start:y2_end, x2_start:x2_end]\n",
    "                    \n",
    "                    # Perform SIFT matching on this tile pair\n",
    "                    # Use ORB for faster, more memory-efficient matching\n",
    "                    orb = cv2.ORB_create(nfeatures=max_features, edgeThreshold=31, patchSize=31)\n",
    "                    kp1_tile, des1_tile = orb.detectAndCompute(tile1, None)\n",
    "                    kp2_tile, des2_tile = orb.detectAndCompute(tile2, None)\n",
    "                    \n",
    "                    if des1_tile is None or des2_tile is None or len(des1_tile) == 0 or len(des2_tile) == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    # Match features\n",
    "                    # ORB uses binary descriptors - use Hamming distance matcher\n",
    "                    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)\n",
    "                    \n",
    "                    try:\n",
    "                    try:\n",
    "                        matches = bf.knnMatch(des1_tile, des2_tile, k=2)\n",
    "                    except:\n",
    "                        continue\n",
    "                    \n",
    "                    # Apply Lowe's ratio test\n",
    "                    good_matches = []\n",
    "                    for match_pair in matches:\n",
    "                        if len(match_pair) == 2:\n",
    "                            m, n = match_pair\n",
    "                            if m.distance < 0.7 * n.distance:\n",
    "                                good_matches.append(m)\n",
    "                    \n",
    "                    if len(good_matches) >= 4:\n",
    "                        # Calculate offset for this tile pair\n",
    "                        src_pts = np.float32([kp1_tile[m.queryIdx].pt for m in good_matches])\n",
    "                        dst_pts = np.float32([kp2_tile[m.trainIdx].pt for m in good_matches])\n",
    "                        \n",
    "                        # Calculate mean offset\n",
    "                        offsets = dst_pts - src_pts\n",
    "                        mean_offset_x = float(np.mean(offsets[:, 0]))\n",
    "                        mean_offset_y = float(np.mean(offsets[:, 1]))\n",
    "                        \n",
    "                        # Adjust for tile positions\n",
    "                        global_offset_x = mean_offset_x + (x2_start - x1_start)\n",
    "                        global_offset_y = mean_offset_y + (y2_start - y1_start)\n",
    "                        \n",
    "                        if len(good_matches) > best_match_count:\n",
    "                            best_match_count = len(good_matches)\n",
    "                            best_offset_x = global_offset_x\n",
    "                            best_offset_y = global_offset_y\n",
    "                    \n",
    "                    total_keypoints1 += len(kp1_tile) if kp1_tile else 0\n",
    "                    total_keypoints2 += len(kp2_tile) if kp2_tile else 0\n",
    "            \n",
    "            if best_offset_x is not None:\n",
    "                all_offsets_x.append(best_offset_x)\n",
    "                all_offsets_y.append(best_offset_y)\n",
    "                all_matches.append(best_match_count)\n",
    "    \n",
    "    # Aggregate results\n",
    "    if len(all_offsets_x) > 0:\n",
    "        # Use median offset (more robust than mean)\n",
    "        offset_x = float(np.median(all_offsets_x))\n",
    "        offset_y = float(np.median(all_offsets_y))\n",
    "        total_matches = sum(all_matches)\n",
    "        \n",
    "        # Calculate RMSE from offsets\n",
    "        if len(all_offsets_x) > 1:\n",
    "            errors_x = np.array(all_offsets_x) - offset_x\n",
    "            errors_y = np.array(all_offsets_y) - offset_y\n",
    "            rmse_2d = float(np.sqrt(np.mean(errors_x**2 + errors_y**2)))\n",
    "        else:\n",
    "            rmse_2d = 0.0\n",
    "    else:\n",
    "        offset_x = None\n",
    "        offset_y = None\n",
    "        total_matches = 0\n",
    "        rmse_2d = None\n",
    "    \n",
    "    return {\n",
    "        'num_keypoints1': total_keypoints1,\n",
    "        'num_keypoints2': total_keypoints2,\n",
    "        'num_matches': total_matches,\n",
    "        'num_inliers': total_matches,  # All matches are considered inliers\n",
    "        'offset_x': offset_x,\n",
    "        'offset_y': offset_y,\n",
    "        'rmse_2d': rmse_2d,\n",
    "        'homography': None,  # Not computed for tile-based\n",
    "        'confidence': total_matches / max(total_keypoints1, total_keypoints2) if total_keypoints1 > 0 and total_keypoints2 > 0 else 0.0,\n",
    "        'good_matches': [],  # Not stored for tile-based\n",
    "        'kp1': [],  # Not stored for tile-based\n",
    "        'kp2': []  # Not stored for tile-based\n",
    "    }\n",
    "\n",
    "# Ensure imports are available\n",
    "try:\n",
    "    import numpy as np\n",
    "    import cv2\n",
    "    from typing import Dict, Optional\n",
    "except (NameError, ImportError):\n",
    "    import numpy as np\n",
    "    import cv2\n",
    "    from typing import Dict, Optional\n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = None  # Disable decompression bomb protection\n",
    "def perform_sift_matching(img1: np.ndarray, img2: np.ndarray, max_features: int = 5000) -> Dict:\n",
    "    \"\"\"\n",
    "    Perform SIFT feature matching between two images.\n",
    "    \n",
    "    Args:\n",
    "        img1: First image (numpy array)\n",
    "        img2: Second image (numpy array)\n",
    "        max_features: Maximum number of features to detect\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with matching results\n",
    "    \"\"\"\n",
    "    # Convert to grayscale if needed\n",
    "    if len(img1.shape) == 3:\n",
    "        gray1 = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray1 = img1\n",
    "    \n",
    "    if len(img2.shape) == 3:\n",
    "        gray2 = cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray2 = img2\n",
    "    \n",
    "    # Initialize SIFT detector\n",
    "                    # Use ORB for faster, more memory-efficient matching\n",
    "                    orb = cv2.ORB_create(nfeatures=max_features, edgeThreshold=31, patchSize=31)\n",
    "    \n",
    "    # Detect keypoints and descriptors\n",
    "    kp1, des1 = sift.detectAndCompute(gray1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(gray2, None)\n",
    "    \n",
    "    if des1 is None or des2 is None or len(des1) == 0 or len(des2) == 0:\n",
    "        return {\n",
    "            'num_keypoints1': len(kp1) if kp1 else 0,\n",
    "            'num_keypoints2': len(kp2) if kp2 else 0,\n",
    "            'num_matches': 0,\n",
    "            'good_matches': [],\n",
    "            'kp1': kp1,\n",
    "            'kp2': kp2,\n",
    "            'error': 'No descriptors found'\n",
    "        }\n",
    "    \n",
    "    # Match features using FLANN or BFMatcher\n",
    "                    # ORB uses binary descriptors - use Hamming distance matcher\n",
    "                    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)\n",
    "    \n",
    "                    try:\n",
    "                        matches = bf.knnMatch(des1_tile, des2_tile, k=2)\n",
    "    \n",
    "    # Apply Lowe's ratio test\n",
    "    good_matches = []\n",
    "    for match_pair in matches:\n",
    "                        if len(match_pair) == 2:\n",
    "            m, n = match_pair\n",
    "            if m.distance < 0.75 * n.distance:  # Lowe's ratio test\n",
    "                good_matches.append(m)\n",
    "    \n",
    "    # Calculate offsets\n",
    "    offset_x = None\n",
    "    offset_y = None\n",
    "    rmse_2d = None\n",
    "    H = None\n",
    "    mask = None\n",
    "    \n",
    "    if len(good_matches) >= 4:\n",
    "        # Extract matched points\n",
    "        src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "        \n",
    "        # Find homography\n",
    "        H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "        \n",
    "        if H is not None:\n",
    "            # Calculate mean offset from homography\n",
    "            # Use center point as reference\n",
    "            h, w = gray1.shape\n",
    "            center = np.array([[[w/2, h/2]]], dtype=np.float32)\n",
    "            transformed_center = cv2.perspectiveTransform(center, H)\n",
    "            \n",
    "            offset_x = float(transformed_center[0][0][0] - center[0][0][0])\n",
    "            offset_y = float(transformed_center[0][0][1] - center[0][0][1])\n",
    "            offset_x = offset_x / scale_factor\n",
    "            offset_x = offset_x / scale_factor\n",
    "            offset_x = offset_x / scale_factor\n",
    "            \n",
    "            # Calculate RMSE from inliers\n",
    "            inlier_matches = [good_matches[i] for i in range(len(good_matches)) if mask[i]]\n",
    "            \n",
    "            if len(inlier_matches) > 0:\n",
    "                inlier_src = np.float32([kp1[m.queryIdx].pt for m in inlier_matches])\n",
    "                inlier_dst = np.float32([kp2[m.trainIdx].pt for m in inlier_matches])\n",
    "                \n",
    "                # Transform source points\n",
    "                inlier_src_transformed = cv2.perspectiveTransform(\n",
    "                    inlier_src.reshape(-1, 1, 2), H\n",
    "                ).reshape(-1, 2)\n",
    "                \n",
    "                # Calculate RMSE\n",
    "                errors = inlier_dst - inlier_src_transformed\n",
    "                rmse_2d = float(np.sqrt(np.mean(errors**2)))\n",
    "            # Scale RMSE back to original resolution\n",
    "            if scale_factor < 1.0:\n",
    "                rmse_2d = rmse_2d / scale_factor\n",
    "    \n",
    "    num_inliers = len([m for i, m in enumerate(good_matches) if mask is not None and mask[i]]) if mask is not None and len(good_matches) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'num_keypoints1': len(kp1),\n",
    "        'num_keypoints2': len(kp2),\n",
    "        'num_matches': len(good_matches),\n",
    "        'num_inliers': num_inliers,\n",
    "        'good_matches': good_matches,\n",
    "        'kp1': kp1,\n",
    "        'kp2': kp2,\n",
    "        'offset_x': offset_x,\n",
    "        'offset_y': offset_y,\n",
    "        'rmse_2d': rmse_2d,\n",
    "        'homography': H.tolist() if H is not None else None,\n",
    "        'confidence': len(good_matches) / max(len(kp1), len(kp2)) if len(kp1) > 0 and len(kp2) > 0 else 0.0\n",
    "    }\n",
    "\n",
    "# Perform matching at different resolutions\n",
    "# Use pre-saved JPEG files at each resolution\n",
    "# Note: Full resolution skipped - use half and quarter only\n",
    "resolutions = {\n",
    "    # 'full': 1.0,  # Skipped - too large for memory\n",
    "    # 'half': 0.5,  # Skipped - too large, causes kernel crashes\n",
    "    'quarter': 0.25\n",
    "}\n",
    "\n",
    "# Ensure required variables and imports are available\n",
    "try:\n",
    "    import numpy as np\n",
    "    from PIL import Image\n",
    "    from pathlib import Path\n",
    "except (NameError, ImportError):\n",
    "    import numpy as np\n",
    "    from PIL import Image\n",
    "    from pathlib import Path\n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = None  # Disable decompression bomb protection\n",
    "# Ensure converted_dir is defined\n",
    "try:\n",
    "    _ = converted_dir\n",
    "except NameError:\n",
    "    try:\n",
    "        _ = output_dir\n",
    "    except NameError:\n",
    "        output_dir = Path(\"outputs\")\n",
    "    converted_dir = output_dir / \"test_matching\" / \"converted\"\n",
    "    print(f\"\u2139\ufe0f  converted_dir not defined, using default: {converted_dir}\")\n",
    "\n",
    "matching_results = {}\n",
    "\n",
    "for ortho_name in ['no_gcps', 'with_gcps']:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Matching {ortho_name} to basemap\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    matching_results[ortho_name] = {}\n",
    "    \n",
    "    for res_name, factor in resolutions.items():\n",
    "        print(f\"\\n\ud83d\udcca Resolution: {res_name} (factor: {factor})\")\n",
    "        \n",
    "        # Load pre-saved images at this resolution\n",
    "        # Check if converted_files is available, otherwise load from disk\n",
    "        try:\n",
    "            _ = converted_files\n",
    "        except NameError:\n",
    "            print(\"  \u26a0\ufe0f  converted_files not defined, loading from disk...\")\n",
    "            converted_files = {}\n",
    "        \n",
    "        # Load basemap image\n",
    "        if res_name in converted_files and 'basemap' in converted_files[res_name]:\n",
    "            basemap_img = converted_files[res_name]['basemap']['img']\n",
    "        else:\n",
    "            # Load from disk\n",
    "            basemap_jpeg = converted_dir / f\"basemap_{res_name}.jpg\"\n",
    "            basemap_png = converted_dir / f\"basemap_{res_name}.png\"\n",
    "            if basemap_png.exists():\n",
    "                basemap_img = np.array(Image.open(basemap_png))\n",
    "            \n",
    "            # Immediately downsample if too large to prevent memory issues\n",
    "            max_load_dimension = 3000  # Downsample during load\n",
    "            if basemap_img.shape[0] > max_load_dimension or basemap_img.shape[1] > max_load_dimension:\n",
    "                scale = min(max_load_dimension / basemap_img.shape[0], max_load_dimension / basemap_img.shape[1])\n",
    "                new_h = int(basemap_img.shape[0] * scale)\n",
    "                new_w = int(basemap_img.shape[1] * scale)\n",
    "                import cv2\n",
    "                basemap_img = cv2.resize(basemap_img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "                print(f\"    Downsampled basemap during load: {new_w}x{new_h} (scale: {scale:.3f})\")\n",
    "            elif basemap_jpeg.exists():\n",
    "                basemap_img = np.array(Image.open(basemap_jpeg))\n",
    "            \n",
    "            # Immediately downsample if too large to prevent memory issues\n",
    "            max_load_dimension = 3000  # Downsample during load\n",
    "            if basemap_img.shape[0] > max_load_dimension or basemap_img.shape[1] > max_load_dimension:\n",
    "                scale = min(max_load_dimension / basemap_img.shape[0], max_load_dimension / basemap_img.shape[1])\n",
    "                new_h = int(basemap_img.shape[0] * scale)\n",
    "                new_w = int(basemap_img.shape[1] * scale)\n",
    "                import cv2\n",
    "                basemap_img = cv2.resize(basemap_img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "                print(f\"    Downsampled basemap during load: {new_w}x{new_h} (scale: {scale:.3f})\")\n",
    "            else:\n",
    "                print(f\"  \u274c Basemap image not found for {res_name} resolution\")\n",
    "                continue\n",
    "        \n",
    "        # Load ortho image\n",
    "        if res_name in converted_files and ortho_name in converted_files[res_name]:\n",
    "            ortho_img = converted_files[res_name][ortho_name]['img']\n",
    "        else:\n",
    "            # Load from disk\n",
    "            ortho_jpeg = converted_dir / f\"{ortho_name}_{res_name}.jpg\"\n",
    "            ortho_png = converted_dir / f\"{ortho_name}_{res_name}.png\"\n",
    "            if ortho_png.exists():\n",
    "                ortho_img = np.array(Image.open(ortho_png))\n",
    "            \n",
    "            # Immediately downsample if too large to prevent memory issues\n",
    "            max_load_dimension = 3000  # Downsample during load\n",
    "            if ortho_img.shape[0] > max_load_dimension or ortho_img.shape[1] > max_load_dimension:\n",
    "                scale = min(max_load_dimension / ortho_img.shape[0], max_load_dimension / ortho_img.shape[1])\n",
    "                new_h = int(ortho_img.shape[0] * scale)\n",
    "                new_w = int(ortho_img.shape[1] * scale)\n",
    "                import cv2\n",
    "                ortho_img = cv2.resize(ortho_img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "                print(f\"    Downsampled {ortho_name} during load: {new_w}x{new_h} (scale: {scale:.3f})\")\n",
    "            elif ortho_jpeg.exists():\n",
    "                ortho_img = np.array(Image.open(ortho_jpeg))\n",
    "            \n",
    "            # Immediately downsample if too large to prevent memory issues\n",
    "            max_load_dimension = 3000  # Downsample during load\n",
    "            if ortho_img.shape[0] > max_load_dimension or ortho_img.shape[1] > max_load_dimension:\n",
    "                scale = min(max_load_dimension / ortho_img.shape[0], max_load_dimension / ortho_img.shape[1])\n",
    "                new_h = int(ortho_img.shape[0] * scale)\n",
    "                new_w = int(ortho_img.shape[1] * scale)\n",
    "                import cv2\n",
    "                ortho_img = cv2.resize(ortho_img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "                print(f\"    Downsampled {ortho_name} during load: {new_w}x{new_h} (scale: {scale:.3f})\")\n",
    "            else:\n",
    "                print(f\"  \u274c Ortho image not found for {ortho_name} at {res_name} resolution\")\n",
    "                continue\n",
    "        \n",
    "        print(f\"  Basemap: {basemap_img.shape[1]}x{basemap_img.shape[0]}\")\n",
    "        print(f\"  Ortho: {ortho_img.shape[1]}x{ortho_img.shape[0]}\")\n",
    "        \n",
    "        # Perform matching\n",
    "        # Use tile-based matching for memory efficiency\n",
    "        result = perform_tile_based_orb_matching(ortho_img, basemap_img, tile_size=1500, overlap=300, max_features=1000)\n",
    "        \n",
    "        # Clean up memory\n",
    "        import gc\n",
    "        del basemap_img, ortho_img\n",
    "        gc.collect()\n",
    "        \n",
    "        print(f\"  Keypoints (ortho): {result['num_keypoints1']}\")\n",
    "        print(f\"  Keypoints (basemap): {result['num_keypoints2']}\")\n",
    "        print(f\"  Matches: {result['num_matches']}\")\n",
    "        print(f\"  Inliers: {result['num_inliers']}\")\n",
    "        \n",
    "        if result['offset_x'] is not None:\n",
    "            print(f\"  Offset X: {result['offset_x']:.2f} px\")\n",
    "            print(f\"  Offset Y: {result['offset_y']:.2f} px\")\n",
    "            print(f\"  RMSE 2D: {result['rmse_2d']:.2f} px\")\n",
    "            print(f\"  Confidence: {result['confidence']:.3f}\")\n",
    "            \n",
    "            # Scale offsets back to full resolution\n",
    "            result['offset_x_full'] = result['offset_x'] / factor\n",
    "            result['offset_y_full'] = result['offset_y'] / factor\n",
    "            result['rmse_2d_full'] = result['rmse_2d'] / factor if result['rmse_2d'] else None\n",
    "        else:\n",
    "            print(f\"  \u26a0\ufe0f  Matching failed: {result.get('error', 'Unknown error')}\")\n",
    "        \n",
    "        matching_results[ortho_name][res_name] = result\n",
    "        \n",
    "        # Save matching visualization\n",
    "        if result['num_matches'] > 0:\n",
    "            vis_path = matches_dir / f\"{ortho_name}_{res_name}_matches.jpg\"\n",
    "            \n",
    "            # Create visualization\n",
    "            img_matches = cv2.drawMatches(\n",
    "                ortho_img, result['kp1'],\n",
    "                basemap_img, result['kp2'],\n",
    "                result['good_matches'][:50],  # Show first 50 matches\n",
    "                None,\n",
    "                flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS\n",
    "            )\n",
    "            \n",
    "            cv2.imwrite(str(vis_path), img_matches)\n",
    "            print(f\"  \u2713 Saved visualization: {vis_path}\")\n",
    "\n",
    "print(f\"\\n\u2713 Feature matching complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 5: Perform Feature Matching\n",
    "\n",
    "# Perform matching at different resolutions\n",
    "# Use pre-saved JPEG files at each resolution\n",
    "# Note: Only quarter resolution (half skipped due to memory)\n",
    "resolutions = {\n",
    "    # 'full': 1.0,  # Skipped - too large for memory\n",
    "    # 'half': 0.5,  # Skipped - too large, causes kernel crashes\n",
    "    'quarter': 0.25\n",
    "}\n",
    "\n",
    "# Ensure required variables and imports are available\n",
    "try:\n",
    "    import numpy as np\n",
    "    from PIL import Image\n",
    "    from pathlib import Path\n",
    "    import cv2\n",
    "    from typing import Dict\n",
    "except (NameError, ImportError):\n",
    "    import numpy as np\n",
    "    from PIL import Image\n",
    "    from pathlib import Path\n",
    "    import cv2\n",
    "    from typing import Dict\n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = None  # Disable decompression bomb protection\n",
    "\n",
    "# Ensure converted_dir is defined\n",
    "try:\n",
    "    _ = converted_dir\n",
    "except NameError:\n",
    "    try:\n",
    "        _ = output_dir\n",
    "    except NameError:\n",
    "        output_dir = Path(\"outputs\")\n",
    "    converted_dir = output_dir / \"test_matching\" / \"converted\"\n",
    "    print(f\"\u2139\ufe0f  converted_dir not defined, using default: {converted_dir}\")\n",
    "\n",
    "# Ensure matches_dir is defined\n",
    "try:\n",
    "    _ = matches_dir\n",
    "except NameError:\n",
    "    try:\n",
    "        _ = output_dir\n",
    "    except NameError:\n",
    "        output_dir = Path(\"outputs\")\n",
    "    matches_dir = output_dir / \"test_matching\" / \"matches\"\n",
    "    matches_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"\u2139\ufe0f  matches_dir not defined, using default: {matches_dir}\")\n",
    "\n",
    "matching_results = {}\n",
    "\n",
    "for ortho_name in ['no_gcps', 'with_gcps']:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Matching {ortho_name} to basemap\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    matching_results[ortho_name] = {}\n",
    "    \n",
    "    for res_name, factor in resolutions.items():\n",
    "        print(f\"\\n\ud83d\udcca Resolution: {res_name} (factor: {factor})\")\n",
    "        \n",
    "        # Load pre-saved images at this resolution\n",
    "        # Check if converted_files is available, otherwise load from disk\n",
    "        try:\n",
    "            _ = converted_files\n",
    "        except NameError:\n",
    "            print(\"  \u26a0\ufe0f  converted_files not defined, loading from disk...\")\n",
    "            converted_files = {}\n",
    "        \n",
    "        # Load basemap image\n",
    "        if res_name in converted_files and 'basemap' in converted_files[res_name]:\n",
    "            basemap_img = converted_files[res_name]['basemap']['img']\n",
    "        else:\n",
    "            # Load from disk\n",
    "            basemap_jpeg = converted_dir / f\"basemap_{res_name}.jpg\"\n",
    "            basemap_png = converted_dir / f\"basemap_{res_name}.png\"\n",
    "            if basemap_png.exists():\n",
    "                basemap_img = np.array(Image.open(basemap_png))\n",
    "            elif basemap_jpeg.exists():\n",
    "                basemap_img = np.array(Image.open(basemap_jpeg))\n",
    "            else:\n",
    "                print(f\"  \u274c Basemap image not found for {res_name} resolution\")\n",
    "                continue\n",
    "        \n",
    "        # Load ortho image\n",
    "        if res_name in converted_files and ortho_name in converted_files[res_name]:\n",
    "            ortho_img = converted_files[res_name][ortho_name]['img']\n",
    "        else:\n",
    "            # Load from disk\n",
    "            ortho_jpeg = converted_dir / f\"{ortho_name}_{res_name}.jpg\"\n",
    "            ortho_png = converted_dir / f\"{ortho_name}_{res_name}.png\"\n",
    "            if ortho_png.exists():\n",
    "                ortho_img = np.array(Image.open(ortho_png))\n",
    "            elif ortho_jpeg.exists():\n",
    "                ortho_img = np.array(Image.open(ortho_jpeg))\n",
    "            else:\n",
    "                print(f\"  \u274c Ortho image not found for {ortho_name} at {res_name} resolution\")\n",
    "                continue\n",
    "        \n",
    "        print(f\"  Basemap: {basemap_img.shape[1]}x{basemap_img.shape[0]}\")\n",
    "        print(f\"  Ortho: {ortho_img.shape[1]}x{ortho_img.shape[0]}\")\n",
    "        \n",
    "        # Perform matching using tile-based ORB\n",
    "        result = perform_tile_based_orb_matching(ortho_img, basemap_img, tile_size=4000, overlap=800, max_features=2000)\n",
    "        \n",
    "        # Clean up memory\n",
    "        import gc\n",
    "        del basemap_img, ortho_img\n",
    "        gc.collect()\n",
    "        \n",
    "        print(f\"  Keypoints (ortho): {result['num_keypoints1']}\")\n",
    "        print(f\"  Keypoints (basemap): {result['num_keypoints2']}\")\n",
    "        print(f\"  Matches: {result['num_matches']}\")\n",
    "        print(f\"  Inliers: {result['num_inliers']}\")\n",
    "        \n",
    "        if result['offset_x'] is not None:\n",
    "            print(f\"  Offset X: {result['offset_x']:.2f} px\")\n",
    "            print(f\"  Offset Y: {result['offset_y']:.2f} px\")\n",
    "            print(f\"  RMSE 2D: {result['rmse_2d']:.2f} px\")\n",
    "            print(f\"  Confidence: {result['confidence']:.3f}\")\n",
    "            \n",
    "            # Scale offsets back to full resolution\n",
    "            result['offset_x_full'] = result['offset_x'] / factor\n",
    "            result['offset_y_full'] = result['offset_y'] / factor\n",
    "            result['rmse_2d_full'] = result['rmse_2d'] / factor if result['rmse_2d'] else None\n",
    "        else:\n",
    "            print(f\"  \u26a0\ufe0f  Matching failed: {result.get('error', 'Unknown error')}\")\n",
    "        \n",
    "        matching_results[ortho_name][res_name] = result\n",
    "\n",
    "print(f\"\\n\u2713 Feature matching complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u26a0\ufe0f  Required variables not defined. Please run previous cells first.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'matching_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Ensure required variables are defined\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 12\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mmatching_results\u001b[49m\n\u001b[1;32m     13\u001b[0m     _ \u001b[38;5;241m=\u001b[39m resolutions\n\u001b[1;32m     14\u001b[0m     _ \u001b[38;5;241m=\u001b[39m matches_dir\n",
      "\u001b[0;31mNameError\u001b[0m: name 'matching_results' is not defined"
     ]
    }
   ],
   "source": [
    "# Create summary visualization\n",
    "# Ensure imports are available\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    from pathlib import Path\n",
    "except (NameError, ImportError):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from pathlib import Path\n",
    "\n",
    "# Ensure required variables are defined\n",
    "try:\n",
    "    _ = matching_results\n",
    "except NameError:\n",
    "    print(\"\u26a0\ufe0f  matching_results not defined. Please run Step 5 (matching loop) first.\")\n",
    "    print(\"   Skipping visualization...\")\n",
    "    matching_results = {}\n",
    "\n",
    "try:\n",
    "    _ = resolutions\n",
    "except NameError:\n",
    "    resolutions = {'quarter': 0.25}  # Default\n",
    "\n",
    "try:\n",
    "    _ = matches_dir\n",
    "except NameError:\n",
    "    try:\n",
    "        _ = output_dir\n",
    "    except NameError:\n",
    "        output_dir = Path(\"outputs\")\n",
    "    matches_dir = output_dir / \"test_matching\" / \"matches\"\n",
    "    matches_dir.mkdir(parents=True, exist_ok=True)\n",
    "try:\n",
    "    _ = matching_results\n",
    "    _ = resolutions\n",
    "    _ = matches_dir\n",
    "    print(\"\u26a0\ufe0f  Required variables not defined. Please run previous cells first.\")\n",
    "\n",
    "# Determine subplot dimensions dynamically\n",
    "# Calculate max resolutions dynamically\n",
    "max_resolutions = 1\n",
    "for on in ['no_gcps', 'with_gcps']:\n",
    "    if on in matching_results:\n",
    "        num_res = len(matching_results[on].keys())\n",
    "        if num_res > max_resolutions:\n",
    "            max_resolutions = num_res\n",
    "\n",
    "# Check if we have any results to visualize\n",
    "has_results = False\n",
    "if matching_results:\n",
    "    for on in ['no_gcps', 'with_gcps']:\n",
    "        if on in matching_results and matching_results[on]:\n",
    "            has_results = True\n",
    "            break\n",
    "\n",
    "if not has_results:\n",
    "    print(\"\u26a0\ufe0f  No matching results available. Please run Step 5 (matching loop) first.\")\n",
    "    fig, axes = plt.subplots(2, max_resolutions, figsize=(6*max_resolutions, 12))\n",
    "    if max_resolutions == 1:\n",
    "        axes = axes.reshape(2, 1)  # Ensure 2D array for indexing\n",
    "    fig.suptitle('SIFT Feature Matching Results at Different Resolutions', fontsize=16, fontweight='bold')\n",
    "\n",
    "for ortho_idx, ortho_name in enumerate(['no_gcps', 'with_gcps']):\n",
    "    # Get available resolutions for this ortho\n",
    "    available_resolutions = list(matching_results[ortho_name].keys()) if ortho_name in matching_results else []\n",
    "    for res_idx, res_name in enumerate(available_resolutions):\n",
    "        if res_name not in matching_results[ortho_name]:\n",
    "            continue\n",
    "        # Get factor for this resolution\n",
    "        factor = resolutions.get(res_name, 0.25)  # Default to quarter if not found\n",
    "        ax = axes[ortho_idx, res_idx]\n",
    "        \n",
    "        result = matching_results[ortho_name][res_name]\n",
    "        \n",
    "        if result['num_matches'] > 0 and result['offset_x'] is not None:\n",
    "            # Load visualization if it exists\n",
    "            vis_path = matches_dir / f\"{ortho_name}_{res_name}_matches.jpg\"\n",
    "            if vis_path.exists():\n",
    "                vis_img = plt.imread(vis_path)\n",
    "                ax.imshow(vis_img)\n",
    "                ax.axis('off')\n",
    "                \n",
    "                title = f\"{ortho_name.replace('_', ' ').title()} - {res_name.title()}\\n\"\n",
    "                title += f\"Matches: {result['num_matches']}, \"\n",
    "                title += f\"Offset: ({result['offset_x']:.1f}, {result['offset_y']:.1f}) px\"\n",
    "                ax.set_title(title, fontsize=10)\n",
    "            else:\n",
    "                ax.text(0.5, 0.5, f\"No visualization\\navailable\", \n",
    "                       ha='center', va='center', transform=ax.transAxes)\n",
    "                ax.set_title(f\"{ortho_name} - {res_name}\", fontsize=10)\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, f\"No matches found\\n{result.get('error', '')}\", \n",
    "                   ha='center', va='center', transform=ax.transAxes)\n",
    "            ax.set_title(f\"{ortho_name} - {res_name}\", fontsize=10)\n",
    "            ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "summary_vis_path = matches_dir / \"matching_summary.png\"\n",
    "plt.savefig(summary_vis_path, dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(f\"\u2713 Summary visualization saved: {summary_vis_path}\")\n",
    "\n",
    "# Print summary table\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Matching Results Summary\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for ortho_name in ['no_gcps', 'with_gcps']:\n",
    "    print(f\"\\n{ortho_name.replace('_', ' ').title()}:\")\n",
    "    print(f\"  {'Resolution':<12} {'Matches':<10} {'Offset X':<12} {'Offset Y':<12} {'RMSE 2D':<12} {'Confidence':<10}\")\n",
    "    print(f\"  {'-'*12} {'-'*10} {'-'*12} {'-'*12} {'-'*12} {'-'*10}\")\n",
    "    \n",
    "    for res_name in ['half', 'quarter']:  # Skip 'full'\n",
    "        result = matching_results[ortho_name][res_name]\n",
    "        matches = result['num_matches']\n",
    "        offset_x = f\"{result['offset_x']:.2f}\" if result['offset_x'] is not None else \"N/A\"\n",
    "        offset_y = f\"{result['offset_y']:.2f}\" if result['offset_y'] is not None else \"N/A\"\n",
    "        rmse = f\"{result['rmse_2d']:.2f}\" if result['rmse_2d'] is not None else \"N/A\"\n",
    "        conf = f\"{result['confidence']:.3f}\" if result['confidence'] else \"0.000\"\n",
    "        \n",
    "        print(f\"  {res_name:<12} {matches:<10} {offset_x:<12} {offset_y:<12} {rmse:<12} {conf:<10}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Apply 2D Shift and Register Orthomosaics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure imports are available\n",
    "try:\n",
    "    import numpy as np\n",
    "    from typing import Tuple\n",
    "except (NameError, ImportError):\n",
    "    import numpy as np\n",
    "    from typing import Tuple\n",
    "\n",
    "def apply_2d_shift_to_image(img: np.ndarray, shift_x: float, shift_y: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply 2D shift to an image.\n",
    "    \n",
    "    Args:\n",
    "        img: Input image array\n",
    "        shift_x: Shift in X direction (pixels)\n",
    "        shift_y: Shift in Y direction (pixels)\n",
    "        \n",
    "    Returns:\n",
    "        Shifted image\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from scipy.ndimage import shift\n",
    "        use_scipy = True\n",
    "    except ImportError:\n",
    "        use_scipy = False\n",
    "    \n",
    "    if use_scipy:\n",
    "        if len(img.shape) == 3:\n",
    "            # RGB image\n",
    "            shifted = np.zeros_like(img)\n",
    "            for i in range(img.shape[2]):\n",
    "                shifted[:, :, i] = shift(img[:, :, i], (shift_y, shift_x), mode='constant', cval=0, order=1)\n",
    "        else:\n",
    "            # Grayscale\n",
    "            shifted = shift(img, (shift_y, shift_x), mode='constant', cval=0, order=1)\n",
    "    else:\n",
    "        # Fallback: integer shift using numpy\n",
    "        shift_x_int = int(round(shift_x))\n",
    "        shift_y_int = int(round(shift_y))\n",
    "        \n",
    "        if len(img.shape) == 3:\n",
    "            shifted = np.zeros_like(img)\n",
    "            h, w = img.shape[:2]\n",
    "            if shift_y_int >= 0 and shift_x_int >= 0:\n",
    "                shifted[shift_y_int:, shift_x_int:] = img[:h-shift_y_int, :w-shift_x_int]\n",
    "            elif shift_y_int < 0 and shift_x_int < 0:\n",
    "                shifted[:h+shift_y_int, :w+shift_x_int] = img[-shift_y_int:, -shift_x_int:]\n",
    "            else:\n",
    "                # Handle other cases\n",
    "                if shift_y_int >= 0:\n",
    "                    shifted[shift_y_int:, :] = img[:h-shift_y_int, :]\n",
    "                if shift_x_int >= 0:\n",
    "                    shifted[:, shift_x_int:] = img[:, :w-shift_x_int]\n",
    "        else:\n",
    "            shifted = np.zeros_like(img)\n",
    "            h, w = img.shape\n",
    "            if shift_y_int >= 0 and shift_x_int >= 0:\n",
    "                shifted[shift_y_int:, shift_x_int:] = img[:h-shift_y_int, :w-shift_x_int]\n",
    "            elif shift_y_int < 0 and shift_x_int < 0:\n",
    "                shifted[:h+shift_y_int, :w+shift_x_int] = img[-shift_y_int:, -shift_x_int:]\n",
    "    \n",
    "    return shifted\n",
    "\n",
    "# Choose best resolution for registration (prefer full res if available, otherwise use best match count)\n",
    "registered_orthos = {}\n",
    "\n",
    "for ortho_name in ['no_gcps', 'with_gcps']:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Registering {ortho_name}...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Find best resolution (prefer full, then highest match count)\n",
    "    best_res = None\n",
    "    best_matches = 0\n",
    "    \n",
    "    # Use available resolutions from matching_results\n",
    "    available_resolutions = [r for r in matching_results[ortho_name].keys()]\n",
    "    for res_name in available_resolutions:\n",
    "        result = matching_results[ortho_name][res_name]\n",
    "        if result['num_matches'] > best_matches and result['offset_x'] is not None:\n",
    "            best_matches = result['num_matches']\n",
    "            best_res = res_name\n",
    "    \n",
    "    if best_res is None:\n",
    "        print(f\"  \u26a0\ufe0f  No valid matches found for {ortho_name}\")\n",
    "        continue\n",
    "    \n",
    "    result = matching_results[ortho_name][best_res]\n",
    "    print(f\"  Using {best_res} resolution results (matches: {result['num_matches']})\")\n",
    "    \n",
    "    # Get offset scaled to the resolution we'll use for registration\n",
    "    # Scale offsets back to the resolution we're using (half or quarter)\n",
    "    if resolution_used_for_registration == 'half':\n",
    "        scale_factor = 0.5\n",
    "    else:  # quarter\n",
    "        scale_factor = 0.25\n",
    "    \n",
    "    # The offsets from matching are already at the matching resolution\n",
    "    # Scale them to the registration resolution\n",
    "    shift_x = result['offset_x'] / scale_factor if result['offset_x'] is not None else 0\n",
    "    shift_y = result['offset_y'] / scale_factor if result['offset_y'] is not None else 0\n",
    "    \n",
    "    print(f\"  Applying shift: X={shift_x:.2f} px, Y={shift_y:.2f} px\")\n",
    "    \n",
    "    # Load full resolution image\n",
    "    # Load highest available resolution image (prefer half, fallback to quarter)\n",
    "    # Full resolution skipped due to memory constraints\n",
    "    if 'half' in converted_files and ortho_name in converted_files['half']:\n",
    "        ortho_img = converted_files['half'][ortho_name]['img']\n",
    "        resolution_used_for_registration = 'half'\n",
    "    elif 'quarter' in converted_files and ortho_name in converted_files['quarter']:\n",
    "        ortho_img = converted_files['quarter'][ortho_name]['img']\n",
    "        resolution_used_for_registration = 'quarter'\n",
    "    else:\n",
    "        print(f\"  \u26a0\ufe0f  No converted images found for {ortho_name}\")\n",
    "        continue\n",
    "    # Apply shift\n",
    "    shifted_img = apply_2d_shift_to_image(ortho_img, shift_x, shift_y)\n",
    "    \n",
    "    # Save registered image\n",
    "    registered_path = registered_dir / f\"{ortho_name}_registered.jpg\"\n",
    "    \n",
    "    if len(shifted_img.shape) == 3:\n",
    "        img_pil = Image.fromarray(shifted_img)\n",
    "    else:\n",
    "        img_pil = Image.fromarray(shifted_img).convert('RGB')\n",
    "    \n",
    "    img_pil.save(registered_path, 'JPEG', quality=95)\n",
    "    print(f\"  \u2713 Saved registered image: {registered_path}\")\n",
    "    \n",
    "    registered_orthos[ortho_name] = {\n",
    "        'path': registered_path,\n",
    "        'img': shifted_img,\n",
    "        'shift_x': shift_x,\n",
    "        'shift_y': shift_y,\n",
    "        'resolution_used': best_res\n",
    "    }\n",
    "\n",
    "print(f\"\\n\u2713 Registration complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Create Final Visualizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure imports are available\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import cv2\n",
    "    from pathlib import Path\n",
    "except (NameError, ImportError):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import cv2\n",
    "    from pathlib import Path\n",
    "\n",
    "# Create side-by-side comparison: original vs registered\n",
    "for ortho_name in ['no_gcps', 'with_gcps']:\n",
    "    if ortho_name not in registered_orthos:\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nCreating visualization for {ortho_name}...\")\n",
    "    \n",
    "    # Load images (use full resolution)\n",
    "    # Load images (use highest available resolution - half or quarter)\n",
    "    if 'half' in converted_files and ortho_name in converted_files['half']:\n",
    "        resolution_key = 'half'\n",
    "    elif 'quarter' in converted_files and ortho_name in converted_files['quarter']:\n",
    "        resolution_key = 'quarter'\n",
    "    else:\n",
    "        print(f\"  \u26a0\ufe0f  No converted images found for {ortho_name}, skipping visualization\")\n",
    "        continue\n",
    "    \n",
    "    original_img = converted_files[resolution_key][ortho_name]['img']\n",
    "    registered_img = registered_orthos[ortho_name]['img']\n",
    "    basemap_img = converted_files[resolution_key]['basemap']['img']\n",
    "    \n",
    "    # Resize to same size for comparison (use smallest)\n",
    "    min_h = min(original_img.shape[0], registered_img.shape[0], basemap_img.shape[0])\n",
    "    min_w = min(original_img.shape[1], registered_img.shape[1], basemap_img.shape[1])\n",
    "    \n",
    "    original_resized = cv2.resize(original_img, (min_w, min_h))\n",
    "    registered_resized = cv2.resize(registered_img, (min_w, min_h))\n",
    "    basemap_resized = cv2.resize(basemap_img, (min_w, min_h))\n",
    "    \n",
    "    # Create comparison figure\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 16))\n",
    "    fig.suptitle(f'Registration Results: {ortho_name.replace(\"_\", \" \").title()}', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Basemap (ground truth)\n",
    "    axes[0, 0].imshow(basemap_resized)\n",
    "    axes[0, 0].set_title('Ground Truth Basemap', fontweight='bold')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # Original ortho\n",
    "    axes[0, 1].imshow(original_resized)\n",
    "    axes[0, 1].set_title('Original Orthomosaic', fontweight='bold')\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    # Registered ortho\n",
    "    axes[1, 0].imshow(registered_resized)\n",
    "    shift_info = registered_orthos[ortho_name]\n",
    "    title = f\"Registered Orthomosaic\\n\"\n",
    "    title += f\"Shift: ({shift_info['shift_x']:.2f}, {shift_info['shift_y']:.2f}) px\\n\"\n",
    "    title += f\"Resolution: {shift_info['resolution_used']}\"\n",
    "    axes[1, 0].set_title(title, fontweight='bold')\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    # Difference map\n",
    "    diff = np.abs(registered_resized.astype(float) - basemap_resized.astype(float))\n",
    "    diff_norm = (diff / diff.max() * 255).astype(np.uint8) if diff.max() > 0 else diff.astype(np.uint8)\n",
    "    axes[1, 1].imshow(diff_norm, cmap='hot')\n",
    "    axes[1, 1].set_title('Difference Map (Registered vs Basemap)', fontweight='bold')\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    comparison_path = registered_dir / f\"{ortho_name}_comparison.png\"\n",
    "    plt.savefig(comparison_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"  \u2713 Saved comparison: {comparison_path}\")\n",
    "\n",
    "# Save matching results to JSON\n",
    "results_json_path = matching_output_dir / \"matching_results.json\"\n",
    "\n",
    "def convert_to_native(obj):\n",
    "    \"\"\"Convert numpy types to native Python types for JSON.\"\"\"\n",
    "    if isinstance(obj, np.integer):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, np.floating):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: convert_to_native(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_native(item) for item in obj]\n",
    "    elif hasattr(obj, '__dict__'):\n",
    "        # Handle OpenCV keypoints (skip them for JSON)\n",
    "        return None\n",
    "    return obj\n",
    "\n",
    "# Clean results for JSON (remove OpenCV objects)\n",
    "json_results = {}\n",
    "for ortho_name in matching_results:\n",
    "    json_results[ortho_name] = {}\n",
    "    for res_name in matching_results[ortho_name]:\n",
    "        result = matching_results[ortho_name][res_name].copy()\n",
    "        # Remove OpenCV objects\n",
    "        result.pop('kp1', None)\n",
    "        result.pop('kp2', None)\n",
    "        result.pop('good_matches', None)\n",
    "        json_results[ortho_name][res_name] = convert_to_native(result)\n",
    "\n",
    "with open(results_json_path, 'w') as f:\n",
    "    json.dump(json_results, f, indent=2)\n",
    "\n",
    "print(f\"\\n\u2713 Results saved to: {results_json_path}\")\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"\u2713 Feature Matching and Registration Complete!\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}