{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCP-Based Patch Matching for Orthomosaic Registration\n",
    "\n",
    "This notebook performs patch matching to find ground control points (GCPs) in orthomosaics and uses them to register the orthos to the basemap.\n",
    "\n",
    "## Approach:\n",
    "1. Load GCPs from CSV file (WGS84 coordinates)\n",
    "2. Extract patches from basemap centered on each GCP\n",
    "3. Use template matching to find corresponding patches in orthomosaics\n",
    "4. Compute 2D shift or affine transformation from matches\n",
    "5. Apply transformation to register orthos to basemap\n",
    "6. Evaluate accuracy improvement\n",
    "\n",
    "## Inputs:\n",
    "- **Basemap**: `TestsiteNewWest_Spexigeo_RTK.tiff`\n",
    "- **GCPs**: `25-3288-CONTROL-NAD83-UTM10N-EGM2008.csv` (converted to WGS84)\n",
    "- **Orthomosaics**: \n",
    "  - `outputs/orthomosaics/orthomosaic_no_gcps.tif`\n",
    "  - `outputs/orthomosaics/orthomosaic_with_gcps.tif`\n",
    "\n",
    "## Outputs:\n",
    "- All outputs saved to `outputs/gcp_matching/`\n",
    "- Patches extracted from basemap\n",
    "- Matched GCP locations in orthos\n",
    "- Registered orthomosaics\n",
    "- Accuracy evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if needed\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "packages = [\n",
    "    'rasterio',\n",
    "    'numpy',\n",
    "    'matplotlib',\n",
    "    'opencv-python',\n",
    "    'scipy',\n",
    "    'utm',\n",
    "    'pillow'\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    try:\n",
    "        __import__(package.replace('-', '_'))\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])\n",
    "\n",
    "print(\"\u2713 Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup - Imports and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.transform import xy\n",
    "from rasterio.warp import transform as transform_coords\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "import json\n",
    "import csv\n",
    "import utm\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup paths\n",
    "data_dir = Path(\"/Users/mauriciohessflores/Documents/Code/Data/New Westminster Oct _25\")\n",
    "output_dir = Path(\"outputs\")\n",
    "\n",
    "# Input files\n",
    "basemap_path = data_dir / \"Michael_RTK_orthos\" / \"TestsiteNewWest_Spexigeo_RTK.tiff\"\n",
    "gcp_csv_path = data_dir / \"25-3288-CONTROL-NAD83-UTM10N-EGM2008.csv\"\n",
    "ortho_no_gcps_path = output_dir / \"orthomosaics\" / \"orthomosaic_no_gcps.tif\"\n",
    "ortho_with_gcps_path = output_dir / \"orthomosaics\" / \"orthomosaic_with_gcps.tif\"\n",
    "\n",
    "# Output directories\n",
    "gcp_matching_dir = output_dir / \"gcp_matching\"\n",
    "gcp_matching_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "patches_dir = gcp_matching_dir / \"patches\"\n",
    "patches_dir.mkdir(exist_ok=True)\n",
    "\n",
    "matches_dir = gcp_matching_dir / \"matches\"\n",
    "matches_dir.mkdir(exist_ok=True)\n",
    "\n",
    "registered_dir = gcp_matching_dir / \"registered\"\n",
    "registered_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"\u2713 Output directory: {gcp_matching_dir}\")\n",
    "print(f\"  - Patches: {patches_dir}\")\n",
    "print(f\"  - Matches: {matches_dir}\")\n",
    "print(f\"  - Registered: {registered_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Update paths for Colab\n",
    "data_dir = Path(\"/content/drive/MyDrive/Data/New Westminster Oct _25\")\n",
    "output_dir = Path(\"/content/drive/MyDrive/Code/MyCode/research-westminster_ground_truth_analysis/outputs\")\n",
    "\n",
    "# Update other paths accordingly\n",
    "basemap_path = data_dir / \"Michael_RTK_orthos\" / \"TestsiteNewWest_Spexigeo_RTK.tiff\"\n",
    "gcp_csv_path = data_dir / \"25-3288-CONTROL-NAD83-UTM10N-EGM2008.csv\"\n",
    "ortho_no_gcps_path = output_dir / \"orthomosaics\" / \"orthomosaic_no_gcps.tif\"\n",
    "ortho_with_gcps_path = output_dir / \"orthomosaics\" / \"orthomosaic_with_gcps.tif\"\n",
    "\n",
    "print(\"\u2713 Colab paths configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load GCPs from CSV and Convert to WGS84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 Loaded 0 GCPs from CSV\n",
      "\n",
      "First few GCPs:\n"
     ]
    }
   ],
   "source": [
    "# Load GCPs from CSV file and convert to WGS84\n",
    "def load_gcps_from_csv(csv_path: Path) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Load GCPs from CSV file and convert to WGS84.\n",
    "    \n",
    "    Returns list of GCP dictionaries with 'id', 'lat', 'lon', 'x_utm', 'y_utm' keys.\n",
    "    \"\"\"\n",
    "    import csv\n",
    "    gcps = []\n",
    "    \n",
    "    with open(csv_path, 'r') as f:\n",
    "        # Try to read as DictReader first\n",
    "        f.seek(0)\n",
    "        sample = f.read(1024)\n",
    "        f.seek(0)\n",
    "        \n",
    "        reader = csv.DictReader(f)\n",
    "        fieldnames = reader.fieldnames\n",
    "        \n",
    "        if fieldnames:\n",
    "            # Has headers - try to find relevant columns\n",
    "            name_col = None\n",
    "            x_col = None\n",
    "            y_col = None\n",
    "            \n",
    "            # Common column name variations\n",
    "            for col in fieldnames:\n",
    "                col_lower = col.lower().strip()\n",
    "                if 'name' in col_lower or 'id' in col_lower or 'point' in col_lower or 'label' in col_lower:\n",
    "                    name_col = col\n",
    "                elif 'east' in col_lower or ('x' in col_lower and 'utm' not in col_lower):\n",
    "                    x_col = col\n",
    "                elif 'north' in col_lower or ('y' in col_lower and 'utm' not in col_lower):\n",
    "                    y_col = col\n",
    "            \n",
    "            if name_col and x_col and y_col:\n",
    "                for row in reader:\n",
    "                    try:\n",
    "                        name = str(row[name_col]).strip()\n",
    "                        x_val = float(row[x_col])\n",
    "                        y_val = float(row[y_col])\n",
    "                        \n",
    "                        # Check if values are reasonable (UTM Zone 10N ranges)\n",
    "                        # Easting: 100,000 - 999,999\n",
    "                        # Northing: 0 - 10,000,000\n",
    "                        if 100000 <= x_val <= 999999 and 0 <= y_val <= 10000000:\n",
    "                            # x is easting, y is northing\n",
    "                            lat, lon = utm.to_latlon(x_val, y_val, 10, 'N')\n",
    "                        elif 100000 <= y_val <= 999999 and 0 <= x_val <= 10000000:\n",
    "                            # y is easting, x is northing (swapped)\n",
    "                            lat, lon = utm.to_latlon(y_val, x_val, 10, 'N')\n",
    "                        else:\n",
    "                            # Try both orderings\n",
    "                            try:\n",
    "                                lat, lon = utm.to_latlon(x_val, y_val, 10, 'N')\n",
    "                            except:\n",
    "                                lat, lon = utm.to_latlon(y_val, x_val, 10, 'N')\n",
    "                        \n",
    "                        gcps.append({\n",
    "                            'id': name,\n",
    "                            'lat': lat,\n",
    "                            'lon': lon,\n",
    "                            'x_utm': x_val,\n",
    "                            'y_utm': y_val\n",
    "                        })\n",
    "                    except (ValueError, KeyError) as e:\n",
    "                        print(f\"\u26a0\ufe0f  Skipping row: {e}\")\n",
    "                        continue\n",
    "            else:\n",
    "                print(f\"\u26a0\ufe0f  Could not find required columns. Found: {fieldnames}\")\n",
    "                print(f\"   Looking for: name/id, x/easting, y/northing\")\n",
    "        else:\n",
    "            # No headers - try positional format\n",
    "            f.seek(0)\n",
    "            reader = csv.reader(f)\n",
    "            rows = list(reader)\n",
    "            \n",
    "            # Try to detect format by analyzing first few rows\n",
    "            for row in rows:\n",
    "                if len(row) < 3:\n",
    "                    continue\n",
    "                try:\n",
    "                    # Try different column orders\n",
    "                    name = str(row[0]).strip()\n",
    "                    x_val = float(row[1])\n",
    "                    y_val = float(row[2])\n",
    "                    \n",
    "                    # Try both orderings\n",
    "                    try:\n",
    "                        if 100000 <= x_val <= 999999:\n",
    "                            lat, lon = utm.to_latlon(x_val, y_val, 10, 'N')\n",
    "                        else:\n",
    "                            lat, lon = utm.to_latlon(y_val, x_val, 10, 'N')\n",
    "                    except:\n",
    "                        continue\n",
    "                    \n",
    "                    gcps.append({\n",
    "                        'id': name,\n",
    "                        'lat': lat,\n",
    "                        'lon': lon,\n",
    "                        'x_utm': x_val,\n",
    "                        'y_utm': y_val\n",
    "                    })\n",
    "                except (ValueError, IndexError) as e:\n",
    "                    continue\n",
    "    \n",
    "    return gcps\n",
    "\n",
    "# Load GCPs\n",
    "gcps = load_gcps_from_csv(gcp_csv_path)\n",
    "print(f\"\u2713 Loaded {len(gcps)} GCPs from CSV\")\n",
    "if len(gcps) > 0:\n",
    "    print(f\"\\nFirst few GCPs:\")\n",
    "    for gcp in gcps[:3]:\n",
    "        print(f\"  {gcp['id']}: lat={gcp['lat']:.6f}, lon={gcp['lon']:.6f}\")\n",
    "else:\n",
    "    print(f\"\u26a0\ufe0f  No GCPs loaded! Check CSV format.\")\n",
    "    print(f\"   CSV path: {gcp_csv_path}\")\n",
    "    if gcp_csv_path.exists():\n",
    "        print(f\"   File exists. Showing first few lines:\")\n",
    "        with open(gcp_csv_path, 'r') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if i < 5:\n",
    "                    print(f\"     {line.strip()}\")\n",
    "                else:\n",
    "                    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Convert GCPs to Pixel Coordinates in Basemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert GCPs (WGS84) to pixel coordinates in basemap\n",
    "def gcp_to_pixel_coords(gcp_lat: float, gcp_lon: float, raster_path: Path) -> Optional[Tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    Convert GCP lat/lon to pixel coordinates in raster.\n",
    "    \n",
    "    Returns (col, row) or None if outside bounds.\n",
    "    \"\"\"\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        # Transform WGS84 to raster CRS\n",
    "        x, y = transform_coords(\n",
    "            'EPSG:4326',  # WGS84\n",
    "            src.crs,\n",
    "            [gcp_lon],\n",
    "            [gcp_lat]\n",
    "        )\n",
    "        \n",
    "        # Convert to pixel coordinates\n",
    "        row, col = rasterio.transform.rowcol(src.transform, x[0], y[0])\n",
    "        \n",
    "        # Check if within bounds\n",
    "        if 0 <= row < src.height and 0 <= col < src.width:\n",
    "            return (col, row)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "# Get basemap CRS and transform\n",
    "with rasterio.open(basemap_path) as basemap_src:\n",
    "    basemap_crs = basemap_src.crs\n",
    "    basemap_transform = basemap_src.transform\n",
    "    basemap_width = basemap_src.width\n",
    "    basemap_height = basemap_src.height\n",
    "\n",
    "print(f\"Basemap CRS: {basemap_crs}\")\n",
    "print(f\"Basemap dimensions: {basemap_width}x{basemap_height}\")\n",
    "\n",
    "# Convert all GCPs to pixel coordinates\n",
    "gcp_pixel_coords = {}\n",
    "for gcp in gcps:\n",
    "    pixel_coords = gcp_to_pixel_coords(gcp['lat'], gcp['lon'], basemap_path)\n",
    "    if pixel_coords:\n",
    "        gcp_pixel_coords[gcp['id']] = {\n",
    "            'gcp': gcp,\n",
    "            'pixel_col': pixel_coords[0],\n",
    "            'pixel_row': pixel_coords[1]\n",
    "        }\n",
    "    else:\n",
    "        print(f\"\u26a0\ufe0f  GCP {gcp['id']} is outside basemap bounds\")\n",
    "\n",
    "print(f\"\\n\u2713 Found {len(gcp_pixel_coords)} GCPs within basemap bounds\")\n",
    "print(f\"\\nFirst few GCP pixel coordinates:\")\n",
    "for gcp_id, coords in list(gcp_pixel_coords.items())[:3]:\n",
    "    print(f\"  {gcp_id}: col={coords['pixel_col']}, row={coords['pixel_row']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Extract Patches from Basemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract patches from basemap centered on GCPs\n",
    "def extract_patch(raster_path: Path, center_col: int, center_row: int, patch_size: int) -> Optional[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Extract a patch from raster centered on given pixel coordinates.\n",
    "    \n",
    "    Args:\n",
    "        raster_path: Path to raster file\n",
    "        center_col: Center column (x)\n",
    "        center_row: Center row (y)\n",
    "        patch_size: Size of patch (must be odd, e.g., 29, 39, 49)\n",
    "    \n",
    "    Returns:\n",
    "        Patch array (H, W, C) or None if out of bounds\n",
    "    \"\"\"\n",
    "    half_size = patch_size // 2\n",
    "    \n",
    "    with rasterio.open(raster_path) as src:\n",
    "        # Calculate bounds\n",
    "        col_start = max(0, center_col - half_size)\n",
    "        col_end = min(src.width, center_col + half_size + 1)\n",
    "        row_start = max(0, center_row - half_size)\n",
    "        row_end = min(src.height, center_row + half_size + 1)\n",
    "        \n",
    "        # Check if patch would be out of bounds\n",
    "        if col_end - col_start < patch_size or row_end - row_start < patch_size:\n",
    "            return None\n",
    "        \n",
    "        # Read patch\n",
    "        patch = src.read(\n",
    "            window=rasterio.windows.Window(col_start, row_start, col_end - col_start, row_end - row_start)\n",
    "        )\n",
    "        \n",
    "        # Transpose to (H, W, C) format\n",
    "        if len(patch.shape) == 3:\n",
    "            patch = np.transpose(patch, (1, 2, 0))\n",
    "        \n",
    "        # If single band, convert to 3-channel grayscale\n",
    "        if len(patch.shape) == 2:\n",
    "            patch = np.stack([patch, patch, patch], axis=-1)\n",
    "        \n",
    "        return patch\n",
    "\n",
    "# Extract patches for different patch sizes\n",
    "patch_sizes = [29, 39, 49, 59]  # Try different sizes\n",
    "basemap_patches = {}\n",
    "\n",
    "for patch_size in patch_sizes:\n",
    "    basemap_patches[patch_size] = {}\n",
    "    \n",
    "    for gcp_id, coords in gcp_pixel_coords.items():\n",
    "        patch = extract_patch(\n",
    "            basemap_path,\n",
    "            coords['pixel_col'],\n",
    "            coords['pixel_row'],\n",
    "            patch_size\n",
    "        )\n",
    "        \n",
    "        if patch is not None:\n",
    "            basemap_patches[patch_size][gcp_id] = patch\n",
    "            \n",
    "            # Save patch as image for visualization\n",
    "            patch_path = patches_dir / f\"basemap_{gcp_id}_{patch_size}x{patch_size}.png\"\n",
    "            plt.imsave(patch_path, patch.astype(np.uint8))\n",
    "    \n",
    "    print(f\"\u2713 Extracted {len(basemap_patches[patch_size])} patches of size {patch_size}x{patch_size}\")\n",
    "\n",
    "print(f\"\\n\u2713 Patch extraction complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Reproject Orthomosaics to Match Basemap CRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reprojecting no_gcps...\n"
     ]
    },
    {
     "ename": "CPLE_AppDefinedError",
     "evalue": "Too many points (10201 out of 10201) failed to transform, unable to compute output bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_AppDefinedError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 94\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mReprojecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mortho_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 94\u001b[0m     reprojected_path \u001b[38;5;241m=\u001b[39m \u001b[43mreproject_ortho_to_basemap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43mortho_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbasemap_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreprojected_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mortho_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_reprojected.tif\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m     reprojected_paths[ortho_name] \u001b[38;5;241m=\u001b[39m reprojected_path\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\u2713 Reprojection complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 33\u001b[0m, in \u001b[0;36mreproject_ortho_to_basemap\u001b[0;34m(ortho_path, basemap_path, output_path)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output_path\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Calculate transform\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m transform, width, height \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_default_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource_crs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_crs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_height\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtarget_bounds\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Read source data\u001b[39;00m\n\u001b[1;32m     42\u001b[0m source_data \u001b[38;5;241m=\u001b[39m ortho_src\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/rasterio/env.py:410\u001b[0m, in \u001b[0;36mensure_env.<locals>.wrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m local\u001b[38;5;241m.\u001b[39m_env:\n\u001b[0;32m--> 410\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    412\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m Env\u001b[38;5;241m.\u001b[39mfrom_defaults():\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/rasterio/warp.py:556\u001b[0m, in \u001b[0;36mcalculate_default_transform\u001b[0;34m(src_crs, dst_crs, width, height, left, bottom, right, top, gcps, rpcs, resolution, dst_width, dst_height, src_geoloc_array, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resolution \u001b[38;5;129;01mand\u001b[39;00m dimensions:\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResolution cannot be used with dst_width and dst_height.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 556\u001b[0m dst_affine, dst_width, dst_height \u001b[38;5;241m=\u001b[39m \u001b[43m_calculate_default_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m    \u001b[49m\u001b[43msrc_crs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdst_crs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m    \u001b[49m\u001b[43mleft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbottom\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbottom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mright\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgcps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgcps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrpcs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrpcs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43msrc_geoloc_array\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_geoloc_array\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;66;03m# If resolution is specified, Keep upper-left anchored\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;66;03m# adjust the transform resolutions\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;66;03m# adjust the width/height by the ratio of estimated:specified res (ceil'd)\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resolution:\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;66;03m# resolutions argument into tuple\u001b[39;00m\n",
      "File \u001b[0;32mrasterio/_warp.pyx:796\u001b[0m, in \u001b[0;36mrasterio._warp._calculate_default_transform\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mrasterio/_err.pyx:289\u001b[0m, in \u001b[0;36mrasterio._err.exc_wrap_int\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_AppDefinedError\u001b[0m: Too many points (10201 out of 10201) failed to transform, unable to compute output bounds."
     ]
    }
   ],
   "source": [
    "from rasterio.warp import calculate_default_transform, reproject, Resampling, transform_bounds\n",
    "from rasterio.transform import from_bounds\n",
    "from rasterio.enums import Resampling as RasterioResampling\n",
    "from affine import Affine\n",
    "\n",
    "# Reproject orthos to match basemap CRS and resolution\n",
    "def reproject_ortho_to_basemap(ortho_path: Path, basemap_path: Path, output_path: Path) -> Path:\n",
    "    \"\"\"\n",
    "    Reproject orthomosaic to match basemap CRS and bounds.\n",
    "    Uses manual transform construction to avoid CPLE_AppDefinedError.\n",
    "    \"\"\"\n",
    "    if output_path.exists():\n",
    "        print(f\"  \u2713 Already reprojected: {output_path}\")\n",
    "        return output_path\n",
    "    \n",
    "    with rasterio.open(basemap_path) as basemap_src:\n",
    "        target_crs = basemap_src.crs\n",
    "        target_bounds = basemap_src.bounds\n",
    "        target_transform = basemap_src.transform\n",
    "        target_width = basemap_src.width\n",
    "        target_height = basemap_src.height\n",
    "    \n",
    "    with rasterio.open(ortho_path) as ortho_src:\n",
    "        source_crs = ortho_src.crs\n",
    "        source_bounds = ortho_src.bounds\n",
    "        \n",
    "        if source_crs == target_crs:\n",
    "            print(f\"  \u2713 Already in target CRS\")\n",
    "            import shutil\n",
    "            shutil.copy(ortho_path, output_path)\n",
    "            return output_path\n",
    "        \n",
    "        # Transform source bounds to target CRS\n",
    "        print(f\"  Transforming source bounds to target CRS...\")\n",
    "        src_bounds_target_crs = transform_bounds(\n",
    "            source_crs, target_crs,\n",
    "            source_bounds.left, source_bounds.bottom,\n",
    "            source_bounds.right, source_bounds.top\n",
    "        )\n",
    "        \n",
    "        print(f\"  Source bounds in target CRS: {src_bounds_target_crs}\")\n",
    "        \n",
    "        # Get target pixel size\n",
    "        target_pixel_size_x = abs(target_transform[0])\n",
    "        target_pixel_size_y = abs(target_transform[4])\n",
    "        \n",
    "        # Use intersection of bounds\n",
    "        output_left = max(src_bounds_target_crs[0], target_bounds.left)\n",
    "        output_bottom = max(src_bounds_target_crs[1], target_bounds.bottom)\n",
    "        output_right = min(src_bounds_target_crs[2], target_bounds.right)\n",
    "        output_top = min(src_bounds_target_crs[3], target_bounds.top)\n",
    "        \n",
    "        print(f\"  Output bounds (intersection): left={output_left:.2f}, bottom={output_bottom:.2f}, right={output_right:.2f}, top={output_top:.2f}\")\n",
    "        \n",
    "        # Validate bounds\n",
    "        if output_right <= output_left or output_top <= output_bottom:\n",
    "            raise ValueError(f\"Invalid output bounds: width={output_right-output_left}, height={output_top-output_bottom}\")\n",
    "        \n",
    "        # Calculate dimensions using target pixel size\n",
    "        width = int((output_right - output_left) / target_pixel_size_x)\n",
    "        height = int((output_top - output_bottom) / target_pixel_size_y)\n",
    "        \n",
    "        # Validate dimensions\n",
    "        if width <= 0 or height <= 0:\n",
    "            raise ValueError(f\"Invalid dimensions: width={width}, height={height}\")\n",
    "        \n",
    "        # Create transform for output\n",
    "        transform = Affine.translation(output_left, output_top) * Affine.scale(target_pixel_size_x, -target_pixel_size_y)\n",
    "        \n",
    "        print(f\"  \u2713 Transform calculated: {width}x{height} pixels\")\n",
    "        \n",
    "        # Read source data\n",
    "        source_data = ortho_src.read()\n",
    "        source_count = ortho_src.count\n",
    "        \n",
    "        # Reproject\n",
    "        reprojected_data = np.zeros((source_count, height, width), dtype=source_data.dtype)\n",
    "        \n",
    "        for band_idx in range(1, source_count + 1):\n",
    "            reproject(\n",
    "                source=rasterio.band(ortho_src, band_idx),\n",
    "                destination=reprojected_data[band_idx - 1],\n",
    "                src_transform=ortho_src.transform,\n",
    "                src_crs=source_crs,\n",
    "                dst_transform=transform,\n",
    "                dst_crs=target_crs,\n",
    "                resampling=Resampling.bilinear\n",
    "            )\n",
    "        \n",
    "        # Save\n",
    "        with rasterio.open(\n",
    "            output_path,\n",
    "            'w',\n",
    "            driver='GTiff',\n",
    "            height=height,\n",
    "            width=width,\n",
    "            count=source_count,\n",
    "            dtype=reprojected_data.dtype,\n",
    "            crs=target_crs,\n",
    "            transform=transform,\n",
    "            compress='lzw',\n",
    "            BIGTIFF='YES',\n",
    "            tiled=True,\n",
    "            blockxsize=512,\n",
    "            blockysize=512\n",
    "        ) as dst:\n",
    "            dst.write(reprojected_data)\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "# Check for existing reprojected files from test_matching notebook\n",
    "existing_reprojected_dir = output_dir / \"test_matching\" / \"reprojected\"\n",
    "reprojected_dir = gcp_matching_dir / \"reprojected\"\n",
    "reprojected_dir.mkdir(exist_ok=True)\n",
    "\n",
    "ortho_paths = {\n",
    "    'no_gcps': ortho_no_gcps_path,\n",
    "    'with_gcps': ortho_with_gcps_path\n",
    "}\n",
    "\n",
    "reprojected_paths = {}\n",
    "for ortho_name, ortho_path in ortho_paths.items():\n",
    "    if not ortho_path.exists():\n",
    "        print(f\"\u26a0\ufe0f  Ortho not found: {ortho_path}\")\n",
    "        continue\n",
    "    \n",
    "    # Check for existing reprojected file from test_matching\n",
    "    existing_reprojected = existing_reprojected_dir / f\"{ortho_name}_reprojected.tif\"\n",
    "    if existing_reprojected.exists():\n",
    "        print(f\"\\nFound existing reprojected file: {existing_reprojected}\")\n",
    "        # Copy to our directory\n",
    "        import shutil\n",
    "        reprojected_path = reprojected_dir / f\"{ortho_name}_reprojected.tif\"\n",
    "        if not reprojected_path.exists():\n",
    "            shutil.copy(existing_reprojected, reprojected_path)\n",
    "            print(f\"  \u2713 Copied to: {reprojected_path}\")\n",
    "        else:\n",
    "            print(f\"  \u2713 Already exists: {reprojected_path}\")\n",
    "        reprojected_paths[ortho_name] = reprojected_path\n",
    "        continue\n",
    "    \n",
    "    # Otherwise, reproject\n",
    "    print(f\"\\nReprojecting {ortho_name}...\")\n",
    "    reprojected_path = reproject_ortho_to_basemap(\n",
    "        ortho_path,\n",
    "        basemap_path,\n",
    "        reprojected_dir / f\"{ortho_name}_reprojected.tif\"\n",
    "    )\n",
    "    reprojected_paths[ortho_name] = reprojected_path\n",
    "\n",
    "print(f\"\\n\u2713 Reprojection complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Find GCP Patches in Orthomosaics Using Template Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find GCP patches in orthomosaics using template matching\n",
    "def find_patch_in_ortho(\n",
    "    template_patch: np.ndarray,\n",
    "    ortho_path: Path,\n",
    "    search_center_col: int,\n",
    "    search_center_row: int,\n",
    "    search_radius: int = 500  # Search within this radius (pixels)\n",
    ") -> Optional[Tuple[int, int, float]]:\n",
    "    \"\"\"\n",
    "    Find template patch in orthomosaic using template matching.\n",
    "    \n",
    "    Returns:\n",
    "        (col, row, confidence) or None if not found\n",
    "    \"\"\"\n",
    "    # Convert template to grayscale if needed\n",
    "    if len(template_patch.shape) == 3:\n",
    "        template_gray = cv2.cvtColor(template_patch.astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        template_gray = template_patch.astype(np.uint8)\n",
    "    \n",
    "    with rasterio.open(ortho_path) as ortho_src:\n",
    "        # Define search window\n",
    "        search_col_start = max(0, search_center_col - search_radius)\n",
    "        search_col_end = min(ortho_src.width, search_center_col + search_radius)\n",
    "        search_row_start = max(0, search_center_row - search_radius)\n",
    "        search_row_end = min(ortho_src.height, search_center_row + search_radius)\n",
    "        \n",
    "        # Read search region\n",
    "        search_window = rasterio.windows.Window(\n",
    "            search_col_start,\n",
    "            search_row_start,\n",
    "            search_col_end - search_col_start,\n",
    "            search_row_end - search_row_start\n",
    "        )\n",
    "        \n",
    "        search_region = ortho_src.read(window=search_window)\n",
    "        \n",
    "        # Convert to (H, W, C) and then grayscale\n",
    "        if len(search_region.shape) == 3:\n",
    "            search_region = np.transpose(search_region, (1, 2, 0))\n",
    "            if search_region.shape[2] == 1:\n",
    "                search_gray = search_region[:, :, 0]\n",
    "            else:\n",
    "                search_gray = cv2.cvtColor(search_region.astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "        else:\n",
    "            search_gray = search_region\n",
    "        \n",
    "        # Normalize to uint8\n",
    "        if search_gray.dtype != np.uint8:\n",
    "            search_min = search_gray.min()\n",
    "            search_max = search_gray.max()\n",
    "            if search_max > search_min:\n",
    "                search_gray = ((search_gray - search_min) / (search_max - search_min) * 255).astype(np.uint8)\n",
    "            else:\n",
    "                search_gray = np.zeros_like(search_gray, dtype=np.uint8)\n",
    "        \n",
    "        # Template matching\n",
    "        result = cv2.matchTemplate(search_gray, template_gray, cv2.TM_CCOEFF_NORMED)\n",
    "        \n",
    "        # Find best match\n",
    "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "        \n",
    "        # Convert back to global coordinates\n",
    "        match_col = search_col_start + max_loc[0] + template_gray.shape[1] // 2\n",
    "        match_row = search_row_start + max_loc[1] + template_gray.shape[0] // 2\n",
    "        \n",
    "        # Return if confidence is high enough\n",
    "        if max_val > 0.5:  # Threshold for match confidence\n",
    "            return (match_col, match_row, float(max_val))\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "# Find GCPs in each orthomosaic\n",
    "matching_results = {}\n",
    "\n",
    "for ortho_name, reprojected_path in reprojected_paths.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Finding GCPs in {ortho_name} orthomosaic\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    matching_results[ortho_name] = {}\n",
    "    \n",
    "    # Get expected pixel coordinates in ortho (same as basemap if properly aligned)\n",
    "    with rasterio.open(reprojected_path) as ortho_src:\n",
    "        ortho_transform = ortho_src.transform\n",
    "    \n",
    "    # Try different patch sizes\n",
    "    best_patch_size = None\n",
    "    best_matches = 0\n",
    "    \n",
    "    for patch_size in patch_sizes:\n",
    "        matches_found = 0\n",
    "        \n",
    "        for gcp_id, coords in gcp_pixel_coords.items():\n",
    "            if gcp_id not in basemap_patches[patch_size]:\n",
    "                continue\n",
    "            \n",
    "            template = basemap_patches[patch_size][gcp_id]\n",
    "            \n",
    "            # Expected position in ortho (same as basemap if aligned)\n",
    "            expected_col = coords['pixel_col']\n",
    "            expected_row = coords['pixel_row']\n",
    "            \n",
    "            # Search for patch\n",
    "            match = find_patch_in_ortho(\n",
    "                template,\n",
    "                reprojected_path,\n",
    "                expected_col,\n",
    "                expected_row,\n",
    "                search_radius=500\n",
    "            )\n",
    "            \n",
    "            if match:\n",
    "                match_col, match_row, confidence = match\n",
    "                matches_found += 1\n",
    "                \n",
    "                if gcp_id not in matching_results[ortho_name]:\n",
    "                    matching_results[ortho_name][gcp_id] = {}\n",
    "                \n",
    "                matching_results[ortho_name][gcp_id][patch_size] = {\n",
    "                    'expected_col': expected_col,\n",
    "                    'expected_row': expected_row,\n",
    "                    'matched_col': match_col,\n",
    "                    'matched_row': match_row,\n",
    "                    'offset_col': match_col - expected_col,\n",
    "                    'offset_row': match_row - expected_row,\n",
    "                    'confidence': confidence\n",
    "                }\n",
    "        \n",
    "        print(f\"  Patch size {patch_size}x{patch_size}: {matches_found}/{len(gcp_pixel_coords)} matches\")\n",
    "        \n",
    "        if matches_found > best_matches:\n",
    "            best_matches = matches_found\n",
    "            best_patch_size = patch_size\n",
    "    \n",
    "    print(f\"\\n  \u2713 Best patch size: {best_patch_size}x{best_patch_size} ({best_matches} matches)\")\n",
    "\n",
    "print(f\"\\n\u2713 Patch matching complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Compute 2D Shift or Affine Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Compute transformation from matches\n",
    "def compute_transformation(matches: Dict, use_affine: bool = False) -> Dict:\n",
    "    \"\"\"\n",
    "    Compute 2D shift or affine transformation from GCP matches.\n",
    "    \n",
    "    Args:\n",
    "        matches: Dictionary with GCP matches\n",
    "        use_affine: If True, compute affine transformation; otherwise 2D shift\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with transformation parameters\n",
    "    \"\"\"\n",
    "    # Collect source and destination points\n",
    "    src_points = []\n",
    "    dst_points = []\n",
    "    \n",
    "    for gcp_id, match_data in matches.items():\n",
    "        # Use the best patch size match\n",
    "        best_patch_size = max(match_data.keys())\n",
    "        match = match_data[best_patch_size]\n",
    "        \n",
    "        src_points.append([match['expected_col'], match['expected_row']])\n",
    "        dst_points.append([match['matched_col'], match['matched_row']])\n",
    "    \n",
    "    src_points = np.array(src_points, dtype=np.float32)\n",
    "    dst_points = np.array(dst_points, dtype=np.float32)\n",
    "    \n",
    "    if len(src_points) < 2:\n",
    "        return {'type': 'insufficient_points', 'error': 'Need at least 2 matches'}\n",
    "    \n",
    "    if use_affine and len(src_points) >= 3:\n",
    "        # Compute affine transformation (6 parameters)\n",
    "        # Requires at least 3 points\n",
    "        transform_matrix = cv2.getAffineTransform(\n",
    "            src_points[:3],\n",
    "            dst_points[:3]\n",
    "        )\n",
    "        \n",
    "        # Apply to all points to compute error\n",
    "        ones = np.ones((len(src_points), 1))\n",
    "        src_homogeneous = np.hstack([src_points, ones])\n",
    "        transformed = (transform_matrix @ src_homogeneous.T).T\n",
    "        \n",
    "        errors = dst_points - transformed\n",
    "        rmse = float(np.sqrt(np.mean(errors**2)))\n",
    "        \n",
    "        return {\n",
    "            'type': 'affine',\n",
    "            'matrix': transform_matrix.tolist(),\n",
    "            'rmse': rmse,\n",
    "            'num_points': len(src_points)\n",
    "        }\n",
    "    else:\n",
    "        # Compute 2D shift (mean offset)\n",
    "        offsets = dst_points - src_points\n",
    "        shift_x = float(np.mean(offsets[:, 0]))\n",
    "        shift_y = float(np.mean(offsets[:, 1]))\n",
    "        \n",
    "        # Compute RMSE\n",
    "        errors = offsets - np.array([shift_x, shift_y])\n",
    "        rmse = float(np.sqrt(np.mean(errors**2)))\n",
    "        \n",
    "        return {\n",
    "            'type': 'shift',\n",
    "            'shift_x': shift_x,\n",
    "            'shift_y': shift_y,\n",
    "            'rmse': rmse,\n",
    "            'num_points': len(src_points)\n",
    "        }\n",
    "\n",
    "# Compute transformations for each ortho\n",
    "transformations = {}\n",
    "\n",
    "for ortho_name in matching_results.keys():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Computing transformation for {ortho_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Try 2D shift first\n",
    "    shift_result = compute_transformation(matching_results[ortho_name], use_affine=False)\n",
    "    print(f\"\\n2D Shift:\")\n",
    "    print(f\"  Shift X: {shift_result.get('shift_x', 'N/A'):.2f} px\")\n",
    "    print(f\"  Shift Y: {shift_result.get('shift_y', 'N/A'):.2f} px\")\n",
    "    print(f\"  RMSE: {shift_result.get('rmse', 'N/A'):.2f} px\")\n",
    "    print(f\"  Points: {shift_result.get('num_points', 0)}\")\n",
    "    \n",
    "    # Try affine if we have enough points\n",
    "    if len(matching_results[ortho_name]) >= 3:\n",
    "        affine_result = compute_transformation(matching_results[ortho_name], use_affine=True)\n",
    "        print(f\"\\nAffine Transformation:\")\n",
    "        print(f\"  RMSE: {affine_result.get('rmse', 'N/A'):.2f} px\")\n",
    "        print(f\"  Points: {affine_result.get('num_points', 0)}\")\n",
    "        \n",
    "        # Use the one with lower RMSE\n",
    "        if affine_result.get('rmse', float('inf')) < shift_result.get('rmse', float('inf')):\n",
    "            transformations[ortho_name] = affine_result\n",
    "            print(f\"  \u2713 Using affine transformation (lower RMSE)\")\n",
    "        else:\n",
    "            transformations[ortho_name] = shift_result\n",
    "            print(f\"  \u2713 Using 2D shift (lower RMSE)\")\n",
    "    else:\n",
    "        transformations[ortho_name] = shift_result\n",
    "        print(f\"  \u2713 Using 2D shift (insufficient points for affine)\")\n",
    "\n",
    "# Save transformations\n",
    "transformations_file = matches_dir / \"transformations.json\"\n",
    "with open(transformations_file, 'w') as f:\n",
    "    json.dump(transformations, f, indent=2)\n",
    "\n",
    "print(f\"\\n\u2713 Transformations saved to: {transformations_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Apply Transformation and Register Orthomosaics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply transformation to orthomosaic\n",
    "def apply_transformation(\n",
    "    ortho_path: Path,\n",
    "    transformation: Dict,\n",
    "    output_path: Path,\n",
    "    basemap_path: Path\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    Apply transformation to register orthomosaic to basemap.\n",
    "    \"\"\"\n",
    "    with rasterio.open(basemap_path) as basemap_src:\n",
    "        target_width = basemap_src.width\n",
    "        target_height = basemap_src.height\n",
    "        target_transform = basemap_src.transform\n",
    "        target_crs = basemap_src.crs\n",
    "    \n",
    "    with rasterio.open(ortho_path) as ortho_src:\n",
    "        source_data = ortho_src.read()\n",
    "        source_count = ortho_src.count\n",
    "        \n",
    "        # Apply transformation\n",
    "        if transformation['type'] == 'shift':\n",
    "            # Apply 2D shift using scipy\n",
    "            shift_x = transformation['shift_x']\n",
    "            shift_y = transformation['shift_y']\n",
    "            \n",
    "            registered_data = np.zeros((source_count, target_height, target_width), dtype=source_data.dtype)\n",
    "            \n",
    "            for band_idx in range(source_count):\n",
    "                shifted = ndimage.shift(\n",
    "                    source_data[band_idx],\n",
    "                    (shift_y, shift_x),\n",
    "                    mode='constant',\n",
    "                    cval=0,\n",
    "                    order=1\n",
    "                )\n",
    "                \n",
    "                # Crop or pad to match target dimensions\n",
    "                if shifted.shape[0] > target_height:\n",
    "                    shifted = shifted[:target_height, :]\n",
    "                elif shifted.shape[0] < target_height:\n",
    "                    padded = np.zeros((target_height, shifted.shape[1]), dtype=shifted.dtype)\n",
    "                    padded[:shifted.shape[0], :] = shifted\n",
    "                    shifted = padded\n",
    "                \n",
    "                if shifted.shape[1] > target_width:\n",
    "                    shifted = shifted[:, :target_width]\n",
    "                elif shifted.shape[1] < target_width:\n",
    "                    padded = np.zeros((target_height, target_width), dtype=shifted.dtype)\n",
    "                    padded[:, :shifted.shape[1]] = shifted\n",
    "                    shifted = padded\n",
    "                \n",
    "                registered_data[band_idx] = shifted\n",
    "        \n",
    "        elif transformation['type'] == 'affine':\n",
    "            # Apply affine transformation\n",
    "            transform_matrix = np.array(transformation['matrix'], dtype=np.float32)\n",
    "            \n",
    "            registered_data = np.zeros((source_count, target_height, target_width), dtype=source_data.dtype)\n",
    "            \n",
    "            # Convert to (H, W, C) for OpenCV\n",
    "            if source_count == 1:\n",
    "                img = source_data[0]\n",
    "            else:\n",
    "                img = np.transpose(source_data, (1, 2, 0))\n",
    "            \n",
    "            # Apply affine transform\n",
    "            registered_img = cv2.warpAffine(\n",
    "                img.astype(np.uint8),\n",
    "                transform_matrix,\n",
    "                (target_width, target_height),\n",
    "                flags=cv2.INTER_LINEAR,\n",
    "                borderMode=cv2.BORDER_CONSTANT,\n",
    "                borderValue=0\n",
    "            )\n",
    "            \n",
    "            # Convert back to (C, H, W)\n",
    "            if source_count == 1:\n",
    "                registered_data[0] = registered_img\n",
    "            else:\n",
    "                registered_data = np.transpose(registered_img, (2, 0, 1))\n",
    "        \n",
    "        # Save registered orthomosaic\n",
    "        with rasterio.open(\n",
    "            output_path,\n",
    "            'w',\n",
    "            driver='GTiff',\n",
    "            height=target_height,\n",
    "            width=target_width,\n",
    "            count=source_count,\n",
    "            dtype=registered_data.dtype,\n",
    "            crs=target_crs,\n",
    "            transform=target_transform,\n",
    "            compress='lzw',\n",
    "            BIGTIFF='YES',\n",
    "            tiled=True\n",
    "        ) as dst:\n",
    "            dst.write(registered_data)\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "# Register orthos\n",
    "registered_paths = {}\n",
    "\n",
    "for ortho_name, transformation in transformations.items():\n",
    "    if 'error' in transformation:\n",
    "        print(f\"\u26a0\ufe0f  Skipping {ortho_name}: {transformation['error']}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nRegistering {ortho_name}...\")\n",
    "    \n",
    "    registered_path = apply_transformation(\n",
    "        reprojected_paths[ortho_name],\n",
    "        transformation,\n",
    "        registered_dir / f\"{ortho_name}_registered.tif\",\n",
    "        basemap_path\n",
    "    )\n",
    "    \n",
    "    registered_paths[ortho_name] = registered_path\n",
    "    print(f\"  \u2713 Saved: {registered_path}\")\n",
    "\n",
    "print(f\"\\n\u2713 Registration complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Evaluate Accuracy Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare registered orthos to basemap\n",
    "def evaluate_accuracy(ortho_path: Path, basemap_path: Path, gcps: List[Dict]) -> Dict:\n",
    "    \"\"\"\n",
    "    Evaluate accuracy by comparing pixel values at GCP locations.\n",
    "    \"\"\"\n",
    "    with rasterio.open(basemap_path) as basemap_src:\n",
    "        basemap_data = basemap_src.read()\n",
    "    \n",
    "    with rasterio.open(ortho_path) as ortho_src:\n",
    "        ortho_data = ortho_src.read()\n",
    "    \n",
    "    errors = []\n",
    "    \n",
    "    for gcp in gcps:\n",
    "        pixel_coords = gcp_to_pixel_coords(gcp['lat'], gcp['lon'], basemap_path)\n",
    "        if not pixel_coords:\n",
    "            continue\n",
    "        \n",
    "        col, row = pixel_coords\n",
    "        \n",
    "        if 0 <= row < basemap_data.shape[1] and 0 <= col < basemap_data.shape[2]:\n",
    "            basemap_pixel = basemap_data[:, row, col]\n",
    "            \n",
    "            if 0 <= row < ortho_data.shape[1] and 0 <= col < ortho_data.shape[2]:\n",
    "                ortho_pixel = ortho_data[:, row, col]\n",
    "                \n",
    "                # Compute error (Euclidean distance in pixel space)\n",
    "                error = np.sqrt(np.sum((basemap_pixel.astype(float) - ortho_pixel.astype(float))**2))\n",
    "                errors.append(error)\n",
    "    \n",
    "    if errors:\n",
    "        return {\n",
    "            'mean_error': float(np.mean(errors)),\n",
    "            'rmse': float(np.sqrt(np.mean(np.array(errors)**2))),\n",
    "            'max_error': float(np.max(errors)),\n",
    "            'num_points': len(errors)\n",
    "        }\n",
    "    else:\n",
    "        return {'error': 'No valid GCPs found'}\n",
    "\n",
    "# Evaluate accuracy for original and registered orthos\n",
    "accuracy_results = {}\n",
    "\n",
    "for ortho_name in reprojected_paths.keys():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Accuracy evaluation: {ortho_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Original (reprojected but not registered)\n",
    "    original_accuracy = evaluate_accuracy(\n",
    "        reprojected_paths[ortho_name],\n",
    "        basemap_path,\n",
    "        gcps\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nOriginal (reprojected):\")\n",
    "    print(f\"  Mean error: {original_accuracy.get('mean_error', 'N/A'):.2f}\")\n",
    "    print(f\"  RMSE: {original_accuracy.get('rmse', 'N/A'):.2f}\")\n",
    "    \n",
    "    # Registered\n",
    "    if ortho_name in registered_paths:\n",
    "        registered_accuracy = evaluate_accuracy(\n",
    "            registered_paths[ortho_name],\n",
    "            basemap_path,\n",
    "            gcps\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nRegistered:\")\n",
    "        print(f\"  Mean error: {registered_accuracy.get('mean_error', 'N/A'):.2f}\")\n",
    "        print(f\"  RMSE: {registered_accuracy.get('rmse', 'N/A'):.2f}\")\n",
    "        \n",
    "        improvement = ((original_accuracy.get('rmse', 0) - registered_accuracy.get('rmse', 0)) / original_accuracy.get('rmse', 1)) * 100\n",
    "        print(f\"\\n  Improvement: {improvement:.1f}%\")\n",
    "        \n",
    "        accuracy_results[ortho_name] = {\n",
    "            'original': original_accuracy,\n",
    "            'registered': registered_accuracy,\n",
    "            'improvement_percent': improvement\n",
    "        }\n",
    "    else:\n",
    "        accuracy_results[ortho_name] = {\n",
    "            'original': original_accuracy\n",
    "        }\n",
    "\n",
    "# Save results\n",
    "results_file = gcp_matching_dir / \"accuracy_results.json\"\n",
    "with open(results_file, 'w') as f:\n",
    "    json.dump(accuracy_results, f, indent=2)\n",
    "\n",
    "print(f\"\\n\u2713 Accuracy results saved to: {results_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}