{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCP-Based Patch Matching for Orthomosaic Registration\n",
    "\n",
    "This notebook performs patch matching to find ground control points (GCPs) in orthomosaics and uses them to register the orthos to the basemap.\n",
    "\n",
    "## Approach:\n",
    "1. Load GCPs from CSV file (WGS84 coordinates)\n",
    "2. Extract patches from basemap centered on each GCP\n",
    "3. Use template matching to find corresponding patches in orthomosaics\n",
    "4. Compute 2D shift or affine transformation from matches\n",
    "5. Apply transformation to register orthos to basemap\n",
    "6. Evaluate accuracy improvement\n",
    "\n",
    "## Inputs:\n",
    "- **Basemap**: `TestsiteNewWest_Spexigeo_RTK.tiff`\n",
    "- **GCPs**: `25-3288-CONTROL-NAD83-UTM10N-EGM2008.csv` (converted to WGS84)\n",
    "- **Orthomosaics**: \n",
    "  - `outputs/orthomosaics/orthomosaic_no_gcps.tif`\n",
    "  - `outputs/orthomosaics/orthomosaic_with_gcps.tif`\n",
    "\n",
    "## Outputs:\n",
    "- All outputs saved to `outputs/gcp_matching/`\n",
    "- Patches extracted from basemap\n",
    "- Matched GCP locations in orthos\n",
    "- Registered orthomosaics\n",
    "- Accuracy evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if needed\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "packages = [\n",
    "    'rasterio',\n",
    "    'numpy',\n",
    "    'matplotlib',\n",
    "    'opencv-python',\n",
    "    'scipy',\n",
    "    'utm',\n",
    "    'pillow'\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    try:\n",
    "        __import__(package.replace('-', '_'))\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])\n",
    "\n",
    "print(\"\u2713 Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup - Imports and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 Output directory: outputs/gcp_matching\n",
      "  - Patches: outputs/gcp_matching/patches\n",
      "  - Matches: outputs/gcp_matching/matches\n",
      "  - Registered: outputs/gcp_matching/registered\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.transform import xy\n",
    "from rasterio.warp import transform as transform_coords\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "import json\n",
    "import csv\n",
    "import utm\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup paths\n",
    "data_dir = Path(\"/Users/mauriciohessflores/Documents/Code/Data/New Westminster Oct _25\")\n",
    "output_dir = Path(\"outputs\")\n",
    "\n",
    "# Input files\n",
    "basemap_path = data_dir / \"Michael_RTK_orthos\" / \"TestsiteNewWest_Spexigeo_RTK.tiff\"\n",
    "gcp_csv_path = data_dir / \"25-3288-CONTROL-NAD83-UTM10N-EGM2008.csv\"\n",
    "ortho_no_gcps_path = output_dir / \"orthomosaics\" / \"orthomosaic_no_gcps.tif\"\n",
    "ortho_with_gcps_path = output_dir / \"orthomosaics\" / \"orthomosaic_with_gcps.tif\"\n",
    "\n",
    "# Output directories\n",
    "gcp_matching_dir = output_dir / \"gcp_matching\"\n",
    "gcp_matching_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "patches_dir = gcp_matching_dir / \"patches\"\n",
    "patches_dir.mkdir(exist_ok=True)\n",
    "\n",
    "matches_dir = gcp_matching_dir / \"matches\"\n",
    "matches_dir.mkdir(exist_ok=True)\n",
    "\n",
    "registered_dir = gcp_matching_dir / \"registered\"\n",
    "registered_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"\u2713 Output directory: {gcp_matching_dir}\")\n",
    "print(f\"  - Patches: {patches_dir}\")\n",
    "print(f\"  - Matches: {matches_dir}\")\n",
    "print(f\"  - Registered: {registered_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Update paths for Colab\n",
    "data_dir = Path(\"/content/drive/MyDrive/Data/New Westminster Oct _25\")\n",
    "output_dir = Path(\"/content/drive/MyDrive/Code/MyCode/research-westminster_ground_truth_analysis/outputs\")\n",
    "\n",
    "# Update other paths accordingly\n",
    "basemap_path = data_dir / \"Michael_RTK_orthos\" / \"TestsiteNewWest_Spexigeo_RTK.tiff\"\n",
    "gcp_csv_path = data_dir / \"25-3288-CONTROL-NAD83-UTM10N-EGM2008.csv\"\n",
    "ortho_no_gcps_path = output_dir / \"orthomosaics\" / \"orthomosaic_no_gcps.tif\"\n",
    "ortho_with_gcps_path = output_dir / \"orthomosaics\" / \"orthomosaic_with_gcps.tif\"\n",
    "\n",
    "print(\"\u2713 Colab paths configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load GCPs from CSV and Convert to WGS84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u26a0\ufe0f  Could not find required columns. Found: ['1', '5450945.525', '506914.123', '77.453', 'GCP1']\n",
      "   Looking for: name/id, x/easting, y/northing\n",
      "\u2713 Loaded 0 GCPs from CSV\n",
      "\u26a0\ufe0f  No GCPs loaded! Check CSV format.\n",
      "   CSV path: /Users/mauriciohessflores/Documents/Code/Data/New Westminster Oct _25/25-3288-CONTROL-NAD83-UTM10N-EGM2008.csv\n",
      "   File exists. Showing first few lines:\n",
      "     1,5450945.525,506914.123,77.453,GCP1\n",
      "     2,5450730.008,506657.794,79.218,GCP2\n",
      "     3,5450480.009,506577.772,59.4,GCP3\n",
      "     4,5450578.626,506765.034,65.591,GCP4\n",
      "     5,5450715.958,506926.13,63.103,GCP5\n"
     ]
    }
   ],
   "source": [
    "# Load GCPs - try existing WGS84 files first, otherwise parse CSV\n",
    "import json\n",
    "\n",
    "# Check for existing WGS84 GCP files from ground control comparison\n",
    "gcps_wgs84_geojson = output_dir / \"ground_control_comparison\" / \"gcps_wgs84.geojson\"\n",
    "gcps_wgs84_csv = output_dir / \"ground_control_comparison\" / \"gcps_wgs84.csv\"\n",
    "\n",
    "gcps = []\n",
    "\n",
    "# Try GeoJSON first (preferred)\n",
    "if gcps_wgs84_geojson.exists():\n",
    "    print(f\"Loading GCPs from GeoJSON: {gcps_wgs84_geojson}\")\n",
    "    with open(gcps_wgs84_geojson, 'r') as f:\n",
    "        geojson_data = json.load(f)\n",
    "    \n",
    "    if 'features' in geojson_data:\n",
    "        for feature in geojson_data['features']:\n",
    "            props = feature.get('properties', {})\n",
    "            geom = feature.get('geometry', {})\n",
    "            \n",
    "            if geom.get('type') == 'Point':\n",
    "                coords = geom.get('coordinates', [])\n",
    "                if len(coords) >= 2:\n",
    "                    lon, lat = coords[0], coords[1]\n",
    "                    \n",
    "                    # Get UTM coordinates from properties or convert\n",
    "                    x_utm = props.get('x_utm')\n",
    "                    y_utm = props.get('y_utm')\n",
    "                    \n",
    "                    if x_utm is None or y_utm is None:\n",
    "                        # Convert WGS84 to UTM\n",
    "                        import utm\n",
    "                        x_utm, y_utm, zone_num, zone_letter = utm.from_latlon(lat, lon)\n",
    "                    \n",
    "                    gcps.append({\n",
    "                        'id': props.get('id', props.get('name', f\"GCP_{len(gcps)+1}\")),\n",
    "                        'lat': lat,\n",
    "                        'lon': lon,\n",
    "                        'x_utm': float(x_utm),\n",
    "                        'y_utm': float(y_utm)\n",
    "                    })\n",
    "    \n",
    "    print(f\"\u2713 Loaded {len(gcps)} GCPs from GeoJSON\")\n",
    "\n",
    "# Try CSV if GeoJSON not found\n",
    "elif gcps_wgs84_csv.exists():\n",
    "    print(f\"Loading GCPs from WGS84 CSV: {gcps_wgs84_csv}\")\n",
    "    with open(gcps_wgs84_csv, 'r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            try:\n",
    "                lat = float(row.get('lat', row.get('latitude', 0)))\n",
    "                lon = float(row.get('lon', row.get('longitude', row.get('lon', 0))))\n",
    "                gcp_id = row.get('id', row.get('name', row.get('label', f\"GCP_{len(gcps)+1}\")))\n",
    "                \n",
    "                # Get UTM from row or convert\n",
    "                x_utm_str = row.get('x_utm', '')\n",
    "                y_utm_str = row.get('y_utm', '')\n",
    "                \n",
    "                if x_utm_str and y_utm_str:\n",
    "                    x_utm = float(x_utm_str)\n",
    "                    y_utm = float(y_utm_str)\n",
    "                else:\n",
    "                    import utm\n",
    "                    x_utm, y_utm, zone_num, zone_letter = utm.from_latlon(lat, lon)\n",
    "                \n",
    "                gcps.append({\n",
    "                    'id': gcp_id,\n",
    "                    'lat': lat,\n",
    "                    'lon': lon,\n",
    "                    'x_utm': x_utm,\n",
    "                    'y_utm': y_utm\n",
    "                })\n",
    "            except (ValueError, KeyError) as e:\n",
    "                print(f\"\u26a0\ufe0f  Skipping row: {e}\")\n",
    "                continue\n",
    "    \n",
    "    print(f\"\u2713 Loaded {len(gcps)} GCPs from WGS84 CSV\")\n",
    "\n",
    "# Fallback to parsing UTM CSV\n",
    "if len(gcps) == 0:\n",
    "    print(f\"\\nNo WGS84 GCP files found, parsing UTM CSV: {gcp_csv_path}\")\n",
    "    gcps = load_gcps_from_csv(gcp_csv_path)\n",
    "    print(f\"\u2713 Loaded {len(gcps)} GCPs from UTM CSV\")\n",
    "\n",
    "if len(gcps) > 0:\n",
    "    print(f\"\\nFirst few GCPs:\")\n",
    "    for gcp in gcps[:3]:\n",
    "        print(f\"  {gcp['id']}: UTM=({gcp['x_utm']:.2f}, {gcp['y_utm']:.2f}), WGS84=({gcp['lat']:.6f}, {gcp['lon']:.6f})\")\n",
    "else:\n",
    "    print(f\"\u26a0\ufe0f  No GCPs loaded!\")\n",
    "    print(f\"   Checked:\")\n",
    "    print(f\"   - {gcps_wgs84_geojson}\")\n",
    "    print(f\"   - {gcps_wgs84_csv}\")\n",
    "    print(f\"   - {gcp_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basemap CRS: EPSG:32610\n",
      "Basemap dimensions: 90129x90188\n",
      "Basemap bounds: BoundingBox(left=506424.37839793676, bottom=5450017.622213458, right=507501.0951215451, top=5451095.043774429)\n",
      "Basemap transform: | 0.01, 0.00, 506424.38|\n",
      "| 0.00,-0.01, 5451095.04|\n",
      "| 0.00, 0.00, 1.00|\n",
      "\n",
      "GCP GCP1: UTM=(506914.12, 5450945.53)\n",
      "  \u2713 Found at pixel: col=40995, row=12515\n",
      "\n",
      "GCP GCP2: UTM=(506657.79, 5450730.01)\n",
      "  \u2713 Found at pixel: col=19538, row=30556\n",
      "\n",
      "GCP GCP3: UTM=(506577.77, 5450480.01)\n",
      "  \u2713 Found at pixel: col=12840, row=51482\n",
      "\n",
      "GCP GCP4: UTM=(506765.03, 5450578.63)\n",
      "  \u2713 Found at pixel: col=28515, row=43227\n",
      "\n",
      "GCP GCP5: UTM=(506926.13, 5450715.96)\n",
      "  \u2713 Found at pixel: col=42000, row=31732\n",
      "\n",
      "GCP GCP6: UTM=(507071.92, 5450992.66)\n",
      "  \u2713 Found at pixel: col=54203, row=8570\n",
      "\n",
      "GCP GCP7: UTM=(507089.40, 5450794.23)\n",
      "  \u2713 Found at pixel: col=55667, row=25180\n",
      "\n",
      "GCP GCP8: UTM=(507315.01, 5450717.85)\n",
      "  \u2713 Found at pixel: col=74551, row=31574\n",
      "\n",
      "GCP GCP9: UTM=(507252.65, 5450536.03)\n",
      "  \u2713 Found at pixel: col=69332, row=46793\n",
      "\n",
      "GCP GCP10: UTM=(507072.02, 5450500.33)\n",
      "  \u2713 Found at pixel: col=54212, row=49782\n",
      "\n",
      "GCP GCP11: UTM=(507020.05, 5450595.29)\n",
      "  \u2713 Found at pixel: col=49861, row=41832\n",
      "\n",
      "GCP GCP12: UTM=(506885.91, 5450346.64)\n",
      "  \u2713 Found at pixel: col=38633, row=62646\n",
      "\n",
      "GCP GCP13: UTM=(506586.74, 5450323.69)\n",
      "  \u2713 Found at pixel: col=13590, row=64568\n",
      "\n",
      "GCP GCP14: UTM=(506746.87, 5450378.55)\n",
      "  \u2713 Found at pixel: col=26994, row=59975\n",
      "\n",
      "GCP GCP15: UTM=(506903.07, 5450193.68)\n",
      "  \u2713 Found at pixel: col=40069, row=75450\n",
      "\n",
      "GCP GCP16: UTM=(506977.00, 5450109.82)\n",
      "  \u2713 Found at pixel: col=46258, row=82470\n",
      "\n",
      "GCP CP1: UTM=(507060.63, 5450345.17)\n",
      "  \u2713 Found at pixel: col=53258, row=62769\n",
      "\n",
      "GCP CP2: UTM=(506911.89, 5450506.71)\n",
      "  \u2713 Found at pixel: col=40808, row=49247\n",
      "\n",
      "GCP CP3: UTM=(506821.64, 5450292.79)\n",
      "  \u2713 Found at pixel: col=33254, row=67154\n",
      "\n",
      "GCP CP4: UTM=(507148.30, 5450712.13)\n",
      "  \u2713 Found at pixel: col=60597, row=32052\n",
      "\n",
      "GCP CP5: UTM=(506800.86, 5450859.45)\n",
      "  \u2713 Found at pixel: col=31514, row=19720\n",
      "\n",
      "GCP OMON 6076: UTM=(506864.18, 5450326.10)\n",
      "  \u2713 Found at pixel: col=36814, row=64366\n",
      "\n",
      "GCP OMON 6066: UTM=(507163.74, 5450716.44)\n",
      "  \u2713 Found at pixel: col=61889, row=31691\n",
      "\n",
      "\u2713 Found 23 GCPs within basemap bounds\n",
      "\n",
      "First few GCP pixel coordinates:\n",
      "  GCP1: col=40995, row=12515\n",
      "  GCP2: col=19538, row=30556\n",
      "  GCP3: col=12840, row=51482\n"
     ]
    }
   ],
   "source": [
    "# Convert GCPs (UTM) to pixel coordinates in basemap\n",
    "def gcp_to_pixel_coords_from_utm(gcp_x_utm: float, gcp_y_utm: float, raster_path: Path) -> Optional[Tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    Convert GCP UTM coordinates to pixel coordinates in raster.\n",
    "    \n",
    "    Args:\n",
    "        gcp_x_utm: UTM Easting (EPSG:32610)\n",
    "        gcp_y_utm: UTM Northing (EPSG:32610)\n",
    "        raster_path: Path to raster file\n",
    "    \n",
    "    Returns:\n",
    "        (col, row) or None if outside bounds.\n",
    "    \"\"\"\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        # Raster should be in EPSG:32610 (UTM Zone 10N)\n",
    "        if src.crs != 'EPSG:32610':\n",
    "            # Transform UTM to raster CRS if needed\n",
    "            x, y = transform_coords(\n",
    "                'EPSG:32610',\n",
    "                src.crs,\n",
    "                [gcp_x_utm],\n",
    "                [gcp_y_utm]\n",
    "            )\n",
    "            utm_x, utm_y = x[0], y[0]\n",
    "        else:\n",
    "            utm_x, utm_y = gcp_x_utm, gcp_y_utm\n",
    "        \n",
    "        # Convert to pixel coordinates\n",
    "        row, col = rasterio.transform.rowcol(src.transform, utm_x, utm_y)\n",
    "        \n",
    "        # Check if within bounds\n",
    "        if 0 <= row < src.height and 0 <= col < src.width:\n",
    "            return (col, row)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "# Get basemap CRS and transform\n",
    "with rasterio.open(basemap_path) as basemap_src:\n",
    "    basemap_crs = basemap_src.crs\n",
    "    basemap_transform = basemap_src.transform\n",
    "    basemap_width = basemap_src.width\n",
    "    basemap_height = basemap_src.height\n",
    "    basemap_bounds = basemap_src.bounds\n",
    "\n",
    "print(f\"Basemap CRS: {basemap_crs}\")\n",
    "print(f\"Basemap dimensions: {basemap_width}x{basemap_height}\")\n",
    "print(f\"Basemap bounds: {basemap_bounds}\")\n",
    "print(f\"Basemap transform: {basemap_transform}\")\n",
    "\n",
    "# Convert all GCPs to pixel coordinates\n",
    "gcp_pixel_coords = {}\n",
    "for gcp in gcps:\n",
    "    # Debug: show GCP UTM coordinates\n",
    "    print(f\"\\nGCP {gcp['id']}: UTM=({gcp['x_utm']:.2f}, {gcp['y_utm']:.2f})\")\n",
    "    \n",
    "    pixel_coords = gcp_to_pixel_coords_from_utm(gcp['x_utm'], gcp['y_utm'], basemap_path)\n",
    "    if pixel_coords:\n",
    "        gcp_pixel_coords[gcp['id']] = {\n",
    "            'gcp': gcp,\n",
    "            'pixel_col': pixel_coords[0],\n",
    "            'pixel_col': pixel_coords[0],\n",
    "            'pixel_row': pixel_coords[1]\n",
    "            'utm_x': gcp.get('x_utm'),\n",
    "            'utm_y': gcp.get('y_utm'),\n",
    "            'pixel_row': pixel_coords[1]\n",
    "        }\n",
    "        print(f\"  \u2713 Found at pixel: col={pixel_coords[0]}, row={pixel_coords[1]}\")\n",
    "    else:\n",
    "        # Debug: show why it's outside bounds\n",
    "        with rasterio.open(basemap_path) as src:\n",
    "            row, col = rasterio.transform.rowcol(src.transform, gcp['x_utm'], gcp['y_utm'])\n",
    "            print(f\"  \u26a0\ufe0f  Outside bounds: col={col}, row={row}\")\n",
    "            print(f\"     Basemap: {src.width}x{src.height}\")\n",
    "            print(f\"     Basemap bounds: {src.bounds}\")\n",
    "            # Check if coordinates are in bounds in UTM space\n",
    "            in_x = src.bounds.left <= gcp['x_utm'] <= src.bounds.right\n",
    "            in_y = src.bounds.bottom <= gcp['y_utm'] <= src.bounds.top\n",
    "            print(f\"     UTM X in bounds: {in_x} ({src.bounds.left:.2f} <= {gcp['x_utm']:.2f} <= {src.bounds.right:.2f})\")\n",
    "            print(f\"     UTM Y in bounds: {in_y} ({src.bounds.bottom:.2f} <= {gcp['y_utm']:.2f} <= {src.bounds.top:.2f})\")\n",
    "\n",
    "print(f\"\\n\u2713 Found {len(gcp_pixel_coords)} GCPs within basemap bounds\")\n",
    "if len(gcp_pixel_coords) > 0:\n",
    "    print(f\"\\nFirst few GCP pixel coordinates:\")\n",
    "    for gcp_id, coords in list(gcp_pixel_coords.items())[:3]:\n",
    "        print(f\"  {gcp_id}: col={coords['pixel_col']}, row={coords['pixel_row']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert GCPs (WGS84) to pixel coordinates in basemap\n",
    "def gcp_to_pixel_coords(gcp_lat: float, gcp_lon: float, raster_path: Path) -> Optional[Tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    Convert GCP lat/lon to pixel coordinates in raster.\n",
    "    \n",
    "    Returns (col, row) or None if outside bounds.\n",
    "    \"\"\"\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        # Transform WGS84 to raster CRS\n",
    "        x, y = transform_coords(\n",
    "            'EPSG:4326',  # WGS84\n",
    "            src.crs,\n",
    "            [gcp_lon],\n",
    "            [gcp_lat]\n",
    "        )\n",
    "        \n",
    "        # Convert to pixel coordinates\n",
    "        row, col = rasterio.transform.rowcol(src.transform, x[0], y[0])\n",
    "        \n",
    "        # Check if within bounds\n",
    "        if 0 <= row < src.height and 0 <= col < src.width:\n",
    "            return (col, row)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "# Get basemap CRS and transform\n",
    "with rasterio.open(basemap_path) as basemap_src:\n",
    "    basemap_crs = basemap_src.crs\n",
    "    basemap_transform = basemap_src.transform\n",
    "    basemap_width = basemap_src.width\n",
    "    basemap_height = basemap_src.height\n",
    "\n",
    "print(f\"Basemap CRS: {basemap_crs}\")\n",
    "print(f\"Basemap dimensions: {basemap_width}x{basemap_height}\")\n",
    "\n",
    "# Convert all GCPs to pixel coordinates\n",
    "gcp_pixel_coords = {}\n",
    "for gcp in gcps:\n",
    "    pixel_coords = gcp_to_pixel_coords(gcp['lat'], gcp['lon'], basemap_path)\n",
    "    if pixel_coords:\n",
    "        gcp_pixel_coords[gcp['id']] = {\n",
    "            'gcp': gcp,\n",
    "            'pixel_col': pixel_coords[0],\n",
    "            'pixel_row': pixel_coords[1]\n",
    "        }\n",
    "    else:\n",
    "        print(f\"\u26a0\ufe0f  GCP {gcp['id']} is outside basemap bounds\")\n",
    "\n",
    "print(f\"\\n\u2713 Found {len(gcp_pixel_coords)} GCPs within basemap bounds\")\n",
    "print(f\"\\nFirst few GCP pixel coordinates:\")\n",
    "for gcp_id, coords in list(gcp_pixel_coords.items())[:3]:\n",
    "    print(f\"  {gcp_id}: col={coords['pixel_col']}, row={coords['pixel_row']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Extract Patches from Basemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract patches from basemap centered on GCPs\n",
    "def extract_patch(raster_path: Path, center_col: int, center_row: int, patch_size: int) -> Optional[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Extract a patch from raster centered on given pixel coordinates.\n",
    "    \n",
    "    Args:\n",
    "        raster_path: Path to raster file\n",
    "        center_col: Center column (x)\n",
    "        center_row: Center row (y)\n",
    "        patch_size: Size of patch (must be odd, e.g., 29, 39, 49)\n",
    "    \n",
    "    Returns:\n",
    "        Patch array (H, W, C) or None if out of bounds\n",
    "    \"\"\"\n",
    "    half_size = patch_size // 2\n",
    "    \n",
    "    with rasterio.open(raster_path) as src:\n",
    "        # Calculate bounds\n",
    "        col_start = max(0, center_col - half_size)\n",
    "        col_end = min(src.width, center_col + half_size + 1)\n",
    "        row_start = max(0, center_row - half_size)\n",
    "        row_end = min(src.height, center_row + half_size + 1)\n",
    "        \n",
    "        # Check if patch would be out of bounds\n",
    "        if col_end - col_start < patch_size or row_end - row_start < patch_size:\n",
    "            return None\n",
    "        \n",
    "        # Read patch\n",
    "        patch = src.read(\n",
    "            window=rasterio.windows.Window(col_start, row_start, col_end - col_start, row_end - row_start)\n",
    "        )\n",
    "        \n",
    "        # Transpose to (H, W, C) format\n",
    "        if len(patch.shape) == 3:\n",
    "            patch = np.transpose(patch, (1, 2, 0))\n",
    "        \n",
    "        # If single band, convert to 3-channel grayscale\n",
    "        if len(patch.shape) == 2:\n",
    "            patch = np.stack([patch, patch, patch], axis=-1)\n",
    "        \n",
    "        return patch\n",
    "\n",
    "# Extract patches for different patch sizes\n",
    "patch_sizes = [29, 39, 49, 59]  # Try different sizes\n",
    "basemap_patches = {}\n",
    "\n",
    "for patch_size in patch_sizes:\n",
    "    basemap_patches[patch_size] = {}\n",
    "    \n",
    "    for gcp_id, coords in gcp_pixel_coords.items():\n",
    "        patch = extract_patch(\n",
    "            basemap_path,\n",
    "            coords['pixel_col'],\n",
    "            coords['pixel_row'],\n",
    "            patch_size\n",
    "        )\n",
    "        \n",
    "        if patch is not None:\n",
    "            basemap_patches[patch_size][gcp_id] = patch\n",
    "            \n",
    "            # Save patch as image for visualization\n",
    "            patch_path = patches_dir / f\"basemap_{gcp_id}_{patch_size}x{patch_size}.png\"\n",
    "            plt.imsave(patch_path, patch.astype(np.uint8))\n",
    "    \n",
    "    print(f\"\u2713 Extracted {len(basemap_patches[patch_size])} patches of size {patch_size}x{patch_size}\")\n",
    "\n",
    "print(f\"\\n\u2713 Patch extraction complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Reproject Orthomosaics to Match Basemap CRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reprojecting no_gcps...\n"
     ]
    },
    {
     "ename": "CPLE_AppDefinedError",
     "evalue": "Too many points (10201 out of 10201) failed to transform, unable to compute output bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_AppDefinedError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 94\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mReprojecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mortho_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 94\u001b[0m     reprojected_path \u001b[38;5;241m=\u001b[39m \u001b[43mreproject_ortho_to_basemap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43mortho_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbasemap_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreprojected_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mortho_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_reprojected.tif\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m     reprojected_paths[ortho_name] \u001b[38;5;241m=\u001b[39m reprojected_path\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\u2713 Reprojection complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 33\u001b[0m, in \u001b[0;36mreproject_ortho_to_basemap\u001b[0;34m(ortho_path, basemap_path, output_path)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output_path\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Calculate transform\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m transform, width, height \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_default_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource_crs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_crs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_height\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtarget_bounds\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Read source data\u001b[39;00m\n\u001b[1;32m     42\u001b[0m source_data \u001b[38;5;241m=\u001b[39m ortho_src\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/rasterio/env.py:410\u001b[0m, in \u001b[0;36mensure_env.<locals>.wrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m local\u001b[38;5;241m.\u001b[39m_env:\n\u001b[0;32m--> 410\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    412\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m Env\u001b[38;5;241m.\u001b[39mfrom_defaults():\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/rasterio/warp.py:556\u001b[0m, in \u001b[0;36mcalculate_default_transform\u001b[0;34m(src_crs, dst_crs, width, height, left, bottom, right, top, gcps, rpcs, resolution, dst_width, dst_height, src_geoloc_array, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resolution \u001b[38;5;129;01mand\u001b[39;00m dimensions:\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResolution cannot be used with dst_width and dst_height.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 556\u001b[0m dst_affine, dst_width, dst_height \u001b[38;5;241m=\u001b[39m \u001b[43m_calculate_default_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m    \u001b[49m\u001b[43msrc_crs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdst_crs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m    \u001b[49m\u001b[43mleft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbottom\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbottom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mright\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgcps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgcps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrpcs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrpcs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43msrc_geoloc_array\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_geoloc_array\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;66;03m# If resolution is specified, Keep upper-left anchored\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;66;03m# adjust the transform resolutions\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;66;03m# adjust the width/height by the ratio of estimated:specified res (ceil'd)\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resolution:\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;66;03m# resolutions argument into tuple\u001b[39;00m\n",
      "File \u001b[0;32mrasterio/_warp.pyx:796\u001b[0m, in \u001b[0;36mrasterio._warp._calculate_default_transform\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mrasterio/_err.pyx:289\u001b[0m, in \u001b[0;36mrasterio._err.exc_wrap_int\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_AppDefinedError\u001b[0m: Too many points (10201 out of 10201) failed to transform, unable to compute output bounds."
     ]
    }
   ],
   "source": [
    "from rasterio.warp import calculate_default_transform, reproject, Resampling, transform_bounds\n",
    "from rasterio.transform import from_bounds\n",
    "from rasterio.enums import Resampling as RasterioResampling\n",
    "from affine import Affine\n",
    "\n",
    "# Reproject orthos to match basemap CRS and resolution\n",
    "def reproject_ortho_to_basemap(ortho_path: Path, basemap_path: Path, output_path: Path) -> Path:\n",
    "    \"\"\"\n",
    "    Reproject orthomosaic to match basemap CRS and bounds.\n",
    "    Uses manual transform construction to avoid CPLE_AppDefinedError.\n",
    "    \"\"\"\n",
    "    if output_path.exists():\n",
    "        print(f\"  \u2713 Already reprojected: {output_path}\")\n",
    "        return output_path\n",
    "    \n",
    "    with rasterio.open(basemap_path) as basemap_src:\n",
    "        target_crs = basemap_src.crs\n",
    "        target_bounds = basemap_src.bounds\n",
    "        target_transform = basemap_src.transform\n",
    "        target_width = basemap_src.width\n",
    "        target_height = basemap_src.height\n",
    "    \n",
    "    with rasterio.open(ortho_path) as ortho_src:\n",
    "        source_crs = ortho_src.crs\n",
    "        source_bounds = ortho_src.bounds\n",
    "        \n",
    "        if source_crs == target_crs:\n",
    "            print(f\"  \u2713 Already in target CRS\")\n",
    "            import shutil\n",
    "            shutil.copy(ortho_path, output_path)\n",
    "            return output_path\n",
    "        \n",
    "        # Transform source bounds to target CRS\n",
    "        print(f\"  Transforming source bounds to target CRS...\")\n",
    "        src_bounds_target_crs = transform_bounds(\n",
    "            source_crs, target_crs,\n",
    "            source_bounds.left, source_bounds.bottom,\n",
    "            source_bounds.right, source_bounds.top\n",
    "        )\n",
    "        \n",
    "        print(f\"  Source bounds in target CRS: {src_bounds_target_crs}\")\n",
    "        \n",
    "        # Get target pixel size\n",
    "        target_pixel_size_x = abs(target_transform[0])\n",
    "        target_pixel_size_y = abs(target_transform[4])\n",
    "        \n",
    "        # Use intersection of bounds\n",
    "        output_left = max(src_bounds_target_crs[0], target_bounds.left)\n",
    "        output_bottom = max(src_bounds_target_crs[1], target_bounds.bottom)\n",
    "        output_right = min(src_bounds_target_crs[2], target_bounds.right)\n",
    "        output_top = min(src_bounds_target_crs[3], target_bounds.top)\n",
    "        \n",
    "        print(f\"  Output bounds (intersection): left={output_left:.2f}, bottom={output_bottom:.2f}, right={output_right:.2f}, top={output_top:.2f}\")\n",
    "        \n",
    "        # Validate bounds\n",
    "        if output_right <= output_left or output_top <= output_bottom:\n",
    "            raise ValueError(f\"Invalid output bounds: width={output_right-output_left}, height={output_top-output_bottom}\")\n",
    "        \n",
    "        # Calculate dimensions using target pixel size\n",
    "        width = int((output_right - output_left) / target_pixel_size_x)\n",
    "        height = int((output_top - output_bottom) / target_pixel_size_y)\n",
    "        \n",
    "        # Validate dimensions\n",
    "        if width <= 0 or height <= 0:\n",
    "            raise ValueError(f\"Invalid dimensions: width={width}, height={height}\")\n",
    "        \n",
    "        # Create transform for output\n",
    "        transform = Affine.translation(output_left, output_top) * Affine.scale(target_pixel_size_x, -target_pixel_size_y)\n",
    "        \n",
    "        print(f\"  \u2713 Transform calculated: {width}x{height} pixels\")\n",
    "        \n",
    "        # Read source data\n",
    "        source_data = ortho_src.read()\n",
    "        source_count = ortho_src.count\n",
    "        \n",
    "        # Reproject\n",
    "        reprojected_data = np.zeros((source_count, height, width), dtype=source_data.dtype)\n",
    "        \n",
    "        for band_idx in range(1, source_count + 1):\n",
    "            reproject(\n",
    "                source=rasterio.band(ortho_src, band_idx),\n",
    "                destination=reprojected_data[band_idx - 1],\n",
    "                src_transform=ortho_src.transform,\n",
    "                src_crs=source_crs,\n",
    "                dst_transform=transform,\n",
    "                dst_crs=target_crs,\n",
    "                resampling=Resampling.bilinear\n",
    "            )\n",
    "        \n",
    "        # Save\n",
    "        with rasterio.open(\n",
    "            output_path,\n",
    "            'w',\n",
    "            driver='GTiff',\n",
    "            height=height,\n",
    "            width=width,\n",
    "            count=source_count,\n",
    "            dtype=reprojected_data.dtype,\n",
    "            crs=target_crs,\n",
    "            transform=transform,\n",
    "            compress='lzw',\n",
    "            BIGTIFF='YES',\n",
    "            tiled=True,\n",
    "            blockxsize=512,\n",
    "            blockysize=512\n",
    "        ) as dst:\n",
    "            dst.write(reprojected_data)\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "# Check for existing reprojected files from test_matching notebook\n",
    "existing_reprojected_dir = output_dir / \"test_matching\" / \"reprojected\"\n",
    "reprojected_dir = gcp_matching_dir / \"reprojected\"\n",
    "reprojected_dir.mkdir(exist_ok=True)\n",
    "\n",
    "ortho_paths = {\n",
    "    'no_gcps': ortho_no_gcps_path,\n",
    "    'with_gcps': ortho_with_gcps_path\n",
    "}\n",
    "\n",
    "reprojected_paths = {}\n",
    "for ortho_name, ortho_path in ortho_paths.items():\n",
    "    if not ortho_path.exists():\n",
    "        print(f\"\u26a0\ufe0f  Ortho not found: {ortho_path}\")\n",
    "        continue\n",
    "    \n",
    "    # Check for existing reprojected file from test_matching\n",
    "    existing_reprojected = existing_reprojected_dir / f\"{ortho_name}_reprojected.tif\"\n",
    "    if existing_reprojected.exists():\n",
    "        print(f\"\\nFound existing reprojected file: {existing_reprojected}\")\n",
    "        # Copy to our directory\n",
    "        import shutil\n",
    "        reprojected_path = reprojected_dir / f\"{ortho_name}_reprojected.tif\"\n",
    "        if not reprojected_path.exists():\n",
    "            shutil.copy(existing_reprojected, reprojected_path)\n",
    "            print(f\"  \u2713 Copied to: {reprojected_path}\")\n",
    "        else:\n",
    "            print(f\"  \u2713 Already exists: {reprojected_path}\")\n",
    "        reprojected_paths[ortho_name] = reprojected_path\n",
    "        continue\n",
    "    \n",
    "    # Otherwise, reproject\n",
    "    print(f\"\\nReprojecting {ortho_name}...\")\n",
    "    reprojected_path = reproject_ortho_to_basemap(\n",
    "        ortho_path,\n",
    "        basemap_path,\n",
    "        reprojected_dir / f\"{ortho_name}_reprojected.tif\"\n",
    "    )\n",
    "    reprojected_paths[ortho_name] = reprojected_path\n",
    "\n",
    "print(f\"\\n\u2713 Reprojection complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Find GCP Patches in Orthomosaics Using Template Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Finding GCPs in no_gcps orthomosaic\n",
      "============================================================\n",
      "  Patch size 29x29: 22/23 matches\n",
      "  Patch size 39x39: 21/23 matches\n",
      "  Patch size 49x49: 21/23 matches\n",
      "  Patch size 59x59: 21/23 matches\n",
      "\n",
      "  \u2713 Best patch size: 29x29 (22 matches)\n",
      "\n",
      "============================================================\n",
      "Finding GCPs in with_gcps orthomosaic\n",
      "============================================================\n",
      "  Patch size 29x29: 22/23 matches\n",
      "  Patch size 39x39: 22/23 matches\n",
      "  Patch size 49x49: 21/23 matches\n",
      "  Patch size 59x59: 21/23 matches\n",
      "\n",
      "  \u2713 Best patch size: 29x29 (22 matches)\n",
      "\n",
      "\u2713 Patch matching complete!\n",
      "\n",
      "Creating visualization of GCP matches...\n",
      "\u2713 Visualization saved: outputs/gcp_matching/matches/gcp_matching_visualization_no_gcps.png\n",
      "\u2713 Visualization saved: outputs/gcp_matching/matches/gcp_matching_visualization_with_gcps.png\n"
     ]
    }
   ],
   "source": [
    "# Find GCP patches in orthomosaics using template matching\n",
    "def find_patch_in_ortho(\n",
    "    template_patch: np.ndarray,\n",
    "    ortho_path: Path,\n",
    "    search_center_col: int,\n",
    "    search_center_row: int,\n",
    "    search_radius: int = 500  # Search within this radius (pixels)\n",
    ") -> Optional[Tuple[int, int, float]]:\n",
    "    \"\"\"\n",
    "    Find template patch in orthomosaic using template matching.\n",
    "    \n",
    "    Returns:\n",
    "        (col, row, confidence) or None if not found\n",
    "    \"\"\"\n",
    "    # Convert template to grayscale if needed\n",
    "    if len(template_patch.shape) == 3:\n",
    "        template_gray = cv2.cvtColor(template_patch.astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        template_gray = template_patch.astype(np.uint8)\n",
    "    \n",
    "    with rasterio.open(ortho_path) as ortho_src:\n",
    "        # Define search window\n",
    "        search_col_start = max(0, search_center_col - search_radius)\n",
    "        search_col_end = min(ortho_src.width, search_center_col + search_radius)\n",
    "        search_row_start = max(0, search_center_row - search_radius)\n",
    "        search_row_end = min(ortho_src.height, search_center_row + search_radius)\n",
    "        \n",
    "        # Read search region\n",
    "        search_window = rasterio.windows.Window(\n",
    "            search_col_start,\n",
    "            search_row_start,\n",
    "            search_col_end - search_col_start,\n",
    "            search_row_end - search_row_start\n",
    "        )\n",
    "        \n",
    "        search_region = ortho_src.read(window=search_window)\n",
    "        \n",
    "        # Convert to (H, W, C) and then grayscale\n",
    "        if len(search_region.shape) == 3:\n",
    "            search_region = np.transpose(search_region, (1, 2, 0))\n",
    "            if search_region.shape[2] == 1:\n",
    "                search_gray = search_region[:, :, 0]\n",
    "            else:\n",
    "                search_gray = cv2.cvtColor(search_region.astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "        else:\n",
    "            search_gray = search_region\n",
    "        \n",
    "        # Normalize to uint8\n",
    "        if search_gray.dtype != np.uint8:\n",
    "            search_min = search_gray.min()\n",
    "            search_max = search_gray.max()\n",
    "            if search_max > search_min:\n",
    "                search_gray = ((search_gray - search_min) / (search_max - search_min) * 255).astype(np.uint8)\n",
    "            else:\n",
    "                search_gray = np.zeros_like(search_gray, dtype=np.uint8)\n",
    "        \n",
    "        # Template matching\n",
    "        result = cv2.matchTemplate(search_gray, template_gray, cv2.TM_CCOEFF_NORMED)\n",
    "        \n",
    "        # Find best match\n",
    "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "        \n",
    "        # Convert back to global coordinates\n",
    "        match_col = search_col_start + max_loc[0] + template_gray.shape[1] // 2\n",
    "        match_row = search_row_start + max_loc[1] + template_gray.shape[0] // 2\n",
    "        \n",
    "        # Return if confidence is high enough\n",
    "        if max_val > 0.5:  # Threshold for match confidence\n",
    "            return (match_col, match_row, float(max_val))\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "# Find GCPs in each orthomosaic\n",
    "# Create directory for matching patches\n",
    "matching_patches_dir = gcp_matching_dir / \"matching_patches\"\n",
    "matching_patches_dir.mkdir(exist_ok=True)\n",
    "\n",
    "matching_results = {}\n",
    "\n",
    "for ortho_name, reprojected_path in reprojected_paths.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Finding GCPs in {ortho_name} orthomosaic\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    matching_results[ortho_name] = {}\n",
    "    \n",
    "                # Convert GCP UTM coordinates to pixel coordinates in THIS ortho\n",
    "                # The ortho may have different dimensions/transform than basemap\n",
    "    with rasterio.open(reprojected_path) as ortho_src:\n",
    "        ortho_transform = ortho_src.transform\n",
    "    \n",
    "    # Try different patch sizes\n",
    "    best_patch_size = None\n",
    "    best_matches = 0\n",
    "    \n",
    "    for patch_size in patch_sizes:\n",
    "        matches_found = 0\n",
    "        \n",
    "        for gcp_id, coords in gcp_pixel_coords.items():\n",
    "            if gcp_id not in basemap_patches[patch_size]:\n",
    "                continue\n",
    "            \n",
    "            template = basemap_patches[patch_size][gcp_id]\n",
    "            \n",
    "            # Convert GCP UTM coordinates to pixel coordinates in THIS ortho\n",
    "            # The ortho may have different dimensions/transform than basemap\n",
    "            gcp_utm_x = coords.get('utm_x') or coords.get('x_utm')\n",
    "            gcp_utm_y = coords.get('utm_y') or coords.get('y_utm')\n",
    "            \n",
    "            if gcp_utm_x is not None and gcp_utm_y is not None:\n",
    "                # Convert UTM to pixel coordinates using ortho's transform\n",
    "                expected_col, expected_row = ~ortho_transform * (gcp_utm_x, gcp_utm_y)\n",
    "                expected_col = int(expected_col)\n",
    "                expected_row = int(expected_row)\n",
    "            else:\n",
    "                # Fallback: use pixel coordinates from basemap (less accurate)\n",
    "                expected_col = coords['pixel_col']\n",
    "                expected_row = coords['pixel_row']\n",
    "                \n",
    "                if gcp_utm_x is not None and gcp_utm_y is not None:\n",
    "                    # Convert UTM to pixel coordinates using ortho's transform\n",
    "                    expected_col, expected_row = ~ortho_transform * (gcp_utm_x, gcp_utm_y)\n",
    "                    expected_col = int(expected_col)\n",
    "                    expected_row = int(expected_row)\n",
    "                else:\n",
    "                    # Fallback: use pixel coordinates from basemap (less accurate)\n",
    "                    expected_row = coords['pixel_row']\n",
    "            \n",
    "            # Search for patch\n",
    "            match = find_patch_in_ortho(\n",
    "                template,\n",
    "                reprojected_path,\n",
    "                expected_col,\n",
    "                expected_row,\n",
    "                search_radius=500\n",
    "            )\n",
    "            \n",
    "            if match:\n",
    "                match_col, match_row, confidence = match\n",
    "                matches_found += 1\n",
    "                \n",
    "                if gcp_id not in matching_results[ortho_name]:\n",
    "                    matching_results[ortho_name][gcp_id] = {}\n",
    "                \n",
    "                matching_results[ortho_name][gcp_id][patch_size] = {\n",
    "                    'expected_col': expected_col,\n",
    "                    'expected_row': expected_row,\n",
    "                    'matched_col': match_col,\n",
    "                    'matched_row': match_row,\n",
    "                    'offset_col': match_col - expected_col,\n",
    "                    'offset_row': match_row - expected_row,\n",
    "                    'confidence': confidence\n",
    "                }\n",
    "        \n",
    "        print(f\"  Patch size {patch_size}x{patch_size}: {matches_found}/{len(gcp_pixel_coords)} matches\")\n",
    "        \n",
    "        if matches_found > best_matches:\n",
    "            best_matches = matches_found\n",
    "            best_patch_size = patch_size\n",
    "    \n",
    "    print(f\"\\n  \u2713 Best patch size: {best_patch_size}x{best_patch_size} ({best_matches} matches)\")\n",
    "\n",
    "print(f\"\\n\u2713 Patch matching complete!\")\n",
    "\n",
    "# Create comprehensive visualization\n",
    "print(f\"\\nCreating visualization of GCP matches...\")\n",
    "\n",
    "def create_gcp_matching_visualization(\n",
    "    basemap_path: Path,\n",
    "    ortho_paths: Dict[str, Path],\n",
    "    gcp_pixel_coords: Dict,\n",
    "    matching_results: Dict,\n",
    "    output_path: Path,\n",
    "    max_dimension: int = 4000\n",
    "):\n",
    "    \"\"\"\n",
    "    Create visualization showing basemap with GCPs and orthos with matched patches.\n",
    "    \"\"\"\n",
    "    # Load basemap\n",
    "    with rasterio.open(basemap_path) as src:\n",
    "        basemap_data = src.read()\n",
    "        basemap_transform = src.transform\n",
    "        \n",
    "        # Convert to (H, W, C)\n",
    "        if len(basemap_data.shape) == 3:\n",
    "            basemap_img = np.transpose(basemap_data, (1, 2, 0))\n",
    "            if basemap_img.shape[2] == 1:\n",
    "                basemap_img = np.stack([basemap_img[:, :, 0]] * 3, axis=-1)\n",
    "            elif basemap_img.shape[2] == 4:\n",
    "                basemap_img = basemap_img[:, :, :3]  # Take RGB\n",
    "        else:\n",
    "            basemap_img = np.stack([basemap_data] * 3, axis=-1)\n",
    "        \n",
    "        # Normalize to uint8\n",
    "        if basemap_img.dtype != np.uint8:\n",
    "            basemap_min = basemap_img.min()\n",
    "            basemap_max = basemap_img.max()\n",
    "            if basemap_max > basemap_min:\n",
    "                basemap_img = ((basemap_img - basemap_min) / (basemap_max - basemap_min) * 255).astype(np.uint8)\n",
    "            else:\n",
    "                basemap_img = np.zeros_like(basemap_img, dtype=np.uint8)\n",
    "    \n",
    "    # Downsample if too large\n",
    "    h, w = basemap_img.shape[:2]\n",
    "    if max(h, w) > max_dimension:\n",
    "        scale = max_dimension / max(h, w)\n",
    "        new_h, new_w = int(h * scale), int(w * scale)\n",
    "        basemap_img = cv2.resize(basemap_img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "        scale_factor = scale\n",
    "    else:\n",
    "        scale_factor = 1.0\n",
    "    \n",
    "    # Load orthos and create panels\n",
    "    num_orthos = len(ortho_paths)\n",
    "    fig, axes = plt.subplots(1, num_orthos + 1, figsize=(8 * (num_orthos + 1), 8))\n",
    "    \n",
    "    # Basemap panel (left)\n",
    "    ax = axes[0]\n",
    "    basemap_display = basemap_img.copy()\n",
    "    \n",
    "    # Draw GCP positions on basemap\n",
    "    for gcp_id, coords in gcp_pixel_coords.items():\n",
    "        # Scale coordinates\n",
    "        col = int(coords['pixel_col'] * scale_factor)\n",
    "        row = int(coords['pixel_row'] * scale_factor)\n",
    "        \n",
    "        if 0 <= row < basemap_display.shape[0] and 0 <= col < basemap_display.shape[1]:\n",
    "            # Draw red circle\n",
    "            cv2.circle(basemap_display, (col, row), 10, (255, 0, 0), 3)\n",
    "    \n",
    "    ax.imshow(basemap_display)\n",
    "    ax.set_title('Basemap with GCP Locations', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Add GCP labels\n",
    "    for gcp_id, coords in gcp_pixel_coords.items():\n",
    "        col = int(coords['pixel_col'] * scale_factor)\n",
    "        row = int(coords['pixel_row'] * scale_factor)\n",
    "        if 0 <= row < basemap_display.shape[0] and 0 <= col < basemap_display.shape[1]:\n",
    "            ax.text(col, row - 15, gcp_id, color='red', fontsize=8, fontweight='bold',\n",
    "                   ha='center', va='bottom')\n",
    "    \n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Ortho panels (right)\n",
    "    for ortho_idx, (ortho_name, ortho_path) in enumerate(ortho_paths.items(), 1):\n",
    "        ax = axes[ortho_idx]\n",
    "        \n",
    "        # Load ortho\n",
    "        with rasterio.open(ortho_path) as src:\n",
    "            ortho_data = src.read()\n",
    "            \n",
    "            # Convert to (H, W, C)\n",
    "            if len(ortho_data.shape) == 3:\n",
    "                ortho_img = np.transpose(ortho_data, (1, 2, 0))\n",
    "                if ortho_img.shape[2] == 1:\n",
    "                    ortho_img = np.stack([ortho_img[:, :, 0]] * 3, axis=-1)\n",
    "                elif ortho_img.shape[2] == 4:\n",
    "                    ortho_img = ortho_img[:, :, :3]\n",
    "            else:\n",
    "                ortho_img = np.stack([ortho_data] * 3, axis=-1)\n",
    "            \n",
    "            # Normalize\n",
    "            if ortho_img.dtype != np.uint8:\n",
    "                ortho_min = ortho_img.min()\n",
    "                ortho_max = ortho_img.max()\n",
    "                if ortho_max > ortho_min:\n",
    "                    ortho_img = ((ortho_img - ortho_min) / (ortho_max - ortho_min) * 255).astype(np.uint8)\n",
    "                else:\n",
    "                    ortho_img = np.zeros_like(ortho_img, dtype=np.uint8)\n",
    "        \n",
    "        # Downsample if too large\n",
    "        h, w = ortho_img.shape[:2]\n",
    "        if max(h, w) > max_dimension:\n",
    "            scale = max_dimension / max(h, w)\n",
    "            new_h, new_w = int(h * scale), int(w * scale)\n",
    "            ortho_img = cv2.resize(ortho_img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "            ortho_scale = scale\n",
    "        else:\n",
    "            ortho_scale = 1.0\n",
    "        \n",
    "        ortho_display = ortho_img.copy()\n",
    "        \n",
    "        # Draw matched patch centers\n",
    "        if ortho_name in matching_results:\n",
    "            for gcp_id, match_data in matching_results[ortho_name].items():\n",
    "                # Get best patch size match\n",
    "                best_patch_size = max(match_data.keys()) if match_data else None\n",
    "                if best_patch_size:\n",
    "                    match = match_data[best_patch_size]\n",
    "                    matched_col = int(match['matched_col'] * ortho_scale)\n",
    "                    matched_row = int(match['matched_row'] * ortho_scale)\n",
    "                    \n",
    "                    if 0 <= matched_row < ortho_display.shape[0] and 0 <= matched_col < ortho_display.shape[1]:\n",
    "                        # Draw yellow circle\n",
    "                        cv2.circle(ortho_display, (matched_col, matched_row), 10, (255, 255, 0), 3)\n",
    "        \n",
    "        ax.imshow(ortho_display)\n",
    "        ax.set_title(f'{ortho_name.replace(\"_\", \" \").title()} with Matched Patches', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Add labels\n",
    "        if ortho_name in matching_results:\n",
    "            for gcp_id, match_data in matching_results[ortho_name].items():\n",
    "                best_patch_size = max(match_data.keys()) if match_data else None\n",
    "                if best_patch_size:\n",
    "                    match = match_data[best_patch_size]\n",
    "                    matched_col = int(match['matched_col'] * ortho_scale)\n",
    "                    matched_row = int(match['matched_row'] * ortho_scale)\n",
    "                    if 0 <= matched_row < ortho_display.shape[0] and 0 <= matched_col < ortho_display.shape[1]:\n",
    "                        ax.text(matched_col, matched_row - 15, gcp_id, color='yellow', fontsize=8, fontweight='bold',\n",
    "                               ha='center', va='bottom')\n",
    "        \n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight', format='PNG')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"\u2713 Visualization saved: {output_path}\")\n",
    "\n",
    "# Create visualization for each ortho\n",
    "for ortho_name in reprojected_paths.keys():\n",
    "    if ortho_name not in matching_results:\n",
    "        continue\n",
    "    \n",
    "    vis_path = matches_dir / f\"gcp_matching_visualization_{ortho_name}.png\"\n",
    "\n",
    "    # Check if visualization already exists\n",
    "    if vis_path.exists():\n",
    "        print(f\"  \u2713 Visualization already exists: {vis_path}\")\n",
    "        print(f\"  Skipping visualization creation...\")\n",
    "        continue\n",
    "\n",
    "    \n",
    "    create_gcp_matching_visualization(\n",
    "        basemap_path,\n",
    "        {ortho_name: reprojected_paths[ortho_name]},\n",
    "        gcp_pixel_coords,\n",
    "        matching_results,\n",
    "        vis_path,\n",
    "        max_dimension=4000\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Compute 2D Shift or Affine Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Computing transformation for no_gcps\n",
      "============================================================\n",
      "\n",
      "2D Shift:\n",
      "  Shift X: -67.23 px\n",
      "  Shift Y: -7.91 px\n",
      "  RMSE: 286.35 px\n",
      "  Points: 22\n",
      "\n",
      "Affine Transformation:\n",
      "  RMSE: 1291.77 px\n",
      "  Points: 22\n",
      "  \u2713 Using 2D shift (lower RMSE)\n",
      "\n",
      "============================================================\n",
      "Computing transformation for with_gcps\n",
      "============================================================\n",
      "\n",
      "2D Shift:\n",
      "  Shift X: -124.45 px\n",
      "  Shift Y: -37.95 px\n",
      "  RMSE: 267.75 px\n",
      "  Points: 22\n",
      "\n",
      "Affine Transformation:\n",
      "  RMSE: 1889.43 px\n",
      "  Points: 22\n",
      "  \u2713 Using 2D shift (lower RMSE)\n",
      "\n",
      "\u2713 Transformations saved to: outputs/gcp_matching/matches/transformations.json\n"
     ]
    }
   ],
   "source": [
    "# Check for required variables and set defaults if needed\n",
    "try:\n",
    "    _ = output_dir\n",
    "except NameError:\n",
    "    from pathlib import Path\n",
    "    output_dir = Path(\"outputs\")\n",
    "    print(f\"output_dir not defined, using default: {output_dir}\")\n",
    "\n",
    "try:\n",
    "    _ = matches_dir\n",
    "except NameError:\n",
    "    try:\n",
    "        _ = gcp_matching_dir\n",
    "    except NameError:\n",
    "        gcp_matching_dir = output_dir / \"gcp_matching\"\n",
    "    matches_dir = gcp_matching_dir / \"matches\"\n",
    "    matches_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"matches_dir not defined, using default: {matches_dir}\")\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "from typing import Tuple, Dict\n",
    "\n",
    "# Compute transformation from matches\n",
    "\n",
    "def remove_outliers_ransac(src_points: np.ndarray, dst_points: np.ndarray, threshold: float = 50.0, min_samples: int = 3) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Remove outliers using RANSAC-based approach.\n",
    "    \n",
    "    Returns:\n",
    "        (inlier_src, inlier_dst, inlier_mask)\n",
    "    \"\"\"\n",
    "    if len(src_points) < min_samples:\n",
    "        # Return original arrays with all True mask\n",
    "        mask = np.ones(len(src_points), dtype=bool)\n",
    "        return src_points, dst_points, mask\n",
    "        return src_points, dst_points, np.ones(len(src_points), dtype=bool)\n",
    "    \n",
    "    # Compute initial shift (mean offset)\n",
    "    offsets = dst_points - src_points\n",
    "    mean_offset = np.mean(offsets, axis=0)\n",
    "    \n",
    "    # Compute distances from mean offset\n",
    "    distances = np.linalg.norm(offsets - mean_offset, axis=1)\n",
    "    \n",
    "    # Use IQR method to identify outliers\n",
    "    q1 = np.percentile(distances, 25)\n",
    "    q3 = np.percentile(distances, 75)\n",
    "    iqr = q3 - q1\n",
    "    \n",
    "    # Outlier threshold: Q3 + 1.5 * IQR\n",
    "    outlier_threshold = q3 + 1.5 * iqr\n",
    "    \n",
    "    # Also use absolute threshold\n",
    "    inlier_mask = (distances <= outlier_threshold) & (distances <= threshold)\n",
    "    \n",
    "    # Ensure we have at least min_samples inliers\n",
    "    if np.sum(inlier_mask) < min_samples:\n",
    "        # Keep the min_samples points closest to the mean\n",
    "        # Keep the min_samples points closest to the mean\n",
    "        sorted_indices = np.argsort(distances)\n",
    "        inlier_mask = np.zeros(len(src_points), dtype=bool)\n",
    "        inlier_mask[sorted_indices[:min_samples]] = True\n",
    "        inlier_mask = np.zeros(len(src_points), dtype=bool)\n",
    "        inlier_mask[sorted_indices[:min_samples]] = True\n",
    "    \n",
    "    # Ensure inlier_mask is a proper boolean array\n",
    "    inlier_mask = np.asarray(inlier_mask, dtype=bool)\n",
    "    \n",
    "    # Return filtered points\n",
    "    return src_points[inlier_mask], dst_points[inlier_mask], inlier_mask\n",
    "\n",
    "def compute_transformation(matches: Dict, use_affine: bool = False) -> Dict:\n",
    "    \"\"\"\n",
    "    Compute 2D shift or affine transformation from GCP matches.\n",
    "    \n",
    "    Args:\n",
    "        matches: Dictionary with GCP matches\n",
    "        use_affine: If True, compute affine transformation; otherwise 2D shift\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with transformation parameters\n",
    "    \"\"\"\n",
    "    # Collect source and destination points\n",
    "    src_points = []\n",
    "    dst_points = []\n",
    "    \n",
    "    for gcp_id, match_data in matches.items():\n",
    "        # Use the best patch size match\n",
    "        best_patch_size = max(match_data.keys())\n",
    "        match = match_data[best_patch_size]\n",
    "        \n",
    "        src_points.append([match['expected_col'], match['expected_row']])\n",
    "        dst_points.append([match['matched_col'], match['matched_row']])\n",
    "    \n",
    "    src_points = np.array(src_points, dtype=np.float32)\n",
    "\n",
    "    dst_points = np.array(dst_points, dtype=np.float32)\n",
    "\n",
    "    # Remove outliers\n",
    "    src_points, dst_points, inlier_mask = remove_outliers_ransac(src_points, dst_points, threshold=100.0, min_samples=3)\n",
    "    \n",
    "    num_outliers = len(src_points) - np.sum(inlier_mask) if 'inlier_mask' in locals() else 0\n",
    "    num_outliers = len(src_points) - np.sum(inlier_mask) if inlier_mask is not None else 0\n",
    "    if num_outliers > 0:\n",
    "        print(f\"  Removed {num_outliers} outlier(s)\")\n",
    "    dst_points = np.array(dst_points, dtype=np.float32)\n",
    "    \n",
    "    if len(src_points) < min_samples:\n",
    "        # Return original arrays with all True mask\n",
    "        mask = np.ones(len(src_points), dtype=bool)\n",
    "        return src_points, dst_points, mask\n",
    "        return {'type': 'insufficient_points', 'error': 'Need at least 2 matches'}\n",
    "    \n",
    "    if use_affine and len(src_points) >= 3:\n",
    "        # Compute affine transformation (6 parameters)\n",
    "        # Requires at least 3 points\n",
    "        transform_matrix = cv2.getAffineTransform(\n",
    "            src_points[:3],\n",
    "            dst_points[:3]\n",
    "        )\n",
    "        \n",
    "        # Apply to all points to compute error\n",
    "        ones = np.ones((len(src_points), 1))\n",
    "        src_homogeneous = np.hstack([src_points, ones])\n",
    "        transformed = (transform_matrix @ src_homogeneous.T).T\n",
    "        \n",
    "        errors = dst_points - transformed\n",
    "        rmse = float(np.sqrt(np.mean(errors**2)))\n",
    "        \n",
    "        return {\n",
    "            'type': 'affine',\n",
    "            'matrix': transform_matrix.tolist(),\n",
    "            'rmse': rmse,\n",
    "            'num_points': len(src_points)\n",
    "        }\n",
    "    else:\n",
    "        # Compute 2D shift (mean offset)\n",
    "        offsets = dst_points - src_points\n",
    "        shift_x = float(np.mean(offsets[:, 0]))\n",
    "        shift_y = float(np.mean(offsets[:, 1]))\n",
    "        \n",
    "        # Compute RMSE\n",
    "        errors = offsets - np.array([shift_x, shift_y])\n",
    "        rmse = float(np.sqrt(np.mean(errors**2)))\n",
    "        \n",
    "        return {\n",
    "            'type': 'shift',\n",
    "            'shift_x': shift_x,\n",
    "            'shift_y': shift_y,\n",
    "            'rmse': rmse,\n",
    "            'num_points': len(src_points)\n",
    "        }\n",
    "\n",
    "# Compute transformations for each ortho\n",
    "transformations = {}\n",
    "\n",
    "\n",
    "# Check if matching_results is defined, load from file if not\n",
    "try:\n",
    "    _ = matching_results\n",
    "    print(\"\u2713 matching_results found in memory\")\n",
    "except NameError:\n",
    "    print(\"matching_results not in memory, attempting to load from file...\")\n",
    "    try:\n",
    "        matches_json = matches_dir / \"matching_results.json\"\n",
    "        if matches_json.exists():\n",
    "            with open(matches_json, 'r') as f:\n",
    "                matching_results = json.load(f)\n",
    "            print(f\"\u2713 Loaded matching_results from {matches_json}\")\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"matching_results.json not found at {matches_json}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\u274c Could not load matching_results: {e}\")\n",
    "        print(\"Please run Step 6 (patch matching) first.\")\n",
    "        raise\n",
    "\n",
    "for ortho_name in matching_results.keys():\n",
    "\n",
    "    # Print match pixel locations for verification\n",
    "    print(f\"\\nMatch pixel locations:\")\n",
    "    for gcp_id, match_data in matching_results[ortho_name].items():\n",
    "        best_patch_size = max(match_data.keys()) if match_data else None\n",
    "        if best_patch_size:\n",
    "            match = match_data[best_patch_size]\n",
    "            print(f\"  {gcp_id}: Expected=({match['expected_col']:.1f}, {match['expected_row']:.1f}), \")\n",
    "            print(f\"         Matched=({match['matched_col']:.1f}, {match['matched_row']:.1f}), \")\n",
    "            print(f\"         Offset=({match['offset_col']:.1f}, {match['offset_row']:.1f}) px\")\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Computing transformation for {ortho_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Try 2D shift first\n",
    "    shift_result = compute_transformation(matching_results[ortho_name], use_affine=False)\n",
    "    print(f\"\\n2D Shift:\")\n",
    "    shift_x_val = shift_result.get('shift_x', 'N/A')\n",
    "    shift_x_str = f\"{shift_x_val:.2f}\" if isinstance(shift_x_val, (int, float)) else str(shift_x_val)\n",
    "    print(f\"  Shift X: {shift_x_str} px\")\n",
    "    shift_y_val = shift_result.get('shift_y', 'N/A')\n",
    "    shift_y_str = f\"{shift_y_val:.2f}\" if isinstance(shift_y_val, (int, float)) else str(shift_y_val)\n",
    "    print(f\"  Shift Y: {shift_y_str} px\")\n",
    "    rmse_val = shift_result.get('rmse', 'N/A')\n",
    "    rmse_str = f\"{rmse_val:.2f}\" if isinstance(rmse_val, (int, float)) else str(rmse_val)\n",
    "    print(f\"  RMSE: {rmse_str} px\")\n",
    "    print(f\"  Points: {shift_result.get('num_points', 0)}\")\n",
    "    \n",
    "    # Try affine if we have enough points\n",
    "    # Try affine if we have enough points\n",
    "    if len(matching_results[ortho_name]) >= 3:\n",
    "        affine_result = compute_transformation(matching_results[ortho_name], use_affine=True)\n",
    "        print(f\"\\nAffine Transformation:\")\n",
    "        affine_rmse_val = affine_result.get('rmse', 'N/A')\n",
    "\n",
    "        affine_rmse_str = f\"{affine_rmse_val:.2f}\" if isinstance(affine_rmse_val, (int, float)) else str(affine_rmse_val)\n",
    "\n",
    "        print(f\"  RMSE: {affine_rmse_str} px\")\n",
    "        print(f\"  Points: {affine_result.get('num_points', 0)}\")\n",
    "\n",
    "        # Use the one with lower RMSE\n",
    "        if affine_result.get('rmse', float('inf')) < shift_result.get('rmse', float('inf')):\n",
    "            transformations[ortho_name] = affine_result\n",
    "            print(f\"  \u2713 Using affine transformation (lower RMSE)\")\n",
    "        else:\n",
    "            transformations[ortho_name] = shift_result\n",
    "            print(f\"  \u2713 Using 2D shift (lower RMSE)\")\n",
    "    else:\n",
    "        transformations[ortho_name] = shift_result\n",
    "        print(f\"  \u2713 Using 2D shift (insufficient points for affine)\")\n",
    "\n",
    "transformations_file = matches_dir / \"transformations.json\"\n",
    "\n",
    "with open(transformations_file, 'w') as f:\n",
    "    json.dump(transformations, f, indent=2)\n",
    "\n",
    "print(f\"\\n\u2713 Transformations saved to: {transformations_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Apply Transformation and Register Orthomosaics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Registering no_gcps...\n"
     ]
    }
   ],
   "source": [
    "# Apply transformation to orthomosaic\n",
    "def apply_transformation(\n",
    "    ortho_path: Path,\n",
    "    transformation: Dict,\n",
    "    output_path: Path,\n",
    "    basemap_path: Path\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    Apply transformation to register orthomosaic to basemap.\n",
    "    \"\"\"\n",
    "    with rasterio.open(basemap_path) as basemap_src:\n",
    "        target_width = basemap_src.width\n",
    "        target_height = basemap_src.height\n",
    "        target_transform = basemap_src.transform\n",
    "        target_crs = basemap_src.crs\n",
    "    \n",
    "    with rasterio.open(ortho_path) as ortho_src:\n",
    "        source_data = ortho_src.read()\n",
    "        source_count = ortho_src.count\n",
    "        \n",
    "        # Apply transformation\n",
    "        if transformation['type'] == 'shift':\n",
    "            # Apply 2D shift using scipy\n",
    "            shift_x = transformation['shift_x']\n",
    "            shift_y = transformation['shift_y']\n",
    "            \n",
    "            registered_data = np.zeros((source_count, target_height, target_width), dtype=source_data.dtype)\n",
    "            \n",
    "            for band_idx in range(source_count):\n",
    "                shifted = ndimage.shift(\n",
    "                    source_data[band_idx],\n",
    "                    (shift_y, shift_x),\n",
    "                    mode='constant',\n",
    "                    cval=0,\n",
    "                    order=1\n",
    "                )\n",
    "                \n",
    "                # Crop or pad to match target dimensions\n",
    "                if shifted.shape[0] > target_height:\n",
    "                    shifted = shifted[:target_height, :]\n",
    "                elif shifted.shape[0] < target_height:\n",
    "                    padded = np.zeros((target_height, shifted.shape[1]), dtype=shifted.dtype)\n",
    "                    padded[:shifted.shape[0], :] = shifted\n",
    "                    shifted = padded\n",
    "                \n",
    "                if shifted.shape[1] > target_width:\n",
    "                    shifted = shifted[:, :target_width]\n",
    "                elif shifted.shape[1] < target_width:\n",
    "                    padded = np.zeros((target_height, target_width), dtype=shifted.dtype)\n",
    "                    padded[:, :shifted.shape[1]] = shifted\n",
    "                    shifted = padded\n",
    "                \n",
    "                registered_data[band_idx] = shifted\n",
    "        \n",
    "        elif transformation['type'] == 'affine':\n",
    "            # Apply affine transformation\n",
    "            transform_matrix = np.array(transformation['matrix'], dtype=np.float32)\n",
    "            \n",
    "            registered_data = np.zeros((source_count, target_height, target_width), dtype=source_data.dtype)\n",
    "            \n",
    "            # Convert to (H, W, C) for OpenCV\n",
    "            if source_count == 1:\n",
    "                img = source_data[0]\n",
    "            else:\n",
    "                img = np.transpose(source_data, (1, 2, 0))\n",
    "            \n",
    "            # Apply affine transform\n",
    "            registered_img = cv2.warpAffine(\n",
    "                img.astype(np.uint8),\n",
    "                transform_matrix,\n",
    "                (target_width, target_height),\n",
    "                flags=cv2.INTER_LINEAR,\n",
    "                borderMode=cv2.BORDER_CONSTANT,\n",
    "                borderValue=0\n",
    "            )\n",
    "            \n",
    "            # Convert back to (C, H, W)\n",
    "            if source_count == 1:\n",
    "                registered_data[0] = registered_img\n",
    "            else:\n",
    "                registered_data = np.transpose(registered_img, (2, 0, 1))\n",
    "        \n",
    "        # Save registered orthomosaic\n",
    "        with rasterio.open(\n",
    "            output_path,\n",
    "            'w',\n",
    "            driver='GTiff',\n",
    "            height=target_height,\n",
    "            width=target_width,\n",
    "            count=source_count,\n",
    "            dtype=registered_data.dtype,\n",
    "            crs=target_crs,\n",
    "            transform=target_transform,\n",
    "            compress='lzw',\n",
    "            BIGTIFF='YES',\n",
    "            tiled=True\n",
    "        ) as dst:\n",
    "            dst.write(registered_data)\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "# Register orthos\n",
    "registered_paths = {}\n",
    "\n",
    "for ortho_name, transformation in transformations.items():\n",
    "    if 'error' in transformation:\n",
    "        print(f\"\u26a0\ufe0f  Skipping {ortho_name}: {transformation['error']}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nRegistering {ortho_name}...\")\n",
    "    \n",
    "    registered_path = apply_transformation(\n",
    "        reprojected_paths[ortho_name],\n",
    "        transformation,\n",
    "        registered_dir / f\"{ortho_name}_registered.tif\",\n",
    "        basemap_path\n",
    "    )\n",
    "    \n",
    "    registered_paths[ortho_name] = registered_path\n",
    "    print(f\"  \u2713 Saved: {registered_path}\")\n",
    "\n",
    "print(f\"\\n\u2713 Registration complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Evaluate Accuracy Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare registered orthos to basemap\n",
    "def evaluate_accuracy(ortho_path: Path, basemap_path: Path, gcps: List[Dict]) -> Dict:\n",
    "    \"\"\"\n",
    "    Evaluate accuracy by comparing pixel values at GCP locations.\n",
    "    \"\"\"\n",
    "    with rasterio.open(basemap_path) as basemap_src:\n",
    "        basemap_data = basemap_src.read()\n",
    "    \n",
    "    with rasterio.open(ortho_path) as ortho_src:\n",
    "        ortho_data = ortho_src.read()\n",
    "    \n",
    "    errors = []\n",
    "    \n",
    "    for gcp in gcps:\n",
    "        pixel_coords = gcp_to_pixel_coords(gcp['lat'], gcp['lon'], basemap_path)\n",
    "        if not pixel_coords:\n",
    "            continue\n",
    "        \n",
    "        col, row = pixel_coords\n",
    "        \n",
    "        if 0 <= row < basemap_data.shape[1] and 0 <= col < basemap_data.shape[2]:\n",
    "            basemap_pixel = basemap_data[:, row, col]\n",
    "            \n",
    "            if 0 <= row < ortho_data.shape[1] and 0 <= col < ortho_data.shape[2]:\n",
    "                ortho_pixel = ortho_data[:, row, col]\n",
    "                \n",
    "                # Compute error (Euclidean distance in pixel space)\n",
    "                error = np.sqrt(np.sum((basemap_pixel.astype(float) - ortho_pixel.astype(float))**2))\n",
    "                errors.append(error)\n",
    "    \n",
    "    if errors:\n",
    "        return {\n",
    "            'mean_error': float(np.mean(errors)),\n",
    "            'rmse': float(np.sqrt(np.mean(np.array(errors)**2))),\n",
    "            'max_error': float(np.max(errors)),\n",
    "            'num_points': len(errors)\n",
    "        }\n",
    "    else:\n",
    "        return {'error': 'No valid GCPs found'}\n",
    "\n",
    "# Evaluate accuracy for original and registered orthos\n",
    "accuracy_results = {}\n",
    "\n",
    "for ortho_name in reprojected_paths.keys():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Accuracy evaluation: {ortho_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Original (reprojected but not registered)\n",
    "    original_accuracy = evaluate_accuracy(\n",
    "        reprojected_paths[ortho_name],\n",
    "        basemap_path,\n",
    "        gcps\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nOriginal (reprojected):\")\n",
    "    print(f\"  Mean error: {original_accuracy.get('mean_error', 'N/A'):.2f}\")\n",
    "    print(f\"  RMSE: {original_accuracy.get('rmse', 'N/A'):.2f}\")\n",
    "    \n",
    "    # Registered\n",
    "    if ortho_name in registered_paths:\n",
    "        registered_accuracy = evaluate_accuracy(\n",
    "            registered_paths[ortho_name],\n",
    "            basemap_path,\n",
    "            gcps\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nRegistered:\")\n",
    "        print(f\"  Mean error: {registered_accuracy.get('mean_error', 'N/A'):.2f}\")\n",
    "        print(f\"  RMSE: {registered_accuracy.get('rmse', 'N/A'):.2f}\")\n",
    "        \n",
    "        improvement = ((original_accuracy.get('rmse', 0) - registered_accuracy.get('rmse', 0)) / original_accuracy.get('rmse', 1)) * 100\n",
    "        print(f\"\\n  Improvement: {improvement:.1f}%\")\n",
    "        \n",
    "        accuracy_results[ortho_name] = {\n",
    "            'original': original_accuracy,\n",
    "            'registered': registered_accuracy,\n",
    "            'improvement_percent': improvement\n",
    "        }\n",
    "    else:\n",
    "        accuracy_results[ortho_name] = {\n",
    "            'original': original_accuracy\n",
    "        }\n",
    "\n",
    "# Save results\n",
    "results_file = gcp_matching_dir / \"accuracy_results.json\"\n",
    "with open(results_file, 'w') as f:\n",
    "    json.dump(accuracy_results, f, indent=2)\n",
    "\n",
    "print(f\"\\n\u2713 Accuracy results saved to: {results_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}