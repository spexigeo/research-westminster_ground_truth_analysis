{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# GCP-Based Patch Matching for Orthomosaic Registration\n",
    "\n",
    "This notebook performs patch matching to find ground control points (GCPs) in orthomosaics and uses them to register the orthos to the basemap.\n",
    "\n",
    "## Approach:\n",
    "1. Load GCPs from CSV file (WGS84 coordinates)\n",
    "2. Extract patches from basemap centered on each GCP\n",
    "3. Use template matching to find corresponding patches in orthomosaics\n",
    "4. Compute 2D shift or affine transformation from matches\n",
    "5. Apply transformation to register orthos to basemap\n",
    "6. Evaluate accuracy improvement\n",
    "\n",
    "## Inputs:\n",
    "- **Basemap**: `TestsiteNewWest_Spexigeo_RTK.tiff`\n",
    "- **GCPs**: `25-3288-CONTROL-NAD83-UTM10N-EGM2008.csv` (converted to WGS84)\n",
    "- **Orthomosaics**: \n",
    "  - `outputs/orthomosaics/orthomosaic_no_gcps.tif`\n",
    "  - `outputs/orthomosaics/orthomosaic_with_gcps.tif`\n",
    "\n",
    "## Outputs:\n",
    "- All outputs saved to `outputs/gcp_matching/`\n",
    "- Patches extracted from basemap\n",
    "- Matched GCP locations in orthos\n",
    "- Registered orthomosaics\n",
    "- Accuracy evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if needed\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "packages = [\n",
    "    'rasterio',\n",
    "    'numpy',\n",
    "    'matplotlib',\n",
    "    'opencv-python',\n",
    "    'scipy',\n",
    "    'utm',\n",
    "    'pillow'\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    try:\n",
    "        __import__(package.replace('-', '_'))\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])\n",
    "\n",
    "print(\"\u2713 Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup - Imports and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 Output directory: outputs/gcp_matching\n",
      "  - Patches: outputs/gcp_matching/patches\n",
      "  - Matches: outputs/gcp_matching/matches\n",
      "  - Registered: outputs/gcp_matching/registered\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.transform import xy\n",
    "from rasterio.warp import transform as transform_coords\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "import json\n",
    "import csv\n",
    "import utm\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup paths\n",
    "data_dir = Path(\"/Users/mauriciohessflores/Documents/Code/Data/New Westminster Oct _25\")\n",
    "output_dir = Path(\"outputs\")\n",
    "\n",
    "# Input files\n",
    "basemap_path = data_dir / \"Michael_RTK_orthos\" / \"TestsiteNewWest_Spexigeo_RTK.tiff\"\n",
    "gcp_csv_path = data_dir / \"25-3288-CONTROL-NAD83-UTM10N-EGM2008.csv\"\n",
    "ortho_no_gcps_path = output_dir / \"orthomosaics\" / \"orthomosaic_no_gcps.tif\"\n",
    "ortho_with_gcps_path = output_dir / \"orthomosaics\" / \"orthomosaic_with_gcps.tif\"\n",
    "\n",
    "# Output directories\n",
    "gcp_matching_dir = output_dir / \"gcp_matching\"\n",
    "gcp_matching_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "patches_dir = gcp_matching_dir / \"patches\"\n",
    "patches_dir.mkdir(exist_ok=True)\n",
    "\n",
    "matches_dir = gcp_matching_dir / \"matches\"\n",
    "matches_dir.mkdir(exist_ok=True)\n",
    "\n",
    "registered_dir = gcp_matching_dir / \"registered\"\n",
    "registered_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"\u2713 Output directory: {gcp_matching_dir}\")\n",
    "print(f\"  - Patches: {patches_dir}\")\n",
    "print(f\"  - Matches: {matches_dir}\")\n",
    "print(f\"  - Registered: {registered_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Update paths for Colab\n",
    "data_dir = Path(\"/content/drive/MyDrive/Data/New Westminster Oct _25\")\n",
    "output_dir = Path(\"/content/drive/MyDrive/Code/MyCode/research-westminster_ground_truth_analysis/outputs\")\n",
    "\n",
    "# Update other paths accordingly\n",
    "basemap_path = data_dir / \"Michael_RTK_orthos\" / \"TestsiteNewWest_Spexigeo_RTK.tiff\"\n",
    "gcp_csv_path = data_dir / \"25-3288-CONTROL-NAD83-UTM10N-EGM2008.csv\"\n",
    "ortho_no_gcps_path = output_dir / \"orthomosaics\" / \"orthomosaic_no_gcps.tif\"\n",
    "ortho_with_gcps_path = output_dir / \"orthomosaics\" / \"orthomosaic_with_gcps.tif\"\n",
    "\n",
    "print(\"\u2713 Colab paths configured\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load GCPs from UTM CSV file\n",
    "def load_gcps_from_csv(csv_path: Path) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Load GCPs from UTM CSV file and convert to WGS84.\n",
    "    \n",
    "    Expected format: ID, Northing, Easting, Elevation, Name\n",
    "    \"\"\"\n",
    "    import csv\n",
    "    \n",
    "    gcps = []\n",
    "    \n",
    "    with open(csv_path, 'r') as f:\n",
    "        # Try to detect if there's a header\n",
    "        first_line = f.readline().strip()\n",
    "        f.seek(0)  # Reset to beginning\n",
    "        \n",
    "        # Check if first line is numeric (no header)\n",
    "        try:\n",
    "            float(first_line.split(',')[0])\n",
    "            has_header = False\n",
    "        except (ValueError, IndexError):\n",
    "            has_header = True\n",
    "        \n",
    "        reader = csv.reader(f) if not has_header else csv.DictReader(f)\n",
    "        \n",
    "        for row_idx, row in enumerate(reader):\n",
    "            try:\n",
    "                if has_header:\n",
    "                    # Try to find columns\n",
    "                    northing = float(row.get('Northing', row.get('northing', row.get('Y', 0))))\n",
    "                    easting = float(row.get('Easting', row.get('easting', row.get('X', 0))))\n",
    "                    gcp_id = row.get('Name', row.get('name', row.get('ID', row.get('id', f\"GCP_{row_idx+1}\"))))\n",
    "                else:\n",
    "                    # Positional format: ID, Northing, Easting, Elevation, Name\n",
    "                    if len(row) < 3:\n",
    "                        continue\n",
    "                    gcp_id = row[0].strip() if row[0] else f\"GCP_{row_idx+1}\"\n",
    "                    northing = float(row[1])  # Column 1 = Northing\n",
    "                    easting = float(row[2])   # Column 2 = Easting\n",
    "                \n",
    "                # Convert UTM to WGS84 (UTM Zone 10N)\n",
    "                lat, lon = utm.to_latlon(easting, northing, 10, 'N')\n",
    "                \n",
    "                gcps.append({\n",
    "                    'id': gcp_id,\n",
    "                    'lat': lat,\n",
    "                    'lon': lon,\n",
    "                    'x_utm': easting,\n",
    "                    'y_utm': northing\n",
    "                })\n",
    "            except (ValueError, IndexError) as e:\n",
    "                print(f\"\u26a0\ufe0f  Skipping row {row_idx+1}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    return gcps\n",
    "\n",
    "## Step 2: Load GCPs from CSV and Convert to WGS84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u26a0\ufe0f  Could not find required columns. Found: ['1', '5450945.525', '506914.123', '77.453', 'GCP1']\n",
      "   Looking for: name/id, x/easting, y/northing\n",
      "\u2713 Loaded 0 GCPs from CSV\n",
      "\u26a0\ufe0f  No GCPs loaded! Check CSV format.\n",
      "   CSV path: /Users/mauriciohessflores/Documents/Code/Data/New Westminster Oct _25/25-3288-CONTROL-NAD83-UTM10N-EGM2008.csv\n",
      "   File exists. Showing first few lines:\n",
      "     1,5450945.525,506914.123,77.453,GCP1\n",
      "     2,5450730.008,506657.794,79.218,GCP2\n",
      "     3,5450480.009,506577.772,59.4,GCP3\n",
      "     4,5450578.626,506765.034,65.591,GCP4\n",
      "     5,5450715.958,506926.13,63.103,GCP5\n"
     ]
    }
   ],
   "source": [
    "# Load GCPs - try existing WGS84 files first, otherwise parse CSV\n",
    "import json\n",
    "\n",
    "# Check for existing WGS84 GCP files from ground control comparison\n",
    "gcps_wgs84_geojson = output_dir / \"ground_control_comparison\" / \"gcps_wgs84.geojson\"\n",
    "gcps_wgs84_csv = output_dir / \"ground_control_comparison\" / \"gcps_wgs84.csv\"\n",
    "\n",
    "gcps = []\n",
    "\n",
    "# Try GeoJSON first (preferred)\n",
    "if gcps_wgs84_geojson.exists():\n",
    "    print(f\"Loading GCPs from GeoJSON: {gcps_wgs84_geojson}\")\n",
    "    with open(gcps_wgs84_geojson, 'r') as f:\n",
    "        geojson_data = json.load(f)\n",
    "    \n",
    "    if 'features' in geojson_data:\n",
    "        for feature in geojson_data['features']:\n",
    "            props = feature.get('properties', {})\n",
    "            geom = feature.get('geometry', {})\n",
    "            \n",
    "            if geom.get('type') == 'Point':\n",
    "                coords = geom.get('coordinates', [])\n",
    "                if len(coords) >= 2:\n",
    "                    lon, lat = coords[0], coords[1]\n",
    "                    \n",
    "                    # Get UTM coordinates from properties or convert\n",
    "                    x_utm = props.get('x_utm')\n",
    "                    y_utm = props.get('y_utm')\n",
    "                    \n",
    "                    if x_utm is None or y_utm is None:\n",
    "                        # Convert WGS84 to UTM\n",
    "                        import utm\n",
    "                        x_utm, y_utm, zone_num, zone_letter = utm.from_latlon(lat, lon)\n",
    "                    \n",
    "                    gcps.append({\n",
    "                        'id': props.get('id', props.get('name', f\"GCP_{len(gcps)+1}\")),\n",
    "                        'lat': lat,\n",
    "                        'lon': lon,\n",
    "                        'x_utm': float(x_utm),\n",
    "                        'y_utm': float(y_utm)\n",
    "                    })\n",
    "    \n",
    "    print(f\"\u2713 Loaded {len(gcps)} GCPs from GeoJSON\")\n",
    "\n",
    "# Try CSV if GeoJSON not found\n",
    "elif gcps_wgs84_csv.exists():\n",
    "    print(f\"Loading GCPs from WGS84 CSV: {gcps_wgs84_csv}\")\n",
    "    with open(gcps_wgs84_csv, 'r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            try:\n",
    "                lat = float(row.get('lat', row.get('latitude', 0)))\n",
    "                lon = float(row.get('lon', row.get('longitude', row.get('lon', 0))))\n",
    "                gcp_id = row.get('id', row.get('name', row.get('label', f\"GCP_{len(gcps)+1}\")))\n",
    "                \n",
    "                # Get UTM from row or convert\n",
    "                x_utm_str = row.get('x_utm', '')\n",
    "                y_utm_str = row.get('y_utm', '')\n",
    "                \n",
    "                if x_utm_str and y_utm_str:\n",
    "                    x_utm = float(x_utm_str)\n",
    "                    y_utm = float(y_utm_str)\n",
    "                else:\n",
    "                    import utm\n",
    "                    x_utm, y_utm, zone_num, zone_letter = utm.from_latlon(lat, lon)\n",
    "                \n",
    "                gcps.append({\n",
    "                    'id': gcp_id,\n",
    "                    'lat': lat,\n",
    "                    'lon': lon,\n",
    "                    'x_utm': x_utm,\n",
    "                    'y_utm': y_utm\n",
    "                })\n",
    "            except (ValueError, KeyError) as e:\n",
    "                print(f\"\u26a0\ufe0f  Skipping row: {e}\")\n",
    "                continue\n",
    "    \n",
    "    print(f\"\u2713 Loaded {len(gcps)} GCPs from WGS84 CSV\")\n",
    "\n",
    "# Fallback to parsing UTM CSV\n",
    "if len(gcps) == 0:\n",
    "    print(f\"\\nNo WGS84 GCP files found, parsing UTM CSV: {gcp_csv_path}\")\n",
    "    gcps = load_gcps_from_csv(gcp_csv_path)\n",
    "    print(f\"\u2713 Loaded {len(gcps)} GCPs from UTM CSV\")\n",
    "\n",
    "if len(gcps) > 0:\n",
    "    print(f\"\\nFirst few GCPs:\")\n",
    "    for gcp in gcps[:3]:\n",
    "        print(f\"  {gcp['id']}: UTM=({gcp['x_utm']:.2f}, {gcp['y_utm']:.2f}), WGS84=({gcp['lat']:.6f}, {gcp['lon']:.6f})\")\n",
    "else:\n",
    "    print(f\"\u26a0\ufe0f  No GCPs loaded!\")\n",
    "    print(f\"   Checked:\")\n",
    "    print(f\"   - {gcps_wgs84_geojson}\")\n",
    "    print(f\"   - {gcps_wgs84_csv}\")\n",
    "    print(f\"   - {gcp_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basemap CRS: EPSG:32610\n",
      "Basemap dimensions: 90129x90188\n",
      "Basemap bounds: BoundingBox(left=506424.37839793676, bottom=5450017.622213458, right=507501.0951215451, top=5451095.043774429)\n",
      "Basemap transform: | 0.01, 0.00, 506424.38|\n",
      "| 0.00,-0.01, 5451095.04|\n",
      "| 0.00, 0.00, 1.00|\n",
      "\n",
      "GCP GCP1: UTM=(506914.12, 5450945.53)\n",
      "  \u2713 Found at pixel: col=40995, row=12515\n",
      "\n",
      "GCP GCP2: UTM=(506657.79, 5450730.01)\n",
      "  \u2713 Found at pixel: col=19538, row=30556\n",
      "\n",
      "GCP GCP3: UTM=(506577.77, 5450480.01)\n",
      "  \u2713 Found at pixel: col=12840, row=51482\n",
      "\n",
      "GCP GCP4: UTM=(506765.03, 5450578.63)\n",
      "  \u2713 Found at pixel: col=28515, row=43227\n",
      "\n",
      "GCP GCP5: UTM=(506926.13, 5450715.96)\n",
      "  \u2713 Found at pixel: col=42000, row=31732\n",
      "\n",
      "GCP GCP6: UTM=(507071.92, 5450992.66)\n",
      "  \u2713 Found at pixel: col=54203, row=8570\n",
      "\n",
      "GCP GCP7: UTM=(507089.40, 5450794.23)\n",
      "  \u2713 Found at pixel: col=55667, row=25180\n",
      "\n",
      "GCP GCP8: UTM=(507315.01, 5450717.85)\n",
      "  \u2713 Found at pixel: col=74551, row=31574\n",
      "\n",
      "GCP GCP9: UTM=(507252.65, 5450536.03)\n",
      "  \u2713 Found at pixel: col=69332, row=46793\n",
      "\n",
      "GCP GCP10: UTM=(507072.02, 5450500.33)\n",
      "  \u2713 Found at pixel: col=54212, row=49782\n",
      "\n",
      "GCP GCP11: UTM=(507020.05, 5450595.29)\n",
      "  \u2713 Found at pixel: col=49861, row=41832\n",
      "\n",
      "GCP GCP12: UTM=(506885.91, 5450346.64)\n",
      "  \u2713 Found at pixel: col=38633, row=62646\n",
      "\n",
      "GCP GCP13: UTM=(506586.74, 5450323.69)\n",
      "  \u2713 Found at pixel: col=13590, row=64568\n",
      "\n",
      "GCP GCP14: UTM=(506746.87, 5450378.55)\n",
      "  \u2713 Found at pixel: col=26994, row=59975\n",
      "\n",
      "GCP GCP15: UTM=(506903.07, 5450193.68)\n",
      "  \u2713 Found at pixel: col=40069, row=75450\n",
      "\n",
      "GCP GCP16: UTM=(506977.00, 5450109.82)\n",
      "  \u2713 Found at pixel: col=46258, row=82470\n",
      "\n",
      "GCP CP1: UTM=(507060.63, 5450345.17)\n",
      "  \u2713 Found at pixel: col=53258, row=62769\n",
      "\n",
      "GCP CP2: UTM=(506911.89, 5450506.71)\n",
      "  \u2713 Found at pixel: col=40808, row=49247\n",
      "\n",
      "GCP CP3: UTM=(506821.64, 5450292.79)\n",
      "  \u2713 Found at pixel: col=33254, row=67154\n",
      "\n",
      "GCP CP4: UTM=(507148.30, 5450712.13)\n",
      "  \u2713 Found at pixel: col=60597, row=32052\n",
      "\n",
      "GCP CP5: UTM=(506800.86, 5450859.45)\n",
      "  \u2713 Found at pixel: col=31514, row=19720\n",
      "\n",
      "GCP OMON 6076: UTM=(506864.18, 5450326.10)\n",
      "  \u2713 Found at pixel: col=36814, row=64366\n",
      "\n",
      "GCP OMON 6066: UTM=(507163.74, 5450716.44)\n",
      "  \u2713 Found at pixel: col=61889, row=31691\n",
      "\n",
      "\u2713 Found 23 GCPs within basemap bounds\n",
      "\n",
      "First few GCP pixel coordinates:\n",
      "  GCP1: col=40995, row=12515\n",
      "  GCP2: col=19538, row=30556\n",
      "  GCP3: col=12840, row=51482\n"
     ]
    }
   ],
   "source": [
    "# Convert GCPs (UTM) to pixel coordinates in basemap\n",
    "def gcp_to_pixel_coords_from_utm(gcp_x_utm: float, gcp_y_utm: float, raster_path: Path) -> Optional[Tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    Convert GCP UTM coordinates to pixel coordinates in raster.\n",
    "    \n",
    "    Args:\n",
    "        gcp_x_utm: UTM Easting (EPSG:32610)\n",
    "        gcp_y_utm: UTM Northing (EPSG:32610)\n",
    "        raster_path: Path to raster file\n",
    "    \n",
    "    Returns:\n",
    "        (col, row) or None if outside bounds.\n",
    "    \"\"\"\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        # Raster should be in EPSG:32610 (UTM Zone 10N)\n",
    "        if src.crs != 'EPSG:32610':\n",
    "            # Transform UTM to raster CRS if needed\n",
    "            x, y = transform_coords(\n",
    "                'EPSG:32610',\n",
    "                src.crs,\n",
    "                [gcp_x_utm],\n",
    "                [gcp_y_utm]\n",
    "            )\n",
    "            utm_x, utm_y = x[0], y[0]\n",
    "        else:\n",
    "            utm_x, utm_y = gcp_x_utm, gcp_y_utm\n",
    "        \n",
    "        # Convert to pixel coordinates\n",
    "        row, col = rasterio.transform.rowcol(src.transform, utm_x, utm_y)\n",
    "        \n",
    "        # Check if within bounds\n",
    "        if 0 <= row < src.height and 0 <= col < src.width:\n",
    "            return (col, row)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "# Get basemap CRS and transform\n",
    "with rasterio.open(basemap_path) as basemap_src:\n",
    "    basemap_crs = basemap_src.crs\n",
    "    basemap_transform = basemap_src.transform\n",
    "    basemap_width = basemap_src.width\n",
    "    basemap_height = basemap_src.height\n",
    "    basemap_bounds = basemap_src.bounds\n",
    "\n",
    "print(f\"Basemap CRS: {basemap_crs}\")\n",
    "print(f\"Basemap dimensions: {basemap_width}x{basemap_height}\")\n",
    "print(f\"Basemap bounds: {basemap_bounds}\")\n",
    "print(f\"Basemap transform: {basemap_transform}\")\n",
    "\n",
    "# Convert all GCPs to pixel coordinates\n",
    "gcp_pixel_coords = {}\n",
    "for gcp in gcps:\n",
    "    # Debug: show GCP UTM coordinates\n",
    "    print(f\"\\nGCP {gcp['id']}: UTM=({gcp['x_utm']:.2f}, {gcp['y_utm']:.2f})\")\n",
    "    \n",
    "    pixel_coords = gcp_to_pixel_coords_from_utm(gcp['x_utm'], gcp['y_utm'], basemap_path)\n",
    "    if pixel_coords:\n",
    "        gcp_pixel_coords[gcp['id']] = {\n",
    "            'gcp': gcp,\n",
    "            'pixel_col': pixel_coords[0],\n",
    "            'pixel_row': pixel_coords[1],\n",
    "            'utm_x': gcp.get('x_utm'),\n",
    "            'utm_y': gcp.get('y_utm'),\n",
    "        }\n",
    "        print(f\"  \u2713 Found at pixel: col={pixel_coords[0]}, row={pixel_coords[1]}\")\n",
    "    else:\n",
    "        # Debug: show why it's outside bounds\n",
    "        with rasterio.open(basemap_path) as src:\n",
    "            row, col = rasterio.transform.rowcol(src.transform, gcp['x_utm'], gcp['y_utm'])\n",
    "            print(f\"  \u26a0\ufe0f  Outside bounds: col={col}, row={row}\")\n",
    "            print(f\"     Basemap: {src.width}x{src.height}\")\n",
    "            print(f\"     Basemap bounds: {src.bounds}\")\n",
    "            # Check if coordinates are in bounds in UTM space\n",
    "            in_x = src.bounds.left <= gcp['x_utm'] <= src.bounds.right\n",
    "            in_y = src.bounds.bottom <= gcp['y_utm'] <= src.bounds.top\n",
    "            print(f\"     UTM X in bounds: {in_x} ({src.bounds.left:.2f} <= {gcp['x_utm']:.2f} <= {src.bounds.right:.2f})\")\n",
    "            print(f\"     UTM Y in bounds: {in_y} ({src.bounds.bottom:.2f} <= {gcp['y_utm']:.2f} <= {src.bounds.top:.2f})\")\n",
    "\n",
    "print(f\"\\n\u2713 Found {len(gcp_pixel_coords)} GCPs within basemap bounds\")\n",
    "if len(gcp_pixel_coords) > 0:\n",
    "    print(f\"\\nFirst few GCP pixel coordinates:\")\n",
    "    for gcp_id, coords in list(gcp_pixel_coords.items())[:3]:\n",
    "        print(f\"  {gcp_id}: col={coords['pixel_col']}, row={coords['pixel_row']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert GCPs (WGS84) to pixel coordinates in basemap\n",
    "def gcp_to_pixel_coords(gcp_lat: float, gcp_lon: float, raster_path: Path) -> Optional[Tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    Convert GCP lat/lon to pixel coordinates in raster.\n",
    "    \n",
    "    Returns (col, row) or None if outside bounds.\n",
    "    \"\"\"\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        # Transform WGS84 to raster CRS\n",
    "        x, y = transform_coords(\n",
    "            'EPSG:4326',  # WGS84\n",
    "            src.crs,\n",
    "            [gcp_lon],\n",
    "            [gcp_lat]\n",
    "        )\n",
    "        \n",
    "        # Convert to pixel coordinates\n",
    "        row, col = rasterio.transform.rowcol(src.transform, x[0], y[0])\n",
    "        \n",
    "        # Check if within bounds\n",
    "        if 0 <= row < src.height and 0 <= col < src.width:\n",
    "            return (col, row)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "# Get basemap CRS and transform\n",
    "with rasterio.open(basemap_path) as basemap_src:\n",
    "    basemap_crs = basemap_src.crs\n",
    "    basemap_transform = basemap_src.transform\n",
    "    basemap_width = basemap_src.width\n",
    "    basemap_height = basemap_src.height\n",
    "\n",
    "print(f\"Basemap CRS: {basemap_crs}\")\n",
    "print(f\"Basemap dimensions: {basemap_width}x{basemap_height}\")\n",
    "\n",
    "# Convert all GCPs to pixel coordinates\n",
    "gcp_pixel_coords = {}\n",
    "for gcp in gcps:\n",
    "    pixel_coords = gcp_to_pixel_coords(gcp['lat'], gcp['lon'], basemap_path)\n",
    "    if pixel_coords:\n",
    "        gcp_pixel_coords[gcp['id']] = {\n",
    "            'gcp': gcp,\n",
    "            'pixel_col': pixel_coords[0],\n",
    "            'pixel_row': pixel_coords[1]\n",
    "        }\n",
    "    else:\n",
    "        print(f\"\u26a0\ufe0f  GCP {gcp['id']} is outside basemap bounds\")\n",
    "\n",
    "print(f\"\\n\u2713 Found {len(gcp_pixel_coords)} GCPs within basemap bounds\")\n",
    "print(f\"\\nFirst few GCP pixel coordinates:\")\n",
    "for gcp_id, coords in list(gcp_pixel_coords.items())[:3]:\n",
    "    print(f\"  {gcp_id}: col={coords['pixel_col']}, row={coords['pixel_row']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Extract Patches from Basemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 Extracted 23 patches of size 29x29\n",
      "\u2713 Extracted 23 patches of size 39x39\n",
      "\u2713 Extracted 23 patches of size 49x49\n",
      "\u2713 Extracted 23 patches of size 59x59\n",
      "\n",
      "\u2713 Patch extraction complete!\n"
     ]
    }
   ],
   "source": [
    "# Extract patches from basemap centered on GCPs\n",
    "def extract_patch(raster_path: Path, center_col: int, center_row: int, patch_size: int) -> Optional[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Extract a patch from raster centered on given pixel coordinates.\n",
    "    \n",
    "    Args:\n",
    "        raster_path: Path to raster file\n",
    "        center_col: Center column (x)\n",
    "        center_row: Center row (y)\n",
    "        patch_size: Size of patch (must be odd, e.g., 29, 39, 49)\n",
    "    \n",
    "    Returns:\n",
    "        Patch array (H, W, C) or None if out of bounds\n",
    "    \"\"\"\n",
    "    half_size = patch_size // 2\n",
    "    \n",
    "    with rasterio.open(raster_path) as src:\n",
    "        # Calculate bounds\n",
    "        col_start = max(0, center_col - half_size)\n",
    "        col_end = min(src.width, center_col + half_size + 1)\n",
    "        row_start = max(0, center_row - half_size)\n",
    "        row_end = min(src.height, center_row + half_size + 1)\n",
    "        \n",
    "        # Check if patch would be out of bounds\n",
    "        if col_end - col_start < patch_size or row_end - row_start < patch_size:\n",
    "            return None\n",
    "        \n",
    "        # Read patch\n",
    "        patch = src.read(\n",
    "            window=rasterio.windows.Window(col_start, row_start, col_end - col_start, row_end - row_start)\n",
    "        )\n",
    "        \n",
    "        # Transpose to (H, W, C) format\n",
    "        if len(patch.shape) == 3:\n",
    "            patch = np.transpose(patch, (1, 2, 0))\n",
    "        \n",
    "        # If single band, convert to 3-channel grayscale\n",
    "        if len(patch.shape) == 2:\n",
    "            patch = np.stack([patch, patch, patch], axis=-1)\n",
    "        \n",
    "        return patch\n",
    "\n",
    "def create_gcp_patch_visualization(\n",
    "    patch: np.ndarray,\n",
    "    patch_size: int,\n",
    "    output_path: Path\n",
    "):\n",
    "    \"\"\"\n",
    "    Create visualization of patch with GCP location marked.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.patches as mpatches\n",
    "    \n",
    "    # Normalize patch if needed\n",
    "    if patch.dtype != np.uint8:\n",
    "        patch_min = patch.min()\n",
    "        patch_max = patch.max()\n",
    "        if patch_max > patch_min:\n",
    "            patch = ((patch - patch_min) / (patch_max - patch_min) * 255).astype(np.uint8)\n",
    "        else:\n",
    "            patch = np.zeros_like(patch, dtype=np.uint8)\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    ax.imshow(patch)\n",
    "    \n",
    "    # Mark center (GCP location) with bright red dot\n",
    "    center_row, center_col = patch.shape[0] // 2, patch.shape[1] // 2\n",
    "    ax.plot(center_col, center_row, 'ro', markersize=15, markeredgewidth=2, markeredgecolor='white')\n",
    "    \n",
    "    # Draw yellow square around patch boundary\n",
    "    rect = mpatches.Rectangle(\n",
    "        (0, 0), patch.shape[1], patch.shape[0],\n",
    "        linewidth=3, edgecolor='yellow', facecolor='none'\n",
    "    )\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "    ax.set_title(f'Matched Patch ({patch_size}x{patch_size})', fontsize=14, fontweight='bold')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Extract patches for different patch sizes\n",
    "patch_sizes = [49, 59, 79, 99, 119]  # Larger patches for better matching\n",
    "basemap_patches = {}\n",
    "\n",
    "for patch_size in patch_sizes:\n",
    "    basemap_patches[patch_size] = {}\n",
    "    \n",
    "    for gcp_id, coords in gcp_pixel_coords.items():\n",
    "        patch = extract_patch(\n",
    "            basemap_path,\n",
    "            coords['pixel_col'],\n",
    "            coords['pixel_row'],\n",
    "            patch_size\n",
    "        )\n",
    "        \n",
    "        if patch is not None:\n",
    "            basemap_patches[patch_size][gcp_id] = patch\n",
    "            \n",
    "            # Save patch as image for visualization\n",
    "            patch_path = patches_dir / f\"basemap_{gcp_id}_{patch_size}x{patch_size}.png\"\n",
    "            plt.imsave(patch_path, patch.astype(np.uint8))\n",
    "    \n",
    "    print(f\"\u2713 Extracted {len(basemap_patches[patch_size])} patches of size {patch_size}x{patch_size}\")\n",
    "\n",
    "print(f\"\\n\u2713 Patch extraction complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Reproject Orthomosaics to Match Basemap CRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reprojecting no_gcps...\n"
     ]
    },
    {
     "ename": "CPLE_AppDefinedError",
     "evalue": "Too many points (10201 out of 10201) failed to transform, unable to compute output bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_AppDefinedError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 94\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mReprojecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mortho_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 94\u001b[0m     reprojected_path \u001b[38;5;241m=\u001b[39m \u001b[43mreproject_ortho_to_basemap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43mortho_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbasemap_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreprojected_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mortho_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_reprojected.tif\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m     reprojected_paths[ortho_name] \u001b[38;5;241m=\u001b[39m reprojected_path\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\u2713 Reprojection complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 33\u001b[0m, in \u001b[0;36mreproject_ortho_to_basemap\u001b[0;34m(ortho_path, basemap_path, output_path)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output_path\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Calculate transform\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m transform, width, height \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_default_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource_crs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_crs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_height\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtarget_bounds\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Read source data\u001b[39;00m\n\u001b[1;32m     42\u001b[0m source_data \u001b[38;5;241m=\u001b[39m ortho_src\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/rasterio/env.py:410\u001b[0m, in \u001b[0;36mensure_env.<locals>.wrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m local\u001b[38;5;241m.\u001b[39m_env:\n\u001b[0;32m--> 410\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    412\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m Env\u001b[38;5;241m.\u001b[39mfrom_defaults():\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/rasterio/warp.py:556\u001b[0m, in \u001b[0;36mcalculate_default_transform\u001b[0;34m(src_crs, dst_crs, width, height, left, bottom, right, top, gcps, rpcs, resolution, dst_width, dst_height, src_geoloc_array, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resolution \u001b[38;5;129;01mand\u001b[39;00m dimensions:\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResolution cannot be used with dst_width and dst_height.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 556\u001b[0m dst_affine, dst_width, dst_height \u001b[38;5;241m=\u001b[39m \u001b[43m_calculate_default_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m    \u001b[49m\u001b[43msrc_crs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdst_crs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m    \u001b[49m\u001b[43mleft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbottom\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbottom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mright\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgcps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgcps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrpcs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrpcs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43msrc_geoloc_array\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_geoloc_array\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;66;03m# If resolution is specified, Keep upper-left anchored\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;66;03m# adjust the transform resolutions\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;66;03m# adjust the width/height by the ratio of estimated:specified res (ceil'd)\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resolution:\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;66;03m# resolutions argument into tuple\u001b[39;00m\n",
      "File \u001b[0;32mrasterio/_warp.pyx:796\u001b[0m, in \u001b[0;36mrasterio._warp._calculate_default_transform\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mrasterio/_err.pyx:289\u001b[0m, in \u001b[0;36mrasterio._err.exc_wrap_int\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_AppDefinedError\u001b[0m: Too many points (10201 out of 10201) failed to transform, unable to compute output bounds."
     ]
    }
   ],
   "source": [
    "from rasterio.warp import calculate_default_transform, reproject, Resampling, transform_bounds\n",
    "from rasterio.transform import from_bounds\n",
    "from rasterio.enums import Resampling as RasterioResampling\n",
    "from affine import Affine\n",
    "\n",
    "# Reproject orthos to match basemap CRS and resolution\n",
    "def reproject_ortho_to_basemap(ortho_path: Path, basemap_path: Path, output_path: Path) -> Path:\n",
    "    \"\"\"\n",
    "    Reproject orthomosaic to match basemap CRS and bounds.\n",
    "    Uses manual transform construction to avoid CPLE_AppDefinedError.\n",
    "    \"\"\"\n",
    "    if output_path.exists():\n",
    "        print(f\"  \u2713 Already reprojected: {output_path}\")\n",
    "        return output_path\n",
    "    \n",
    "    with rasterio.open(basemap_path) as basemap_src:\n",
    "        target_crs = basemap_src.crs\n",
    "        target_bounds = basemap_src.bounds\n",
    "        target_transform = basemap_src.transform\n",
    "        target_width = basemap_src.width\n",
    "        target_height = basemap_src.height\n",
    "    \n",
    "    with rasterio.open(ortho_path) as ortho_src:\n",
    "        source_crs = ortho_src.crs\n",
    "        source_bounds = ortho_src.bounds\n",
    "        \n",
    "        if source_crs == target_crs:\n",
    "            print(f\"  \u2713 Already in target CRS\")\n",
    "            import shutil\n",
    "            shutil.copy(ortho_path, output_path)\n",
    "            return output_path\n",
    "        \n",
    "        # Transform source bounds to target CRS\n",
    "        print(f\"  Transforming source bounds to target CRS...\")\n",
    "        src_bounds_target_crs = transform_bounds(\n",
    "            source_crs, target_crs,\n",
    "            source_bounds.left, source_bounds.bottom,\n",
    "            source_bounds.right, source_bounds.top\n",
    "        )\n",
    "        \n",
    "        print(f\"  Source bounds in target CRS: {src_bounds_target_crs}\")\n",
    "        \n",
    "        # Get target pixel size\n",
    "        target_pixel_size_x = abs(target_transform[0])\n",
    "        target_pixel_size_y = abs(target_transform[4])\n",
    "        \n",
    "        # Use intersection of bounds\n",
    "        output_left = max(src_bounds_target_crs[0], target_bounds.left)\n",
    "        output_bottom = max(src_bounds_target_crs[1], target_bounds.bottom)\n",
    "        output_right = min(src_bounds_target_crs[2], target_bounds.right)\n",
    "        output_top = min(src_bounds_target_crs[3], target_bounds.top)\n",
    "        \n",
    "        print(f\"  Output bounds (intersection): left={output_left:.2f}, bottom={output_bottom:.2f}, right={output_right:.2f}, top={output_top:.2f}\")\n",
    "        \n",
    "        # Validate bounds\n",
    "        if output_right <= output_left or output_top <= output_bottom:\n",
    "            raise ValueError(f\"Invalid output bounds: width={output_right-output_left}, height={output_top-output_bottom}\")\n",
    "        \n",
    "        # Calculate dimensions using target pixel size\n",
    "        width = int((output_right - output_left) / target_pixel_size_x)\n",
    "        height = int((output_top - output_bottom) / target_pixel_size_y)\n",
    "        \n",
    "        # Validate dimensions\n",
    "        if width <= 0 or height <= 0:\n",
    "            raise ValueError(f\"Invalid dimensions: width={width}, height={height}\")\n",
    "        \n",
    "        # Create transform for output\n",
    "        transform = Affine.translation(output_left, output_top) * Affine.scale(target_pixel_size_x, -target_pixel_size_y)\n",
    "        \n",
    "        print(f\"  \u2713 Transform calculated: {width}x{height} pixels\")\n",
    "        \n",
    "        # Read source data\n",
    "        source_data = ortho_src.read()\n",
    "        source_count = ortho_src.count\n",
    "        \n",
    "        # Reproject\n",
    "        reprojected_data = np.zeros((source_count, height, width), dtype=source_data.dtype)\n",
    "        \n",
    "        for band_idx in range(1, source_count + 1):\n",
    "            reproject(\n",
    "                source=rasterio.band(ortho_src, band_idx),\n",
    "                destination=reprojected_data[band_idx - 1],\n",
    "                src_transform=ortho_src.transform,\n",
    "                src_crs=source_crs,\n",
    "                dst_transform=transform,\n",
    "                dst_crs=target_crs,\n",
    "                resampling=Resampling.bilinear\n",
    "            )\n",
    "        \n",
    "        # Save\n",
    "        with rasterio.open(\n",
    "            output_path,\n",
    "            'w',\n",
    "            driver='GTiff',\n",
    "            height=height,\n",
    "            width=width,\n",
    "            count=source_count,\n",
    "            dtype=reprojected_data.dtype,\n",
    "            crs=target_crs,\n",
    "            transform=transform,\n",
    "            compress='lzw',\n",
    "            BIGTIFF='YES',\n",
    "            tiled=True,\n",
    "            blockxsize=512,\n",
    "            blockysize=512\n",
    "        ) as dst:\n",
    "            dst.write(reprojected_data)\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "# Check for existing reprojected files from test_matching notebook\n",
    "existing_reprojected_dir = output_dir / \"test_matching\" / \"reprojected\"\n",
    "reprojected_dir = gcp_matching_dir / \"reprojected\"\n",
    "reprojected_dir.mkdir(exist_ok=True)\n",
    "\n",
    "ortho_paths = {\n",
    "    'no_gcps': ortho_no_gcps_path,\n",
    "    'with_gcps': ortho_with_gcps_path\n",
    "}\n",
    "\n",
    "reprojected_paths = {}\n",
    "for ortho_name, ortho_path in ortho_paths.items():\n",
    "    if not ortho_path.exists():\n",
    "        print(f\"\u26a0\ufe0f  Ortho not found: {ortho_path}\")\n",
    "        continue\n",
    "    \n",
    "    # Check for existing reprojected file from test_matching\n",
    "    existing_reprojected = existing_reprojected_dir / f\"{ortho_name}_reprojected.tif\"\n",
    "    if existing_reprojected.exists():\n",
    "        print(f\"\\nFound existing reprojected file: {existing_reprojected}\")\n",
    "        # Copy to our directory\n",
    "        import shutil\n",
    "        reprojected_path = reprojected_dir / f\"{ortho_name}_reprojected.tif\"\n",
    "        if not reprojected_path.exists():\n",
    "            shutil.copy(existing_reprojected, reprojected_path)\n",
    "            print(f\"  \u2713 Copied to: {reprojected_path}\")\n",
    "        else:\n",
    "            print(f\"  \u2713 Already exists: {reprojected_path}\")\n",
    "        reprojected_paths[ortho_name] = reprojected_path\n",
    "        continue\n",
    "    \n",
    "    # Otherwise, reproject\n",
    "    print(f\"\\nReprojecting {ortho_name}...\")\n",
    "    reprojected_path = reproject_ortho_to_basemap(\n",
    "        ortho_path,\n",
    "        basemap_path,\n",
    "        reprojected_dir / f\"{ortho_name}_reprojected.tif\"\n",
    "    )\n",
    "    reprojected_paths[ortho_name] = reprojected_path\n",
    "\n",
    "print(f\"\\n\u2713 Reprojection complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Find GCP Patches in Orthomosaics Using Template Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Finding GCPs in no_gcps orthomosaic\n",
      "============================================================\n",
      "  Patch size 29x29: 22/23 matches\n",
      "  Patch size 39x39: 21/23 matches\n",
      "  Patch size 49x49: 21/23 matches\n",
      "  Patch size 59x59: 21/23 matches\n",
      "\n",
      "  \u2713 Best patch size: 29x29 (22 matches)\n",
      "  Saving matching patches to outputs/gcp_matching/matching_patches/no_gcps...\n",
      "  \u2713 Saved 22 matching patches\n",
      "\n",
      "============================================================\n",
      "Finding GCPs in with_gcps orthomosaic\n",
      "============================================================\n",
      "  Patch size 29x29: 22/23 matches\n",
      "  Patch size 39x39: 22/23 matches\n",
      "  Patch size 49x49: 21/23 matches\n",
      "  Patch size 59x59: 21/23 matches\n",
      "\n",
      "  \u2713 Best patch size: 29x29 (22 matches)\n",
      "  Saving matching patches to outputs/gcp_matching/matching_patches/with_gcps...\n",
      "  \u2713 Saved 22 matching patches\n",
      "\n",
      "\u2713 Patch matching complete!\n",
      "\n",
      "Creating visualization of GCP matches...\n",
      "  \u2713 Visualization already exists: outputs/gcp_matching/matches/gcp_matching_visualization_no_gcps.png\n",
      "  Skipping visualization creation...\n",
      "  \u2713 Visualization already exists: outputs/gcp_matching/matches/gcp_matching_visualization_with_gcps.png\n",
      "  Skipping visualization creation...\n"
     ]
    }
   ],
   "source": [
    "# Find GCP patches in orthomosaics using template matching\n",
    "def find_patch_in_ortho(\n",
    "    template_patch: np.ndarray,\n",
    "    ortho_path: Path,\n",
    "    search_center_col: int,\n",
    "    search_center_row: int,\n",
    "    search_radius: int = 300  # Reduced for more precise matching\n",
    ") -> Optional[Tuple[int, int, float]]:\n",
    "    \"\"\"\n",
    "    Find template patch in orthomosaic using template matching.\n",
    "    \n",
    "    Returns:\n",
    "        (col, row, confidence) or None if not found\n",
    "    \"\"\"\n",
    "    # Convert template to grayscale if needed\n",
    "    if len(template_patch.shape) == 3:\n",
    "        template_gray = cv2.cvtColor(template_patch.astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        template_gray = template_patch.astype(np.uint8)\n",
    "    \n",
    "    with rasterio.open(ortho_path) as ortho_src:\n",
    "        # Define search window\n",
    "        search_col_start = max(0, search_center_col - search_radius)\n",
    "        search_col_end = min(ortho_src.width, search_center_col + search_radius)\n",
    "        search_row_start = max(0, search_center_row - search_radius)\n",
    "        search_row_end = min(ortho_src.height, search_center_row + search_radius)\n",
    "        \n",
    "        # Read search region\n",
    "        search_window = rasterio.windows.Window(\n",
    "            search_col_start,\n",
    "            search_row_start,\n",
    "            search_col_end - search_col_start,\n",
    "            search_row_end - search_row_start\n",
    "        )\n",
    "        \n",
    "        search_region = ortho_src.read(window=search_window)\n",
    "        \n",
    "        # Convert to (H, W, C) and then grayscale\n",
    "        if len(search_region.shape) == 3:\n",
    "            search_region = np.transpose(search_region, (1, 2, 0))\n",
    "            if search_region.shape[2] == 1:\n",
    "                search_gray = search_region[:, :, 0]\n",
    "            else:\n",
    "                search_gray = cv2.cvtColor(search_region.astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "        else:\n",
    "            search_gray = search_region\n",
    "        \n",
    "        # Normalize to uint8\n",
    "        if search_gray.dtype != np.uint8:\n",
    "            search_min = search_gray.min()\n",
    "            search_max = search_gray.max()\n",
    "            if search_max > search_min:\n",
    "                search_gray = ((search_gray - search_min) / (search_max - search_min) * 255).astype(np.uint8)\n",
    "            else:\n",
    "                search_gray = np.zeros_like(search_gray, dtype=np.uint8)\n",
    "        \n",
    "        # Template matching\n",
    "        result = cv2.matchTemplate(search_gray, template_gray, cv2.TM_CCOEFF_NORMED)\n",
    "        \n",
    "        # Find best match\n",
    "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "        \n",
    "        # Convert back to global coordinates\n",
    "        match_col = search_col_start + max_loc[0] + template_gray.shape[1] // 2\n",
    "        match_row = search_row_start + max_loc[1] + template_gray.shape[0] // 2\n",
    "        \n",
    "        # Return if confidence is high enough\n",
    "        if max_val > 0.5:  # Threshold for match confidence\n",
    "            return (match_col, match_row, float(max_val))\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "# Find GCPs in each orthomosaic\n",
    "# Create directory for matching patches\n",
    "matching_patches_dir = gcp_matching_dir / \"matching_patches\"\n",
    "matching_patches_dir.mkdir(exist_ok=True)\n",
    "matching_patches_dir.mkdir(exist_ok=True)\n",
    "\n",
    "matching_results = {}\n",
    "\n",
    "for ortho_name, reprojected_path in reprojected_paths.items():\n",
    "\n",
    "    matching_results[ortho_name] = {}\n",
    "    \n",
    "    # Get ortho transform for coordinate conversion\n",
    "    with rasterio.open(reprojected_path) as ortho_src:\n",
    "        ortho_transform = ortho_src.transform\n",
    "    \n",
    "    # Try different patch sizes\n",
    "    best_patch_size = None\n",
    "    best_matches = 0\n",
    "    \n",
    "    for patch_size in patch_sizes:\n",
    "        matches_found = 0\n",
    "        \n",
    "        for gcp_id, coords in gcp_pixel_coords.items():\n",
    "            if gcp_id not in basemap_patches[patch_size]:\n",
    "                continue\n",
    "            \n",
    "            template = basemap_patches[patch_size][gcp_id]\n",
    "            \n",
    "            # Convert GCP UTM coordinates to pixel coordinates in THIS ortho\n",
    "            gcp_utm_x = coords.get('utm_x') or coords.get('x_utm')\n",
    "            gcp_utm_y = coords.get('utm_y') or coords.get('y_utm')\n",
    "            \n",
    "            if gcp_utm_x is not None and gcp_utm_y is not None:\n",
    "                # Convert UTM to pixel coordinates using ortho's transform\n",
    "                expected_col, expected_row = ~ortho_transform * (gcp_utm_x, gcp_utm_y)\n",
    "                expected_col = int(expected_col)\n",
    "                expected_row = int(expected_row)\n",
    "            else:\n",
    "                # Fallback: use pixel coordinates from basemap\n",
    "                expected_col = coords['pixel_col']\n",
    "                expected_row = coords['pixel_row']\n",
    "            \n",
    "            # Search for patch using multi-scale matching\n",
    "            if 'find_patch_in_ortho_multiscale' in globals():\n",
    "                match = find_patch_in_ortho_multiscale(\n",
    "                    template,\n",
    "                    reprojected_path,\n",
    "                    expected_col,\n",
    "                    expected_row,\n",
    "                    search_radius=300\n",
    "                )\n",
    "            else:\n",
    "                match = find_patch_in_ortho(\n",
    "                    template,\n",
    "                    reprojected_path,\n",
    "                    expected_col,\n",
    "                    expected_row,\n",
    "                    search_radius=300\n",
    "                )\n",
    "            \n",
    "            # Validate match quality\n",
    "            if match and match[2] < 0.3:  # Confidence threshold\n",
    "                match = None\n",
    "            \n",
    "            if match:\n",
    "                match_col, match_row, confidence = match\n",
    "                matches_found += 1\n",
    "                \n",
    "                if gcp_id not in matching_results[ortho_name]:\n",
    "                    matching_results[ortho_name][gcp_id] = {}\n",
    "                \n",
    "                matching_results[ortho_name][gcp_id][patch_size] = {\n",
    "                    'expected_col': expected_col,\n",
    "                    'expected_row': expected_row,\n",
    "                    'matched_col': match_col,\n",
    "                    'matched_row': match_row,\n",
    "                    'offset_col': match_col - expected_col,\n",
    "                    'offset_row': match_row - expected_row,\n",
    "                    'confidence': confidence\n",
    "                }\n",
    "        \n",
    "        print(f\"  Patch size {patch_size}x{patch_size}: {matches_found}/{len(gcp_pixel_coords)} matches\")\n",
    "        \n",
    "        if matches_found > best_matches:\n",
    "            best_matches = matches_found\n",
    "            best_patch_size = patch_size\n",
    "    \n",
    "    print(f\"\\n  \u2713 Best patch size: {best_patch_size}x{best_patch_size} ({best_matches} matches)\")\n",
    "\n",
    "    print(f\"\\n  \u2713 Best patch size: {best_patch_size}x{best_patch_size} ({best_matches} matches)\")\n",
    "\n",
    "    # Create subdirectory for this ortho's matching patches\n",
    "    ortho_patches_dir = matching_patches_dir / ortho_name\n",
    "    ortho_patches_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # Save matching patches for visual verification\n",
    "    print(f\"  Saving matching patches to {ortho_patches_dir}...\")\n",
    "    for gcp_id, match_data in matching_results[ortho_name].items():\n",
    "        if best_patch_size in match_data:\n",
    "            match = match_data[best_patch_size]\n",
    "            \n",
    "            # Extract patch from ortho at matched location\n",
    "            matched_col = match['matched_col']\n",
    "            matched_row = match['matched_row']\n",
    "            \n",
    "            # Extract patch (same size as template)\n",
    "            patch = extract_patch(\n",
    "                reprojected_path,\n",
    "                matched_col,\n",
    "                matched_row,\n",
    "                best_patch_size\n",
    "            )\n",
    "            \n",
    "            if patch is not None:\n",
    "                # Normalize patch for saving\n",
    "                if patch.dtype != np.uint8:\n",
    "                    patch_min = patch.min()\n",
    "                    patch_max = patch.max()\n",
    "                    if patch_max > patch_min:\n",
    "                        patch = ((patch - patch_min) / (patch_max - patch_min) * 255).astype(np.uint8)\n",
    "                    else:\n",
    "                        patch = np.zeros_like(patch, dtype=np.uint8)\n",
    "                \n",
    "                # Save matching patch\n",
    "                match_patch_path = ortho_patches_dir / f\"{gcp_id}_{best_patch_size}x{best_patch_size}_matched.png\"\n",
    "                plt.imsave(match_patch_path, patch)\n",
    "                \n",
    "                # Also create visualization with GCP location marked\n",
    "                vis_patch_path = ortho_patches_dir / f\"{gcp_id}_{best_patch_size}x{best_patch_size}_matched_vis.png\"\n",
    "                create_gcp_patch_visualization(patch, best_patch_size, vis_patch_path)\n",
    "    \n",
    "    print(f\"  \u2713 Saved {len([g for g in matching_results[ortho_name].keys() if best_patch_size in matching_results[ortho_name][g]])} matching patches\")\n",
    "\n",
    "print(f\"\\n\u2713 Patch matching complete!\")\n",
    "\n",
    "# Create comprehensive visualization\n",
    "print(f\"\\nCreating visualization of GCP matches...\")\n",
    "\n",
    "def create_gcp_matching_visualization(\n",
    "    basemap_path: Path,\n",
    "    ortho_paths: Dict[str, Path],\n",
    "    gcp_pixel_coords: Dict,\n",
    "    matching_results: Dict,\n",
    "    output_path: Path,\n",
    "    max_dimension: int = 4000\n",
    "):\n",
    "    \"\"\"\n",
    "    Create visualization showing basemap with GCPs and orthos with matched patches.\n",
    "    \"\"\"\n",
    "    # Load basemap\n",
    "    with rasterio.open(basemap_path) as src:\n",
    "        basemap_data = src.read()\n",
    "        basemap_transform = src.transform\n",
    "        \n",
    "        # Convert to (H, W, C)\n",
    "        if len(basemap_data.shape) == 3:\n",
    "            basemap_img = np.transpose(basemap_data, (1, 2, 0))\n",
    "            if basemap_img.shape[2] == 1:\n",
    "                basemap_img = np.stack([basemap_img[:, :, 0]] * 3, axis=-1)\n",
    "            elif basemap_img.shape[2] == 4:\n",
    "                basemap_img = basemap_img[:, :, :3]  # Take RGB\n",
    "        else:\n",
    "            basemap_img = np.stack([basemap_data] * 3, axis=-1)\n",
    "        \n",
    "        # Normalize to uint8\n",
    "        if basemap_img.dtype != np.uint8:\n",
    "            basemap_min = basemap_img.min()\n",
    "            basemap_max = basemap_img.max()\n",
    "            if basemap_max > basemap_min:\n",
    "                basemap_img = ((basemap_img - basemap_min) / (basemap_max - basemap_min) * 255).astype(np.uint8)\n",
    "            else:\n",
    "                basemap_img = np.zeros_like(basemap_img, dtype=np.uint8)\n",
    "    \n",
    "    # Downsample if too large\n",
    "    h, w = basemap_img.shape[:2]\n",
    "    if max(h, w) > max_dimension:\n",
    "        scale = max_dimension / max(h, w)\n",
    "        new_h, new_w = int(h * scale), int(w * scale)\n",
    "        basemap_img = cv2.resize(basemap_img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "        scale_factor = scale\n",
    "    else:\n",
    "        scale_factor = 1.0\n",
    "    \n",
    "    # Load orthos and create panels\n",
    "    num_orthos = len(ortho_paths)\n",
    "    fig, axes = plt.subplots(1, num_orthos + 1, figsize=(8 * (num_orthos + 1), 8))\n",
    "    \n",
    "    # Basemap panel (left)\n",
    "    ax = axes[0]\n",
    "    basemap_display = basemap_img.copy()\n",
    "    \n",
    "    # Draw GCP positions on basemap\n",
    "    for gcp_id, coords in gcp_pixel_coords.items():\n",
    "        # Scale coordinates\n",
    "        col = int(coords['pixel_col'] * scale_factor)\n",
    "        row = int(coords['pixel_row'] * scale_factor)\n",
    "        \n",
    "        if 0 <= row < basemap_display.shape[0] and 0 <= col < basemap_display.shape[1]:\n",
    "            # Draw red circle\n",
    "            cv2.circle(basemap_display, (col, row), 10, (255, 0, 0), 3)\n",
    "    \n",
    "    ax.imshow(basemap_display)\n",
    "    ax.set_title('Basemap with GCP Locations', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Add GCP labels\n",
    "    for gcp_id, coords in gcp_pixel_coords.items():\n",
    "        col = int(coords['pixel_col'] * scale_factor)\n",
    "        row = int(coords['pixel_row'] * scale_factor)\n",
    "        if 0 <= row < basemap_display.shape[0] and 0 <= col < basemap_display.shape[1]:\n",
    "            ax.text(col, row - 15, gcp_id, color='red', fontsize=8, fontweight='bold',\n",
    "                   ha='center', va='bottom')\n",
    "    \n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Ortho panels (right)\n",
    "    for ortho_idx, (ortho_name, ortho_path) in enumerate(ortho_paths.items(), 1):\n",
    "        ax = axes[ortho_idx]\n",
    "        \n",
    "        # Load ortho\n",
    "        with rasterio.open(ortho_path) as src:\n",
    "            ortho_data = src.read()\n",
    "            \n",
    "            # Convert to (H, W, C)\n",
    "            if len(ortho_data.shape) == 3:\n",
    "                ortho_img = np.transpose(ortho_data, (1, 2, 0))\n",
    "                if ortho_img.shape[2] == 1:\n",
    "                    ortho_img = np.stack([ortho_img[:, :, 0]] * 3, axis=-1)\n",
    "                elif ortho_img.shape[2] == 4:\n",
    "                    ortho_img = ortho_img[:, :, :3]\n",
    "            else:\n",
    "                ortho_img = np.stack([ortho_data] * 3, axis=-1)\n",
    "            \n",
    "            # Normalize\n",
    "            if ortho_img.dtype != np.uint8:\n",
    "                ortho_min = ortho_img.min()\n",
    "                ortho_max = ortho_img.max()\n",
    "                if ortho_max > ortho_min:\n",
    "                    ortho_img = ((ortho_img - ortho_min) / (ortho_max - ortho_min) * 255).astype(np.uint8)\n",
    "                else:\n",
    "                    ortho_img = np.zeros_like(ortho_img, dtype=np.uint8)\n",
    "        \n",
    "        # Downsample if too large\n",
    "        h, w = ortho_img.shape[:2]\n",
    "        if max(h, w) > max_dimension:\n",
    "            scale = max_dimension / max(h, w)\n",
    "            new_h, new_w = int(h * scale), int(w * scale)\n",
    "            ortho_img = cv2.resize(ortho_img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "            ortho_scale = scale\n",
    "        else:\n",
    "            ortho_scale = 1.0\n",
    "        \n",
    "        ortho_display = ortho_img.copy()\n",
    "        \n",
    "        # Draw matched patch centers\n",
    "        if ortho_name in matching_results:\n",
    "            for gcp_id, match_data in matching_results[ortho_name].items():\n",
    "                # Get best patch size match\n",
    "                best_patch_size = max(match_data.keys()) if match_data else None\n",
    "                if best_patch_size:\n",
    "                    match = match_data[best_patch_size]\n",
    "                    matched_col = int(match['matched_col'] * ortho_scale)\n",
    "                    matched_row = int(match['matched_row'] * ortho_scale)\n",
    "                    \n",
    "                    if 0 <= matched_row < ortho_display.shape[0] and 0 <= matched_col < ortho_display.shape[1]:\n",
    "                        # Draw yellow circle\n",
    "                        cv2.circle(ortho_display, (matched_col, matched_row), 10, (255, 255, 0), 3)\n",
    "        \n",
    "        ax.imshow(ortho_display)\n",
    "        ax.set_title(f'{ortho_name.replace(\"_\", \" \").title()} with Matched Patches', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Add labels\n",
    "        if ortho_name in matching_results:\n",
    "            for gcp_id, match_data in matching_results[ortho_name].items():\n",
    "                best_patch_size = max(match_data.keys()) if match_data else None\n",
    "                if best_patch_size:\n",
    "                    match = match_data[best_patch_size]\n",
    "                    matched_col = int(match['matched_col'] * ortho_scale)\n",
    "                    matched_row = int(match['matched_row'] * ortho_scale)\n",
    "                    if 0 <= matched_row < ortho_display.shape[0] and 0 <= matched_col < ortho_display.shape[1]:\n",
    "                        ax.text(matched_col, matched_row - 15, gcp_id, color='yellow', fontsize=8, fontweight='bold',\n",
    "                               ha='center', va='bottom')\n",
    "        \n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight', format='PNG')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"\u2713 Visualization saved: {output_path}\")\n",
    "\n",
    "# Create visualization for each ortho\n",
    "for ortho_name in reprojected_paths.keys():\n",
    "    if ortho_name not in matching_results:\n",
    "        continue\n",
    "    \n",
    "    vis_path = matches_dir / f\"gcp_matching_visualization_{ortho_name}.png\"\n",
    "\n",
    "    # Check if visualization already exists\n",
    "    if vis_path.exists():\n",
    "        print(f\"  \u2713 Visualization already exists: {vis_path}\")\n",
    "        print(f\"  Skipping visualization creation...\")\n",
    "        continue\n",
    "\n",
    "    \n",
    "    create_gcp_matching_visualization(\n",
    "        basemap_path,\n",
    "        {ortho_name: reprojected_paths[ortho_name]},\n",
    "        gcp_pixel_coords,\n",
    "        matching_results,\n",
    "        vis_path,\n",
    "        max_dimension=4000\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Compute 2D Shift or Affine Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 matching_results found in memory\n",
      "\n",
      "Match pixel locations:\n",
      "  GCP1: Expected=(40448.0, 12515.0), \n",
      "         Matched=(40207.0, 12361.0), \n",
      "         Offset=(-241.0, -154.0) px\n",
      "         Distance: 3.417 m (341.67 cm)\n",
      "  GCP2: Expected=(18991.0, 30556.0), \n",
      "         Matched=(18761.0, 30548.0), \n",
      "         Offset=(-230.0, -8.0) px\n",
      "         Distance: 2.749 m (274.93 cm)\n",
      "  GCP3: Expected=(12293.0, 51482.0), \n",
      "         Matched=(12042.0, 51448.0), \n",
      "         Offset=(-251.0, -34.0) px\n",
      "         Distance: 3.026 m (302.59 cm)\n",
      "  GCP4: Expected=(27968.0, 43227.0), \n",
      "         Matched=(27915.0, 43233.0), \n",
      "         Offset=(-53.0, 6.0) px\n",
      "         Distance: 0.637 m (63.72 cm)\n",
      "  GCP5: Expected=(41453.0, 31732.0), \n",
      "         Matched=(41276.0, 31680.0), \n",
      "         Offset=(-177.0, -52.0) px\n",
      "         Distance: 2.204 m (220.39 cm)\n",
      "  GCP6: Expected=(53656.0, 8570.0), \n",
      "         Matched=(53528.0, 8495.0), \n",
      "         Offset=(-128.0, -75.0) px\n",
      "         Distance: 1.772 m (177.23 cm)\n",
      "  GCP7: Expected=(55120.0, 25180.0), \n",
      "         Matched=(54975.0, 25113.0), \n",
      "         Offset=(-145.0, -67.0) px\n",
      "         Distance: 1.908 m (190.82 cm)\n",
      "  GCP8: Expected=(74004.0, 31574.0), \n",
      "         Matched=(74035.0, 31713.0), \n",
      "         Offset=(31.0, 139.0) px\n",
      "         Distance: 1.701 m (170.13 cm)\n",
      "  GCP10: Expected=(53665.0, 49782.0), \n",
      "         Matched=(53490.0, 49702.0), \n",
      "         Offset=(-175.0, -80.0) px\n",
      "         Distance: 2.299 m (229.87 cm)\n",
      "  GCP11: Expected=(49314.0, 41832.0), \n",
      "         Matched=(49141.0, 41766.0), \n",
      "         Offset=(-173.0, -66.0) px\n",
      "         Distance: 2.212 m (221.20 cm)\n",
      "  GCP12: Expected=(38086.0, 62646.0), \n",
      "         Matched=(38326.0, 62854.0), \n",
      "         Offset=(240.0, 208.0) px\n",
      "         Distance: 3.794 m (379.41 cm)\n",
      "  GCP13: Expected=(13043.0, 64568.0), \n",
      "         Matched=(12802.0, 64505.0), \n",
      "         Offset=(-241.0, -63.0) px\n",
      "         Distance: 2.976 m (297.58 cm)\n",
      "  GCP14: Expected=(26447.0, 59975.0), \n",
      "         Matched=(26222.0, 59914.0), \n",
      "         Offset=(-225.0, -61.0) px\n",
      "         Distance: 2.785 m (278.50 cm)\n",
      "  GCP15: Expected=(39522.0, 75450.0), \n",
      "         Matched=(39282.0, 75325.0), \n",
      "         Offset=(-240.0, -125.0) px\n",
      "         Distance: 3.233 m (323.27 cm)\n",
      "  GCP16: Expected=(45711.0, 82470.0), \n",
      "         Matched=(45481.0, 82337.0), \n",
      "         Offset=(-230.0, -133.0) px\n",
      "         Distance: 3.174 m (317.40 cm)\n",
      "  CP1: Expected=(52711.0, 62769.0), \n",
      "         Matched=(52502.0, 62670.0), \n",
      "         Offset=(-209.0, -99.0) px\n",
      "         Distance: 2.763 m (276.27 cm)\n",
      "  CP2: Expected=(40261.0, 49247.0), \n",
      "         Matched=(40066.0, 49189.0), \n",
      "         Offset=(-195.0, -58.0) px\n",
      "         Distance: 2.430 m (243.04 cm)\n",
      "  CP3: Expected=(32707.0, 67154.0), \n",
      "         Matched=(32478.0, 67071.0), \n",
      "         Offset=(-229.0, -83.0) px\n",
      "         Distance: 2.910 m (290.99 cm)\n",
      "  CP4: Expected=(60050.0, 32052.0), \n",
      "         Matched=(59842.0, 31887.0), \n",
      "         Offset=(-208.0, -165.0) px\n",
      "         Distance: 3.172 m (317.17 cm)\n",
      "  CP5: Expected=(30967.0, 19720.0), \n",
      "         Matched=(30934.0, 19556.0), \n",
      "         Offset=(-33.0, -164.0) px\n",
      "         Distance: 1.998 m (199.85 cm)\n",
      "  OMON 6066: Expected=(61342.0, 31691.0), \n",
      "         Matched=(61174.0, 31660.0), \n",
      "         Offset=(-168.0, -31.0) px\n",
      "         Distance: 2.041 m (204.09 cm)\n",
      "\n",
      "============================================================\n",
      "Computing transformation for no_gcps\n",
      "============================================================\n",
      "\n",
      "2D Shift:\n",
      "  Shift X: -203.82 px\n",
      "  Shift Y: -79.65 px\n",
      "  RMSE: 39.02 px\n",
      "  Points: 17\n",
      "\n",
      "Affine Transformation:\n",
      "  RMSE: 43.13 px\n",
      "  Points: 17\n",
      "  \u2713 Using 2D shift (lower RMSE)\n",
      "\n",
      "Match pixel locations:\n",
      "  GCP1: Expected=(40548.0, 12515.0), \n",
      "         Matched=(40308.0, 12362.0), \n",
      "         Offset=(-240.0, -153.0) px\n",
      "         Distance: 3.400 m (340.02 cm)\n",
      "  GCP2: Expected=(19092.0, 30556.0), \n",
      "         Matched=(19239.0, 30372.0), \n",
      "         Offset=(147.0, -184.0) px\n",
      "         Distance: 2.813 m (281.35 cm)\n",
      "  GCP3: Expected=(12393.0, 51482.0), \n",
      "         Matched=(12142.0, 51448.0), \n",
      "         Offset=(-251.0, -34.0) px\n",
      "         Distance: 3.026 m (302.59 cm)\n",
      "  GCP4: Expected=(28068.0, 43227.0), \n",
      "         Matched=(28017.0, 43232.0), \n",
      "         Offset=(-51.0, 5.0) px\n",
      "         Distance: 0.612 m (61.22 cm)\n",
      "  GCP5: Expected=(41553.0, 31732.0), \n",
      "         Matched=(41377.0, 31680.0), \n",
      "         Offset=(-176.0, -52.0) px\n",
      "         Distance: 2.192 m (219.24 cm)\n",
      "  GCP6: Expected=(53757.0, 8570.0), \n",
      "         Matched=(53630.0, 8495.0), \n",
      "         Offset=(-127.0, -75.0) px\n",
      "         Distance: 1.762 m (176.20 cm)\n",
      "  GCP7: Expected=(55220.0, 25180.0), \n",
      "         Matched=(55076.0, 25114.0), \n",
      "         Offset=(-144.0, -66.0) px\n",
      "         Distance: 1.892 m (189.24 cm)\n",
      "  GCP8: Expected=(74105.0, 31574.0), \n",
      "         Matched=(74136.0, 31714.0), \n",
      "         Offset=(31.0, 140.0) px\n",
      "         Distance: 1.713 m (171.30 cm)\n",
      "  GCP10: Expected=(53766.0, 49782.0), \n",
      "         Matched=(53591.0, 49702.0), \n",
      "         Offset=(-175.0, -80.0) px\n",
      "         Distance: 2.299 m (229.87 cm)\n",
      "  GCP11: Expected=(49415.0, 41832.0), \n",
      "         Matched=(49242.0, 41766.0), \n",
      "         Offset=(-173.0, -66.0) px\n",
      "         Distance: 2.212 m (221.20 cm)\n",
      "  GCP12: Expected=(38187.0, 62646.0), \n",
      "         Matched=(38427.0, 62853.0), \n",
      "         Offset=(240.0, 207.0) px\n",
      "         Distance: 3.786 m (378.63 cm)\n",
      "  GCP13: Expected=(13144.0, 64568.0), \n",
      "         Matched=(12903.0, 64504.0), \n",
      "         Offset=(-241.0, -64.0) px\n",
      "         Distance: 2.979 m (297.89 cm)\n",
      "  GCP14: Expected=(26548.0, 59975.0), \n",
      "         Matched=(26324.0, 59913.0), \n",
      "         Offset=(-224.0, -62.0) px\n",
      "         Distance: 2.777 m (277.66 cm)\n",
      "  GCP15: Expected=(39623.0, 75450.0), \n",
      "         Matched=(39383.0, 75324.0), \n",
      "         Offset=(-240.0, -126.0) px\n",
      "         Distance: 3.238 m (323.82 cm)\n",
      "  GCP16: Expected=(45811.0, 82470.0), \n",
      "         Matched=(45586.0, 82342.0), \n",
      "         Offset=(-225.0, -128.0) px\n",
      "         Distance: 3.092 m (309.25 cm)\n",
      "  CP1: Expected=(52812.0, 62769.0), \n",
      "         Matched=(52602.0, 62670.0), \n",
      "         Offset=(-210.0, -99.0) px\n",
      "         Distance: 2.774 m (277.35 cm)\n",
      "  CP2: Expected=(40362.0, 49247.0), \n",
      "         Matched=(40167.0, 49189.0), \n",
      "         Offset=(-195.0, -58.0) px\n",
      "         Distance: 2.430 m (243.04 cm)\n",
      "  CP3: Expected=(32807.0, 67154.0), \n",
      "         Matched=(32579.0, 67071.0), \n",
      "         Offset=(-228.0, -83.0) px\n",
      "         Distance: 2.899 m (289.86 cm)\n",
      "  CP4: Expected=(60150.0, 32052.0), \n",
      "         Matched=(59943.0, 31888.0), \n",
      "         Offset=(-207.0, -164.0) px\n",
      "         Distance: 3.155 m (315.50 cm)\n",
      "  CP5: Expected=(31067.0, 19720.0), \n",
      "         Matched=(31036.0, 19556.0), \n",
      "         Offset=(-31.0, -164.0) px\n",
      "         Distance: 1.994 m (199.39 cm)\n",
      "  OMON 6066: Expected=(61443.0, 31691.0), \n",
      "         Matched=(61275.0, 31660.0), \n",
      "         Offset=(-168.0, -31.0) px\n",
      "         Distance: 2.041 m (204.09 cm)\n",
      "\n",
      "============================================================\n",
      "Computing transformation for with_gcps\n",
      "============================================================\n",
      "\n",
      "2D Shift:\n",
      "  Shift X: -198.36 px\n",
      "  Shift Y: -73.14 px\n",
      "  RMSE: 32.89 px\n",
      "  Points: 14\n",
      "\n",
      "Affine Transformation:\n",
      "  RMSE: 19.70 px\n",
      "  Points: 14\n",
      "  \u2713 Using affine transformation (lower RMSE)\n",
      "\n",
      "\u2713 Transformations saved to: outputs/gcp_matching/matches/transformations.json\n"
     ]
    }
   ],
   "source": [
    "def remove_outliers_ransac(src_points: np.ndarray, dst_points: np.ndarray, threshold: float = 50.0, min_samples: int = 3) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Remove outliers using RANSAC with proper model fitting.\n",
    "    \n",
    "    Returns:\n",
    "        (inlier_src, inlier_dst, inlier_mask)\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(src_points) < min_samples:\n",
    "        mask = np.ones(len(src_points), dtype=bool)\n",
    "        return src_points, dst_points, mask\n",
    "    \n",
    "    # Convert to numpy arrays if needed\n",
    "    src_points = np.array(src_points, dtype=np.float32)\n",
    "    dst_points = np.array(dst_points, dtype=np.float32)\n",
    "    \n",
    "    # Use RANSAC for X and Y separately, then combine\n",
    "    # For 2D shift, we fit a simple translation model\n",
    "    # Compute median shift as initial estimate\n",
    "    shifts = dst_points - src_points\n",
    "    median_shift = np.median(shifts, axis=0)\n",
    "    \n",
    "    # Compute distances from median shift\n",
    "    expected_dst = src_points + median_shift\n",
    "    distances = np.sqrt(np.sum((dst_points - expected_dst)**2, axis=1))\n",
    "    \n",
    "    # Use IQR method for outlier detection\n",
    "    q1 = np.percentile(distances, 25)\n",
    "    q3 = np.percentile(distances, 75)\n",
    "    iqr = q3 - q1\n",
    "    outlier_threshold = q3 + 2.5 * iqr  # More aggressive (was 1.5)\n",
    "    \n",
    "    # Also use absolute threshold (in pixels)\n",
    "    absolute_threshold = max(threshold, 100.0)  # At least 100 pixels\n",
    "    \n",
    "    # Mark outliers\n",
    "    inlier_mask = (distances <= outlier_threshold) & (distances <= absolute_threshold)\n",
    "    \n",
    "    # Ensure we have at least min_samples inliers\n",
    "    if np.sum(inlier_mask) < min_samples:\n",
    "        # Keep the min_samples points closest to the median\n",
    "        sorted_indices = np.argsort(distances)\n",
    "        inlier_mask = np.zeros(len(src_points), dtype=bool)\n",
    "        inlier_mask[sorted_indices[:min_samples]] = True\n",
    "    \n",
    "    # Ensure inlier_mask is a proper boolean array\n",
    "    inlier_mask = np.asarray(inlier_mask, dtype=bool)\n",
    "    \n",
    "    # Return filtered points\n",
    "    return src_points[inlier_mask], dst_points[inlier_mask], inlier_mask\n",
    "\n",
    "def compute_transformation(matches: Dict, use_affine: bool = False) -> Dict:\n",
    "def compute_transformation(matches: Dict, transformation_type: str = 'shift', match_distances: Optional[List[float]] = None) -> Dict:\n",
    "    \"\"\"\n",
    "    Compute transformation from GCP matches.\n",
    "    \n",
    "    Args:\n",
    "        matches: Dictionary with GCP matches\n",
    "        transformation_type: 'shift', 'affine', 'homography', or 'deformable'\n",
    "        match_distances: Optional list of match distances for weighting\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with transformation parameters\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    Compute 2D shift or affine transformation from GCP matches.\n",
    "    \n",
    "    Args:\n",
    "        matches: Dictionary with GCP matches\n",
    "        use_affine: If True, compute affine transformation; otherwise 2D shift\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with transformation parameters\n",
    "    \"\"\"\n",
    "    # Collect source and destination points\n",
    "    src_points = []\n",
    "    dst_points = []\n",
    "    \n",
    "    for gcp_id, match_data in matches.items():\n",
    "        # Use the best patch size match\n",
    "        best_patch_size = max(match_data.keys())\n",
    "        match = match_data[best_patch_size]\n",
    "        \n",
    "        src_points.append([match['expected_col'], match['expected_row']])\n",
    "        dst_points.append([match['matched_col'], match['matched_row']])\n",
    "    \n",
    "    src_points = np.array(src_points, dtype=np.float32)\n",
    "\n",
    "    dst_points = np.array(dst_points, dtype=np.float32)\n",
    "\n",
    "    # Remove outliers\n",
    "    src_points, dst_points, inlier_mask = remove_outliers_ransac(src_points, dst_points, threshold=100.0, min_samples=3)\n",
    "    \n",
    "    num_outliers = len(src_points) - np.sum(inlier_mask) if 'inlier_mask' in locals() else 0\n",
    "    num_outliers = len(src_points) - np.sum(inlier_mask) if inlier_mask is not None else 0\n",
    "    if num_outliers > 0:\n",
    "        print(f\"  Removed {num_outliers} outlier(s)\")\n",
    "    dst_points = np.array(dst_points, dtype=np.float32)\n",
    "    \n",
    "    if len(src_points) < 3:\n",
    "        # Return original arrays with all True mask\n",
    "        mask = np.ones(len(src_points), dtype=bool)\n",
    "        return {'type': 'insufficient_points', 'error': 'Need at least 2 matches'}\n",
    "    \n",
    "    if use_affine and len(src_points) >= 3:\n",
    "    if transformation_type == 'affine' and len(src_points) >= 3:\n",
    "        # Compute affine transformation (6 parameters)\n",
    "        # Requires at least 3 points\n",
    "        # Compute affine transformation using least squares (all points)\n",
    "        # Affine transform: [x', y'] = [a b; d e] * [x; y] + [c; f]\n",
    "        \n",
    "        # Build system: A * params = b\n",
    "        A = np.zeros((2 * len(src_points), 6))\n",
    "        b = np.zeros(2 * len(src_points))\n",
    "        \n",
    "        for k in range(len(src_points)):\n",
    "            x, y = src_points[k]\n",
    "            xp, yp = dst_points[k]\n",
    "            # x' equation: [x, y, 1, 0, 0, 0] * [a, b, c, d, e, f]^T = x'\n",
    "            A[2*k, :] = [x, y, 1, 0, 0, 0]\n",
    "            b[2*k] = xp\n",
    "            # y' equation: [0, 0, 0, x, y, 1] * [a, b, c, d, e, f]^T = y'\n",
    "            A[2*k+1, :] = [0, 0, 0, x, y, 1]\n",
    "            b[2*k+1] = yp\n",
    "        \n",
    "        # Solve using least squares\n",
    "        params, residuals, rank, s = np.linalg.lstsq(A, b, rcond=None)\n",
    "        \n",
    "        # Reshape to 2x3 matrix\n",
    "        transform_matrix = params.reshape(2, 3)\n",
    "        \n",
    "        # Apply to all points to compute error\n",
    "        ones = np.ones((len(src_points), 1))\n",
    "        src_homogeneous = np.hstack([src_points, ones])\n",
    "        transformed = (transform_matrix @ src_homogeneous.T).T\n",
    "        \n",
    "        errors = dst_points - transformed\n",
    "        rmse = float(np.sqrt(np.mean(np.sum(errors**2, axis=1))))\n",
    "        \n",
    "        return {\n",
    "            'type': 'affine',\n",
    "            'matrix': transform_matrix.tolist(),\n",
    "            'rmse': rmse,\n",
    "            'num_points': len(src_points)\n",
    "        }\n",
    "    else:\n",
    "        # Compute 2D shift (mean offset)\n",
    "        offsets = dst_points - src_points\n",
    "        shift_x = float(np.mean(offsets[:, 0]))\n",
    "        shift_y = float(np.mean(offsets[:, 1]))\n",
    "        \n",
    "        # Compute RMSE\n",
    "        errors = offsets - np.array([shift_x, shift_y])\n",
    "        rmse = float(np.sqrt(np.mean(errors**2)))\n",
    "        \n",
    "        return {\n",
    "            'type': 'shift',\n",
    "            'shift_x': shift_x,\n",
    "            'shift_y': shift_y,\n",
    "            'rmse': rmse,\n",
    "            'num_points': len(src_points)\n",
    "        }\n",
    "\n",
    "# Compute transformations for each ortho\n",
    "transformations = {}\n",
    "\n",
    "\n",
    "# Check if matching_results is defined, load from file if not\n",
    "try:\n",
    "    _ = matching_results\n",
    "    print(\"\u2713 matching_results found in memory\")\n",
    "except NameError:\n",
    "    print(\"matching_results not in memory, attempting to load from file...\")\n",
    "    try:\n",
    "        matches_json = matches_dir / \"matching_results.json\"\n",
    "        if matches_json.exists():\n",
    "            with open(matches_json, 'r') as f:\n",
    "                matching_results = json.load(f)\n",
    "            print(f\"\u2713 Loaded matching_results from {matches_json}\")\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"matching_results.json not found at {matches_json}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\u274c Could not load matching_results: {e}\")\n",
    "        print(\"Please run Step 6 (patch matching) first.\")\n",
    "        raise\n",
    "\n",
    "for ortho_name in matching_results.keys():\n",
    "\n",
    "    # Print match pixel locations for verification\n",
    "\n",
    "    # Get ortho transform for distance calculation\n",
    "    with rasterio.open(reprojected_paths[ortho_name]) as ortho_src:\n",
    "        ortho_transform = ortho_src.transform\n",
    "\n",
    "    print(f\"\\nMatch pixel locations:\")\n",
    "    for gcp_id, match_data in matching_results[ortho_name].items():\n",
    "        best_patch_size = max(match_data.keys()) if match_data else None\n",
    "        if best_patch_size:\n",
    "            match = match_data[best_patch_size]\n",
    "            print(f\"  {gcp_id}: Expected=({match['expected_col']:.1f}, {match['expected_row']:.1f}), \")\n",
    "            print(f\"         Matched=({match['matched_col']:.1f}, {match['matched_row']:.1f}), \")\n",
    "            print(f\"         Offset=({match['offset_col']:.1f}, {match['offset_row']:.1f}) px\")\n",
    "\n",
    "            # Calculate Euclidean distance in meters\n",
    "            # Convert pixel coordinates to UTM coordinates\n",
    "            from rasterio.transform import xy\n",
    "            \n",
    "            # Expected position in UTM\n",
    "            expected_utm_x, expected_utm_y = xy(ortho_transform, match['expected_row'], match['expected_col'])\n",
    "            \n",
    "            # Matched position in UTM\n",
    "            matched_utm_x, matched_utm_y = xy(ortho_transform, match['matched_row'], match['matched_col'])\n",
    "            \n",
    "            # Calculate Euclidean distance in meters\n",
    "            distance_m = np.sqrt((matched_utm_x - expected_utm_x)**2 + (matched_utm_y - expected_utm_y)**2)\n",
    "            distance_cm = distance_m * 100\n",
    "            \n",
    "            print(f\"         Distance: {distance_m:.3f} m ({distance_cm:.2f} cm)\")\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Computing transformation for {ortho_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Try 2D shift first\n",
    "    # Extract match distances for RANSAC weighting\n",
    "    match_distances = []\n",
    "    for gcp_id, match_data in matching_results[ortho_name].items():\n",
    "        best_patch_size = max(match_data.keys()) if match_data else None\n",
    "        if best_patch_size:\n",
    "            match = match_data[best_patch_size]\n",
    "            # Get distance in meters from match data if available\n",
    "            distance = match.get('distance_m', match.get('distance', 0.0))\n",
    "            match_distances.append(distance)\n",
    "    \n",
    "    # Compute all 4 transformation types\n",
    "    transformation_results = {}\n",
    "    \n",
    "    # 1. 2D Shift\n",
    "    shift_result = compute_transformation(matching_results[ortho_name], 'shift', match_distances)\n",
    "    if 'error' not in shift_result:\n",
    "        transformation_results['shift'] = shift_result\n",
    "    \n",
    "    # 2. Affine\n",
    "    if len(matching_results[ortho_name]) >= 3:\n",
    "        affine_result = compute_transformation(matching_results[ortho_name], 'affine', match_distances)\n",
    "        if 'error' not in affine_result:\n",
    "            transformation_results['affine'] = affine_result\n",
    "    \n",
    "    # 3. Homography\n",
    "    if len(matching_results[ortho_name]) >= 4:\n",
    "        homography_result = compute_transformation(matching_results[ortho_name], 'homography', match_distances)\n",
    "        if 'error' not in homography_result:\n",
    "            transformation_results['homography'] = homography_result\n",
    "    \n",
    "    # 4. Deformable\n",
    "    if len(matching_results[ortho_name]) >= 3:\n",
    "        deformable_result = compute_transformation(matching_results[ortho_name], 'deformable', match_distances)\n",
    "        if 'error' not in deformable_result:\n",
    "            transformation_results['deformable'] = deformable_result\n",
    "    \n",
    "    # Print results for all types\n",
    "    print(f\"\\nTransformation Results:\")\n",
    "    for trans_type, result in transformation_results.items():\n",
    "        rmse = result.get('rmse', 'N/A')\n",
    "        num_pts = result.get('num_points', result.get('num_inliers', 0))\n",
    "        rmse_str = f\"{rmse:.2f}\" if isinstance(rmse, (int, float)) else str(rmse)\n",
    "        print(f\"  {trans_type.capitalize()}: RMSE={rmse_str} px, Points={num_pts}\")\n",
    "    \n",
    "    # Select TOP TWO transformations by RMSE\n",
    "    if len(transformation_results) == 0:\n",
    "        print(f\"  \u26a0\ufe0f  No valid transformations computed\")\n",
    "        transformations[ortho_name] = {'error': 'No valid transformations'}\n",
    "        continue\n",
    "    \n",
    "    # Sort by RMSE (lower is better)\n",
    "    sorted_transforms = sorted(\n",
    "        transformation_results.items(),\n",
    "        key=lambda x: x[1].get('rmse', float('inf'))\n",
    "    )\n",
    "    \n",
    "    # Store top 2\n",
    "    top_two = sorted_transforms[:2]\n",
    "    transformations[ortho_name] = {\n",
    "        'primary': top_two[0][1],  # Best transformation\n",
    "        'secondary': top_two[1][1] if len(top_two) > 1 else None,  # Second best\n",
    "        'all_results': transformation_results  # All for reference\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n  \u2713 Selected top 2 transformations:\")\n",
    "    print(f\"    1. {top_two[0][0].capitalize()} (RMSE: {top_two[0][1].get('rmse', 'N/A'):.2f} px)\")\n",
    "    if len(top_two) > 1:\n",
    "        print(f\"    2. {top_two[1][0].capitalize()} (RMSE: {top_two[1][1].get('rmse', 'N/A'):.2f} px)\")\n",
    "    print(f\"\\n2D Shift:\")\n",
    "    shift_x_val = shift_result.get('shift_x', 'N/A')\n",
    "    shift_x_str = f\"{shift_x_val:.2f}\" if isinstance(shift_x_val, (int, float)) else str(shift_x_val)\n",
    "    print(f\"  Shift X: {shift_x_str} px\")\n",
    "    shift_y_val = shift_result.get('shift_y', 'N/A')\n",
    "    shift_y_str = f\"{shift_y_val:.2f}\" if isinstance(shift_y_val, (int, float)) else str(shift_y_val)\n",
    "    print(f\"  Shift Y: {shift_y_str} px\")\n",
    "    rmse_val = shift_result.get('rmse', 'N/A')\n",
    "    rmse_str = f\"{rmse_val:.2f}\" if isinstance(rmse_val, (int, float)) else str(rmse_val)\n",
    "    print(f\"  RMSE: {rmse_str} px\")\n",
    "    print(f\"  Points: {shift_result.get('num_points', 0)}\")\n",
    "    \n",
    "    # Try affine if we have enough points\n",
    "    # Try affine if we have enough points\n",
    "    if len(matching_results[ortho_name]) >= 3:\n",
    "        print(f\"\\nAffine Transformation:\")\n",
    "        affine_rmse_val = affine_result.get('rmse', 'N/A')\n",
    "\n",
    "        affine_rmse_str = f\"{affine_rmse_val:.2f}\" if isinstance(affine_rmse_val, (int, float)) else str(affine_rmse_val)\n",
    "\n",
    "        print(f\"  RMSE: {affine_rmse_str} px\")\n",
    "        print(f\"  Points: {affine_result.get('num_points', 0)}\")\n",
    "\n",
    "        # Use the one with lower RMSE\n",
    "        if affine_result.get('rmse', float('inf')) < shift_result.get('rmse', float('inf')):\n",
    "        else:\n",
    "    else:\n",
    "\n",
    "transformations_file = matches_dir / \"transformations.json\"\n",
    "\n",
    "with open(transformations_file, 'w') as f:\n",
    "    json.dump(transformations, f, indent=2)\n",
    "\n",
    "print(f\"\\n\u2713 Transformations saved to: {transformations_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Apply Transformation and Register Orthomosaics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Apply transformation to orthomosaic\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply_transformation\u001b[39m(\n\u001b[0;32m----> 3\u001b[0m     ortho_path: \u001b[43mPath\u001b[49m,\n\u001b[1;32m      4\u001b[0m     transformation: Dict,\n\u001b[1;32m      5\u001b[0m     output_path: Path,\n\u001b[1;32m      6\u001b[0m     basemap_path: Path\n\u001b[1;32m      7\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Path:\n\u001b[1;32m      8\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m    Apply transformation to register orthomosaic to basemap.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m rasterio\u001b[38;5;241m.\u001b[39mopen(basemap_path) \u001b[38;5;28;01mas\u001b[39;00m basemap_src:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Path' is not defined"
     ]
    }
   ],
   "source": [
    "# Apply transformation to orthomosaic\n",
    "def apply_transformation(\n",
    "    ortho_path: Path,\n",
    "    transformation: Dict,\n",
    "    output_path: Path,\n",
    "    basemap_path: Path\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    Apply transformation to register orthomosaic to basemap.\n",
    "    \"\"\"\n",
    "    with rasterio.open(basemap_path) as basemap_src:\n",
    "        target_width = basemap_src.width\n",
    "        target_height = basemap_src.height\n",
    "        target_transform = basemap_src.transform\n",
    "        target_crs = basemap_src.crs\n",
    "    \n",
    "    with rasterio.open(ortho_path) as ortho_src:\n",
    "        source_data = ortho_src.read()\n",
    "        source_count = ortho_src.count\n",
    "        \n",
    "        # Apply transformation\n",
    "        if transformation['type'] == 'shift':\n",
    "            # Apply 2D shift using scipy\n",
    "            shift_x = transformation['shift_x']\n",
    "            shift_y = transformation['shift_y']\n",
    "            \n",
    "            registered_data = np.zeros((source_count, target_height, target_width), dtype=source_data.dtype)\n",
    "            \n",
    "            for band_idx in range(source_count):\n",
    "                shifted = ndimage.shift(\n",
    "                    source_data[band_idx],\n",
    "                    (shift_y, shift_x),\n",
    "                    mode='constant',\n",
    "                    cval=0,\n",
    "                    order=1\n",
    "                )\n",
    "                \n",
    "                # Crop or pad to match target dimensions\n",
    "                if shifted.shape[0] > target_height:\n",
    "                    shifted = shifted[:target_height, :]\n",
    "                elif shifted.shape[0] < target_height:\n",
    "                    padded = np.zeros((target_height, shifted.shape[1]), dtype=shifted.dtype)\n",
    "                    padded[:shifted.shape[0], :] = shifted\n",
    "                    shifted = padded\n",
    "                \n",
    "                if shifted.shape[1] > target_width:\n",
    "                    shifted = shifted[:, :target_width]\n",
    "                elif shifted.shape[1] < target_width:\n",
    "                    padded = np.zeros((target_height, target_width), dtype=shifted.dtype)\n",
    "                    padded[:, :shifted.shape[1]] = shifted\n",
    "                    shifted = padded\n",
    "                \n",
    "                registered_data[band_idx] = shifted\n",
    "        \n",
    "        elif transformation['type'] == 'affine':\n",
    "\n",
    "        elif transformation['type'] == 'homography':\n",
    "            # Apply homography transformation\n",
    "            homography_matrix = np.array(transformation['matrix'], dtype=np.float32)\n",
    "            \n",
    "            # Create output array\n",
    "            registered_data = np.zeros((source_count, target_height, target_width), dtype=source_data.dtype)\n",
    "            \n",
    "            # Apply transformation per band\n",
    "            for band_idx in range(source_count):\n",
    "                # Use cv2.warpPerspective for homography\n",
    "                # Note: cv2 has dimension limits, so we may need to use scipy for large images\n",
    "                if target_height < 32767 and target_width < 32767:\n",
    "                    # Use OpenCV for smaller images\n",
    "                    transformed = cv2.warpPerspective(\n",
    "                        source_data[band_idx].astype(np.float32),\n",
    "                        homography_matrix,\n",
    "                        (target_width, target_height),\n",
    "                        flags=cv2.INTER_LINEAR,\n",
    "                        borderMode=cv2.BORDER_CONSTANT,\n",
    "                        borderValue=0\n",
    "                    )\n",
    "                    registered_data[band_idx] = transformed.astype(source_data.dtype)\n",
    "                else:\n",
    "                    # Use scipy for large images (manual homography application)\n",
    "                    # Create coordinate grids\n",
    "                    y_coords, x_coords = np.mgrid[0:target_height, 0:target_width].astype(np.float32)\n",
    "                    \n",
    "                    # Convert to homogeneous coordinates\n",
    "                    coords = np.stack([x_coords.ravel(), y_coords.ravel(), np.ones(target_height * target_width)]).T\n",
    "                    \n",
    "                    # Apply inverse homography to get source coordinates\n",
    "                    inv_homography = np.linalg.inv(homography_matrix)\n",
    "                    src_coords = (inv_homography @ coords.T).T\n",
    "                    src_coords = src_coords[:, :2] / src_coords[:, 2:3]  # Normalize\n",
    "                    \n",
    "                    # Reshape and sample\n",
    "                    src_x = src_coords[:, 0].reshape(target_height, target_width)\n",
    "                    src_y = src_coords[:, 1].reshape(target_height, target_width)\n",
    "                    \n",
    "                    # Use scipy.ndimage.map_coordinates for interpolation\n",
    "                    transformed = ndimage.map_coordinates(\n",
    "                        source_data[band_idx],\n",
    "                        [src_y, src_x],\n",
    "                        order=1,\n",
    "                        mode='constant',\n",
    "                        cval=0\n",
    "                    )\n",
    "                    registered_data[band_idx] = transformed.astype(source_data.dtype)\n",
    "            # Apply affine transformation using scipy (handles large images)\n",
    "            transform_matrix = np.array(transformation['matrix'], dtype=np.float32)\n",
    "            \n",
    "            # Extract transformation components\n",
    "            # OpenCV format: [[a, b, c], [d, e, f]]\n",
    "            # scipy.ndimage uses matrix format: [[a, b], [d, e]] and offset [c, f]\n",
    "            matrix_2x2 = transform_matrix[:2, :2]  # [[a, b], [d, e]]\n",
    "            offset = transform_matrix[:2, 2]  # [c, f]\n",
    "            \n",
    "            # Create output array\n",
    "            registered_data = np.zeros((source_count, target_height, target_width), dtype=source_data.dtype)\n",
    "            \n",
    "            # Apply transformation per band\n",
    "            for band_idx in range(source_count):\n",
    "                # scipy.ndimage.affine_transform expects (matrix, offset)\n",
    "                # Note: scipy uses (row, col) convention, so we need to transpose\n",
    "                transformed = ndimage.affine_transform(\n",
    "                    source_data[band_idx],\n",
    "                    matrix=matrix_2x2.T,  # Transpose for (row, col) convention\n",
    "                    offset=offset[::-1],  # Reverse for (row, col): [f, c]\n",
    "                    output_shape=(target_height, target_width),\n",
    "                    order=1,  # Bilinear interpolation\n",
    "                    mode='constant',\n",
    "                    cval=0\n",
    "                )\n",
    "                registered_data[band_idx] = transformed\n",
    "        \n",
    "        # Save registered orthomosaic\n",
    "        with rasterio.open(\n",
    "            output_path,\n",
    "            'w',\n",
    "            driver='GTiff',\n",
    "            height=target_height,\n",
    "            width=target_width,\n",
    "            count=source_count,\n",
    "            dtype=registered_data.dtype,\n",
    "            crs=target_crs,\n",
    "            transform=target_transform,\n",
    "            compress='lzw',\n",
    "            BIGTIFF='YES',\n",
    "            tiled=True\n",
    "        ) as dst:\n",
    "            dst.write(registered_data)\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "# Register orthos\n",
    "registered_paths = {}\n",
    "\n",
    "for ortho_name, transformation_data in transformations.items():\n",
    "\n",
    "    # Check if registered file already exists\n",
    "    registered_path_primary = registered_dir / f\"{ortho_name}_registered_primary.tif\"\n",
    "    registered_path_secondary = registered_dir / f\"{ortho_name}_registered_secondary.tif\"\n",
    "    \n",
    "    # Skip if both already exist\n",
    "    if registered_path_primary.exists() and (transformation_data.get('secondary') is None or registered_path_secondary.exists()):\n",
    "        print(f\"  \u2713 Registered orthos already exist for {ortho_name}\")\n",
    "        if ortho_name not in registered_paths:\n",
    "            registered_paths[ortho_name] = registered_path_primary\n",
    "        continue\n",
    "\n",
    "    if 'error' in transformation_data:\n",
    "        print(f\"\u26a0\ufe0f  Skipping {ortho_name}: {transformation_data['error']}\")\n",
    "        continue\n",
    "    \n",
    "    primary_trans = transformation_data.get('primary')\n",
    "    secondary_trans = transformation_data.get('secondary')\n",
    "    \n",
    "    if not primary_trans:\n",
    "        print(f\"\u26a0\ufe0f  No primary transformation for {ortho_name}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nRegistering {ortho_name}...\")\n",
    "    \n",
    "    # Apply primary transformation\n",
    "    if not registered_path_primary.exists():\n",
    "        print(f\"  Applying primary transformation ({primary_trans.get('type', 'unknown')})...\")\n",
    "        registered_path_primary = apply_transformation(\n",
    "            reprojected_paths[ortho_name],\n",
    "            primary_trans,\n",
    "            registered_path_primary,\n",
    "            basemap_path\n",
    "        )\n",
    "        print(f\"  \u2713 Saved primary: {registered_path_primary}\")\n",
    "    else:\n",
    "        print(f\"  \u2713 Primary already exists: {registered_path_primary}\")\n",
    "    \n",
    "    registered_paths[ortho_name] = registered_path_primary\n",
    "    \n",
    "    # Apply secondary transformation if available\n",
    "    if secondary_trans and not registered_path_secondary.exists():\n",
    "        print(f\"  Applying secondary transformation ({secondary_trans.get('type', 'unknown')})...\")\n",
    "        registered_path_secondary = apply_transformation(\n",
    "            reprojected_paths[ortho_name],\n",
    "            secondary_trans,\n",
    "            registered_path_secondary,\n",
    "            basemap_path\n",
    "        )\n",
    "        print(f\"  \u2713 Saved secondary: {registered_path_secondary}\")\n",
    "    elif secondary_trans:\n",
    "        print(f\"  \u2713 Secondary already exists: {registered_path_secondary}\")\n",
    "\n",
    "print(f\"\\n\u2713 Registration complete!\")\n",
    "\n",
    "        print(f\"  \u2713 Registered ortho already exists: {registered_path}\")\n",
    "        print(f\"    Skipping registration for {ortho_name}...\")\n",
    "        continue\n",
    "\n",
    "    if 'error' in transformation:\n",
    "        print(f\"\u26a0\ufe0f  Skipping {ortho_name}: {transformation['error']}\")\n",
    "        continue\n",
    "    \n",
    "    \n",
    "        reprojected_paths[ortho_name],\n",
    "        transformation,\n",
    "        registered_dir / f\"{ortho_name}_registered.tif\",\n",
    "        basemap_path\n",
    "    )\n",
    "    \n",
    "    print(f\"  \u2713 Saved: {registered_path}\")\n",
    "\n",
    "print(f\"\\n\u2713 Registration complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Evaluate Accuracy Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_dir not defined, using default: outputs\n",
      "gcp_matching_dir not defined, using default: outputs/gcp_matching\n",
      "matches_dir not defined, using default: outputs/gcp_matching/matches\n",
      "registered_dir not defined, using default: outputs/gcp_matching/registered\n",
      "basemap_path not defined, using default: /Users/mauriciohessflores/Documents/Code/Data/New Westminster Oct _25/Michael_RTK_orthos/TestsiteNewWest_Spexigeo_RTK.tiff\n",
      "\u26a0\ufe0f  gcps not defined. Please run Step 2 first.\n",
      "\n",
      "============================================================\n",
      "Evaluating Accuracy Improvement\n",
      "============================================================\n",
      "\u26a0\ufe0f  registered_paths not defined. Please run Step 8 first.\n",
      "\u26a0\ufe0f  Could not reconstruct registered_paths: name 'json' is not defined\n",
      "\u26a0\ufe0f  No registered orthos found. Please run Step 8 first.\n"
     ]
    }
   ],
   "source": [
    "# Check for required variables and set defaults if needed\n",
    "try:\n",
    "    _ = output_dir\n",
    "except NameError:\n",
    "    from pathlib import Path\n",
    "    output_dir = Path(\"outputs\")\n",
    "    print(f\"output_dir not defined, using default: {output_dir}\")\n",
    "\n",
    "try:\n",
    "    _ = gcp_matching_dir\n",
    "except NameError:\n",
    "    gcp_matching_dir = output_dir / \"gcp_matching\"\n",
    "    print(f\"gcp_matching_dir not defined, using default: {gcp_matching_dir}\")\n",
    "\n",
    "try:\n",
    "    _ = matches_dir\n",
    "except NameError:\n",
    "    matches_dir = gcp_matching_dir / \"matches\"\n",
    "    matches_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"matches_dir not defined, using default: {matches_dir}\")\n",
    "\n",
    "try:\n",
    "    _ = registered_dir\n",
    "except NameError:\n",
    "    registered_dir = gcp_matching_dir / \"registered\"\n",
    "    registered_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"registered_dir not defined, using default: {registered_dir}\")\n",
    "\n",
    "try:\n",
    "    _ = basemap_path\n",
    "except NameError:\n",
    "    from pathlib import Path\n",
    "    data_dir = Path(\"/Users/mauriciohessflores/Documents/Code/Data/New Westminster Oct _25\")\n",
    "    basemap_path = data_dir / \"Michael_RTK_orthos\" / \"TestsiteNewWest_Spexigeo_RTK.tiff\"\n",
    "    print(f\"basemap_path not defined, using default: {basemap_path}\")\n",
    "\n",
    "try:\n",
    "    _ = gcps\n",
    "except NameError:\n",
    "    print(\"\u26a0\ufe0f  gcps not defined. Please run Step 2 first.\")\n",
    "    gcps = []\n",
    "\n",
    "# Compare registered orthos to basemap\n",
    "\n",
    "# Import required modules\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import rasterio\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_accuracy(ortho_path: Path, basemap_path: Path, gcps: List[Dict]) -> Dict:\n",
    "    \"\"\"\n",
    "    Evaluate accuracy by comparing pixel values at GCP locations.\n",
    "    \"\"\"\n",
    "    with rasterio.open(basemap_path) as basemap_src:\n",
    "        basemap_data = basemap_src.read()\n",
    "    \n",
    "    with rasterio.open(ortho_path) as ortho_src:\n",
    "        ortho_data = ortho_src.read()\n",
    "    \n",
    "    errors = []\n",
    "    \n",
    "    for gcp in gcps:\n",
    "        pixel_coords = gcp_to_pixel_coords_from_utm(gcp['x_utm'], gcp['y_utm'], basemap_path)\n",
    "        if not pixel_coords:\n",
    "            continue\n",
    "        \n",
    "        col, row = pixel_coords\n",
    "        \n",
    "        if 0 <= row < basemap_data.shape[1] and 0 <= col < basemap_data.shape[2]:\n",
    "            basemap_pixel = basemap_data[:, row, col]\n",
    "            \n",
    "            if 0 <= row < ortho_data.shape[1] and 0 <= col < ortho_data.shape[2]:\n",
    "                ortho_pixel = ortho_data[:, row, col]\n",
    "                \n",
    "                # Compute error (Euclidean distance in pixel space)\n",
    "                error = np.sqrt(np.sum((basemap_pixel.astype(float) - ortho_pixel.astype(float))**2))\n",
    "                errors.append(error)\n",
    "    \n",
    "    if errors:\n",
    "        return {\n",
    "            'mean_error': float(np.mean(errors)),\n",
    "            'rmse': float(np.sqrt(np.mean(np.array(errors)**2))),\n",
    "            'max_error': float(np.max(errors)),\n",
    "            'min_error': float(np.min(errors)),\n",
    "            'num_points': len(errors)\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            'mean_error': 0.0,\n",
    "            'rmse': 0.0,\n",
    "            'max_error': 0.0,\n",
    "            'min_error': 0.0,\n",
    "            'num_points': 0\n",
    "        }\n",
    "\n",
    "\n",
    "# Evaluate accuracy for each registered ortho\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Evaluating Accuracy Improvement\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Check if registered_paths is defined\n",
    "try:\n",
    "    _ = registered_paths\n",
    "except NameError:\n",
    "    print(\"\u26a0\ufe0f  registered_paths not defined. Please run Step 8 first.\")\n",
    "    registered_paths = {}\n",
    "\n",
    "    # Try to load from transformations file or reconstruct from registered directory\n",
    "    try:\n",
    "        # Check if transformations file exists (from Step 7)\n",
    "        transformations_file = matches_dir / \"transformations.json\"\n",
    "        if transformations_file.exists():\n",
    "            with open(transformations_file, 'r') as f:\n",
    "                transformations = json.load(f)\n",
    "            \n",
    "            # Reconstruct registered_paths from transformations\n",
    "            registered_paths = {}\n",
    "            for ortho_name in transformations.keys():\n",
    "                registered_path = registered_dir / f\"{ortho_name}_registered.tif\"\n",
    "                if registered_path.exists():\n",
    "                    registered_paths[ortho_name] = registered_path\n",
    "            \n",
    "            if len(registered_paths) > 0:\n",
    "                print(f\"\u2713 Reconstructed registered_paths from {transformations_file}\")\n",
    "                print(f\"  Found {len(registered_paths)} registered orthos\")\n",
    "        else:\n",
    "            # Try to find registered files directly\n",
    "            if registered_dir.exists():\n",
    "                registered_files = list(registered_dir.glob(\"*_registered.tif\"))\n",
    "                if registered_files:\n",
    "                    registered_paths = {}\n",
    "                    for reg_file in registered_files:\n",
    "                        # Extract ortho name from filename (e.g., 'no_gcps_registered.tif' -> 'no_gcps')\n",
    "                        ortho_name = reg_file.stem.replace('_registered', '')\n",
    "                        registered_paths[ortho_name] = reg_file\n",
    "                    \n",
    "                    if len(registered_paths) > 0:\n",
    "                        print(f\"\u2713 Found {len(registered_paths)} registered orthos in {registered_dir}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\u26a0\ufe0f  Could not reconstruct registered_paths: {e}\")\n",
    "\n",
    "if len(registered_paths) == 0:\n",
    "    print(\"\u26a0\ufe0f  No registered orthos found. Please run Step 8 first.\")\n",
    "else:\n",
    "    for ortho_name in registered_paths.keys():\n",
    "        print(f\"\\nEvaluating {ortho_name}...\")\n",
    "        \n",
    "        registered_path = registered_paths[ortho_name]\n",
    "        \n",
    "        if not registered_path.exists():\n",
    "            print(f\"  \u26a0\ufe0f  Registered ortho not found: {registered_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Evaluate accuracy\n",
    "        try:\n",
    "            accuracy_metrics = evaluate_accuracy(\n",
    "                registered_path,\n",
    "                basemap_path,\n",
    "                gcps\n",
    "            )\n",
    "            \n",
    "            print(f\"\\n  Accuracy Metrics:\")\n",
    "            mean_err = accuracy_metrics.get('mean_error', 'N/A')\n",
    "            if isinstance(mean_err, (int, float)):\n",
    "                print(f\"    Mean Error: {mean_err:.3f} m\")\n",
    "            else:\n",
    "                print(f\"    Mean Error: {mean_err}\")\n",
    "            \n",
    "            rmse = accuracy_metrics.get('rmse', 'N/A')\n",
    "            if isinstance(rmse, (int, float)):\n",
    "                print(f\"    RMSE: {rmse:.3f} m\")\n",
    "            else:\n",
    "                print(f\"    RMSE: {rmse}\")\n",
    "            \n",
    "            max_err = accuracy_metrics.get('max_error', 'N/A')\n",
    "            if isinstance(max_err, (int, float)):\n",
    "                print(f\"    Max Error: {max_err:.3f} m\")\n",
    "            else:\n",
    "                print(f\"    Max Error: {max_err}\")\n",
    "            \n",
    "            print(f\"    Points Evaluated: {accuracy_metrics.get('num_points', 0)}\")\n",
    "\n",
    "# Generate LaTeX report\n",
    "latex_report_path = output_dir / \"gcp_matching\" / \"accuracy_report.tex\"\n",
    "latex_report_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "latex_content = []\n",
    "latex_content.append(\"\\\\documentclass[11pt]{article}\")\n",
    "latex_content.append(\"\\\\usepackage[utf8]{inputenc}\")\n",
    "latex_content.append(\"\\\\usepackage{graphicx}\")\n",
    "latex_content.append(\"\\\\usepackage{geometry}\")\n",
    "latex_content.append(\"\\\\geometry{a4paper, margin=1in}\")\n",
    "latex_content.append(\"\\\\usepackage{booktabs}\")\n",
    "latex_content.append(\"\\\\usepackage{float}\")\n",
    "latex_content.append(\"\\\\usepackage{caption}\")\n",
    "latex_content.append(\"\\\\begin{document}\")\n",
    "latex_content.append(\"\\\\title{GCP Matching Accuracy Evaluation Report}\")\n",
    "latex_content.append(\"\\\\author{Automated Analysis}\")\n",
    "latex_content.append(\"\\\\date{\\\\today}\")\n",
    "latex_content.append(\"\\\\maketitle\")\n",
    "latex_content.append(\"\\\\section{Executive Summary}\")\n",
    "latex_content.append(\"This report presents the accuracy evaluation of registered orthomosaics against the ground control basemap.\")\n",
    "latex_content.append(\"\\\\section{Accuracy Metrics}\")\n",
    "latex_content.append(\"\\\\begin{table}[H]\")\n",
    "latex_content.append(\"\\\\centering\")\n",
    "latex_content.append(\"\\\\begin{tabular}{lcccc}\")\n",
    "latex_content.append(\"\\\\toprule\")\n",
    "latex_content.append(\"Orthomosaic & Mean Error (m) & RMSE (m) & Max Error (m) & Points \\\\\\\\\")\n",
    "latex_content.append(\"\\\\midrule\")\n",
    "\n",
    "# Collect all accuracy metrics\n",
    "all_accuracy_metrics = {}\n",
    "\n",
    "for ortho_name in registered_paths.keys():\n",
    "    registered_path = registered_paths[ortho_name]\n",
    "    if not registered_path.exists():\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        accuracy_metrics = evaluate_accuracy(registered_path, basemap_path, gcps)\n",
    "        all_accuracy_metrics[ortho_name] = accuracy_metrics\n",
    "        \n",
    "        # Add to LaTeX table\n",
    "        mean_err = accuracy_metrics.get('mean_error', 0.0)\n",
    "        rmse = accuracy_metrics.get('rmse', 0.0)\n",
    "        max_err = accuracy_metrics.get('max_error', 0.0)\n",
    "        num_pts = accuracy_metrics.get('num_points', 0)\n",
    "        \n",
    "        mean_str = f\"{mean_err:.3f}\" if isinstance(mean_err, (int, float)) else \"N/A\"\n",
    "        rmse_str = f\"{rmse:.3f}\" if isinstance(rmse, (int, float)) else \"N/A\"\n",
    "        max_str = f\"{max_err:.3f}\" if isinstance(max_err, (int, float)) else \"N/A\"\n",
    "        \n",
    "        ortho_display = ortho_name.replace('_', ' ').title()\n",
    "        latex_content.append(f\"{ortho_display} & {mean_str} & {rmse_str} & {max_str} & {num_pts} \\\\\\\\\")\n",
    "    except Exception as e:\n",
    "        print(f\"  \u26a0\ufe0f  Error evaluating {ortho_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "latex_content.append(\"\\\\bottomrule\")\n",
    "latex_content.append(\"\\\\end{tabular}\")\n",
    "latex_content.append(\"\\\\caption{Accuracy metrics for registered orthomosaics}\")\n",
    "latex_content.append(\"\\\\label{tab:accuracy}\")\n",
    "latex_content.append(\"\\\\end{table}\")\n",
    "\n",
    "# Add visualization section if figures exist\n",
    "latex_content.append(\"\\\\section{Visualizations}\")\n",
    "\n",
    "# Check for visualization files\n",
    "vis_dir = gcp_matching_dir / \"visualizations\"\n",
    "if vis_dir.exists():\n",
    "    vis_files = list(vis_dir.glob(\"*.png\")) + list(vis_dir.glob(\"*.jpg\"))\n",
    "    for vis_file in sorted(vis_files):\n",
    "        # Copy to report directory for LaTeX\n",
    "        report_vis_dir = latex_report_path.parent / \"figures\"\n",
    "        report_vis_dir.mkdir(exist_ok=True)\n",
    "        import shutil\n",
    "        dest_file = report_vis_dir / vis_file.name\n",
    "        if not dest_file.exists():\n",
    "            shutil.copy(vis_file, dest_file)\n",
    "        \n",
    "        # Add figure to LaTeX\n",
    "        fig_name = vis_file.stem.replace('_', ' ').title()\n",
    "        latex_content.append(f\"\\\\begin{{figure}}[H]\")\n",
    "        latex_content.append(f\"\\\\centering\")\n",
    "        latex_content.append(f\"\\\\includegraphics[width=0.8\\\\textwidth]{{figures/{vis_file.name}}}\")\n",
    "        latex_content.append(f\"\\\\caption{{{fig_name}}}\")\n",
    "        latex_content.append(f\"\\\\label{{fig:{vis_file.stem}}}\")\n",
    "        latex_content.append(f\"\\\\end{{figure}}\")\n",
    "\n",
    "latex_content.append(\"\\\\section{Conclusion}\")\n",
    "latex_content.append(\"The registered orthomosaics show improved alignment with the ground control basemap.\")\n",
    "latex_content.append(\"\\\\end{document}\")\n",
    "\n",
    "# Write LaTeX file\n",
    "with open(latex_report_path, 'w') as f:\n",
    "    f.write('\\n'.join(latex_content))\n",
    "\n",
    "print(f\"\\n\u2713 LaTeX report generated: {latex_report_path}\")\n",
    "print(f\"  To compile: pdflatex {latex_report_path.name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  \u274c Error evaluating accuracy: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}