{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orthomosaic-Basemap Feature Matching and Registration\n",
    "\n",
    "This notebook performs feature matching between orthomosaics (with/without GCPs) and a ground control basemap using SIFT and evaluates 2D shifting and registration.\n",
    "\n",
    "## Goals:\n",
    "1. **Feature Matching**: Use SIFT to find corresponding features between orthos and basemap\n",
    "2. **Multi-Resolution Analysis**: Evaluate matching at full, half, and quarter resolution\n",
    "3. **2D Registration**: Apply computed shifts to register orthos to basemap\n",
    "4. **Visualization**: Create visualizations of matches and registered orthos\n",
    "\n",
    "## Inputs:\n",
    "- **Ground Control Basemap**: `TestsiteNewWest_Spexigeo_RTK.tiff`\n",
    "- **Orthomosaic (No GCPs)**: `outputs/orthomosaics/orthomosaic_no_gcps.tif`\n",
    "- **Orthomosaic (With GCPs)**: `outputs/orthomosaics/orthomosaic_with_gcps.tif`\n",
    "\n",
    "## Outputs:\n",
    "- All outputs saved to `outputs/test_matching/`\n",
    "- Match visualizations at different resolutions\n",
    "- Registered orthomosaics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Install Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Dependencies installed\n"
     ]
    }
   ],
   "source": [
    "# Install required packages if needed\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "packages = ['opencv-python', 'scikit-image', 'rasterio', 'numpy', 'matplotlib', 'pillow', 'scipy']\n",
    "for package in packages:\n",
    "    try:\n",
    "        if package == 'opencv-python':\n",
    "            __import__('cv2')\n",
    "        elif package == 'scikit-image':\n",
    "            __import__('skimage')\n",
    "        elif package == 'pillow':\n",
    "            __import__('PIL')\n",
    "        else:\n",
    "            __import__(package)\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "print(\"‚úì Dependencies installed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Imports successful!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling, transform_bounds\n",
    "from rasterio import Affine\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import warnings\n",
    "import json\n",
    "from typing import Dict, Tuple, Optional, List\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"‚úì Imports successful!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup Paths and Output Directories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Output directory: outputs/test_matching\n",
      "  - Reprojected: outputs/test_matching/reprojected\n",
      "  - Converted: outputs/test_matching/converted\n",
      "  - Matches: outputs/test_matching/matches\n",
      "  - Registered: outputs/test_matching/registered\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "data_dir = Path(\"/Users/mauriciohessflores/Documents/Code/Data/New Westminster Oct _25\")\n",
    "output_dir = Path(\"outputs\")\n",
    "\n",
    "# Input files\n",
    "basemap_path = data_dir / \"Michael_RTK_orthos\" / \"TestsiteNewWest_Spexigeo_RTK.tiff\"\n",
    "ortho_no_gcps_path = output_dir / \"orthomosaics\" / \"orthomosaic_no_gcps.tif\"\n",
    "ortho_with_gcps_path = output_dir / \"orthomosaics\" / \"orthomosaic_with_gcps.tif\"\n",
    "\n",
    "# Output directory structure\n",
    "matching_output_dir = output_dir / \"test_matching\"\n",
    "matching_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Subdirectories\n",
    "reprojected_dir = matching_output_dir / \"reprojected\"\n",
    "reprojected_dir.mkdir(exist_ok=True)\n",
    "\n",
    "converted_dir = matching_output_dir / \"converted\"\n",
    "converted_dir.mkdir(exist_ok=True)\n",
    "\n",
    "matches_dir = matching_output_dir / \"matches\"\n",
    "matches_dir.mkdir(exist_ok=True)\n",
    "\n",
    "registered_dir = matching_output_dir / \"registered\"\n",
    "registered_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"‚úì Output directory: {matching_output_dir}\")\n",
    "print(f\"  - Reprojected: {reprojected_dir}\")\n",
    "print(f\"  - Converted: {converted_dir}\")\n",
    "print(f\"  - Matches: {matches_dir}\")\n",
    "print(f\"  - Registered: {registered_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load and Check Input Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì All input files found\n",
      "\n",
      "üìä File Information:\n",
      "\n",
      "Basemap:\n",
      "  Path: /Users/mauriciohessflores/Documents/Code/Data/New Westminster Oct _25/Michael_RTK_orthos/TestsiteNewWest_Spexigeo_RTK.tiff\n",
      "  Size: 19804.91 MB\n",
      "  CRS: EPSG:32610\n",
      "  Dimensions: 90129 x 90188\n",
      "  Bands: 4\n",
      "  Bounds: BoundingBox(left=506424.37839793676, bottom=5450017.622213458, right=507501.0951215451, top=5451095.043774429)\n",
      "  Pixel size: 0.0119 m (X), 0.0119 m (Y)\n",
      "\n",
      "Ortho (No GCPs):\n",
      "  Path: outputs/orthomosaics/orthomosaic_no_gcps.tif\n",
      "  Size: 3887.28 MB\n",
      "  CRS: EPSG:4326\n",
      "  Dimensions: 38531 x 39277\n",
      "  Bands: 4\n",
      "  Bounds: BoundingBox(left=-122.91170031378732, bottom=49.20303508811748, right=-122.89720111440005, top=49.212718829461046)\n",
      "  Pixel size: 0.0000 m (X), 0.0000 m (Y)\n",
      "\n",
      "Ortho (With GCPs):\n",
      "  Path: outputs/orthomosaics/orthomosaic_with_gcps.tif\n",
      "  Size: 3867.91 MB\n",
      "  CRS: EPSG:4326\n",
      "  Dimensions: 38538 x 39233\n",
      "  Bands: 4\n",
      "  Bounds: BoundingBox(left=-122.9117167927641, bottom=49.203044960109175, right=-122.89720605758104, top=49.21272378933356)\n",
      "  Pixel size: 0.0000 m (X), 0.0000 m (Y)\n"
     ]
    }
   ],
   "source": [
    "# Check if files exist\n",
    "if not basemap_path.exists():\n",
    "    raise FileNotFoundError(f\"Basemap not found: {basemap_path}\")\n",
    "if not ortho_no_gcps_path.exists():\n",
    "    raise FileNotFoundError(f\"Orthomosaic (no GCPs) not found: {ortho_no_gcps_path}\")\n",
    "if not ortho_with_gcps_path.exists():\n",
    "    raise FileNotFoundError(f\"Orthomosaic (with GCPs) not found: {ortho_with_gcps_path}\")\n",
    "\n",
    "print(\"‚úì All input files found\")\n",
    "\n",
    "# Get basic info about each file\n",
    "print(\"\\nüìä File Information:\")\n",
    "for name, path in [(\"Basemap\", basemap_path), (\"Ortho (No GCPs)\", ortho_no_gcps_path), (\"Ortho (With GCPs)\", ortho_with_gcps_path)]:\n",
    "    with rasterio.open(path) as src:\n",
    "        file_size_mb = path.stat().st_size / (1024 * 1024)\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"  Path: {path}\")\n",
    "        print(f\"  Size: {file_size_mb:.2f} MB\")\n",
    "        print(f\"  CRS: {src.crs}\")\n",
    "        print(f\"  Dimensions: {src.width} x {src.height}\")\n",
    "        print(f\"  Bands: {src.count}\")\n",
    "        print(f\"  Bounds: {src.bounds}\")\n",
    "        if src.crs:\n",
    "            pixel_size_x = abs(src.transform[0])\n",
    "            pixel_size_y = abs(src.transform[4])\n",
    "            print(f\"  Pixel size: {pixel_size_x:.4f} m (X), {pixel_size_y:.4f} m (Y)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Reproject Orthomosaics to Match Basemap CRS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target CRS: EPSG:32610\n",
      "Target bounds: BoundingBox(left=506424.37839793676, bottom=5450017.622213458, right=507501.0951215451, top=5451095.043774429)\n",
      "Target dimensions: 90129 x 90188\n",
      "\n",
      "============================================================\n",
      "Reprojecting no_gcps...\n",
      "  ‚úì Already reprojected: outputs/test_matching/reprojected/no_gcps_reprojected.tif\n",
      "    Dimensions: 88515x89120, CRS: EPSG:32610\n",
      "\n",
      "============================================================\n",
      "Reprojecting with_gcps...\n",
      "  Source CRS: EPSG:4326\n",
      "  Source bounds: BoundingBox(left=-122.9117167927641, bottom=49.203044960109175, right=-122.89720605758104, top=49.21272378933356)\n",
      "  Transforming source bounds to target CRS...\n",
      "  Source bounds in target CRS: (506429.71224202216, 5450031.47560229, 507487.9980312089, 5451108.798120763)\n",
      "  Output bounds (intersection): left=506429.71, bottom=5450031.48, right=507488.00, top=5451095.04\n",
      "  ‚úì Transform calculated: 88586x89028 pixels\n",
      "  Reprojecting to 88586x89028...\n",
      "  ‚úì Saved: outputs/test_matching/reprojected/with_gcps_reprojected.tif\n",
      "  Note: JPEG conversion will be done in Step 4 (PIL limit: 65500 pixels)\n",
      "\n",
      "‚úì Reprojection complete!\n"
     ]
    }
   ],
   "source": [
    "# Get basemap CRS (target CRS)\n",
    "with rasterio.open(basemap_path) as basemap_src:\n",
    "    target_crs = basemap_src.crs\n",
    "    target_bounds = basemap_src.bounds\n",
    "    target_transform = basemap_src.transform\n",
    "    target_width = basemap_src.width\n",
    "    target_height = basemap_src.height\n",
    "\n",
    "print(f\"Target CRS: {target_crs}\")\n",
    "print(f\"Target bounds: {target_bounds}\")\n",
    "print(f\"Target dimensions: {target_width} x {target_height}\")\n",
    "\n",
    "# Reproject each orthomosaic\n",
    "ortho_paths = {\n",
    "    'no_gcps': ortho_no_gcps_path,\n",
    "    'with_gcps': ortho_with_gcps_path\n",
    "}\n",
    "\n",
    "reprojected_paths = {}\n",
    "\n",
    "for ortho_name, ortho_path in ortho_paths.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Reprojecting {ortho_name}...\")\n",
    "    \n",
    "    reprojected_path = reprojected_dir / f\"{ortho_name}_reprojected.tif\"\n",
    "    \n",
    "    # Check if already reprojected (skip if file exists and is valid)\n",
    "    if reprojected_path.exists():\n",
    "        try:\n",
    "            # Verify the file is valid by checking its properties\n",
    "            with rasterio.open(reprojected_path) as check_src:\n",
    "                if check_src.crs == target_crs:\n",
    "                    print(f\"  ‚úì Already reprojected: {reprojected_path}\")\n",
    "                    print(f\"    Dimensions: {check_src.width}x{check_src.height}, CRS: {check_src.crs}\")\n",
    "                    reprojected_paths[ortho_name] = reprojected_path\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"  ‚ö†Ô∏è  Existing file has wrong CRS, will reproject...\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö†Ô∏è  Existing file is invalid ({e}), will reproject...\")\n",
    "    \n",
    "    with rasterio.open(ortho_path) as ortho_src:\n",
    "        source_crs = ortho_src.crs\n",
    "        source_bounds = ortho_src.bounds\n",
    "        \n",
    "        print(f\"  Source CRS: {source_crs}\")\n",
    "        print(f\"  Source bounds: {source_bounds}\")\n",
    "        \n",
    "        # Check if reprojection is needed\n",
    "        if source_crs == target_crs:\n",
    "            print(f\"  ‚úì Already in target CRS, copying...\")\n",
    "            import shutil\n",
    "            shutil.copy(ortho_path, reprojected_path)\n",
    "            reprojected_paths[ortho_name] = reprojected_path\n",
    "            continue\n",
    "        \n",
    "        # Calculate transform using source bounds (not target bounds)\n",
    "        # First, transform source bounds to target CRS to get output extent\n",
    "        try:\n",
    "            print(f\"  Transforming source bounds to target CRS...\")\n",
    "            src_bounds_target_crs = transform_bounds(\n",
    "                source_crs, target_crs,\n",
    "                source_bounds.left, source_bounds.bottom,\n",
    "                source_bounds.right, source_bounds.top\n",
    "            )\n",
    "            \n",
    "            print(f\"  Source bounds in target CRS: {src_bounds_target_crs}\")\n",
    "            \n",
    "            # Get target pixel size\n",
    "            target_pixel_size_x = abs(target_transform[0])\n",
    "            target_pixel_size_y = abs(target_transform[4])\n",
    "            \n",
    "            # Use intersection of bounds (where both images overlap)\n",
    "            output_left = max(src_bounds_target_crs[0], target_bounds.left)\n",
    "            output_bottom = max(src_bounds_target_crs[1], target_bounds.bottom)\n",
    "            output_right = min(src_bounds_target_crs[2], target_bounds.right)\n",
    "            output_top = min(src_bounds_target_crs[3], target_bounds.top)\n",
    "            \n",
    "            print(f\"  Output bounds (intersection): left={output_left:.2f}, bottom={output_bottom:.2f}, right={output_right:.2f}, top={output_top:.2f}\")\n",
    "            \n",
    "            # Validate bounds\n",
    "            if output_right <= output_left or output_top <= output_bottom:\n",
    "                raise ValueError(f\"Invalid output bounds: width={output_right-output_left}, height={output_top-output_bottom}\")\n",
    "            \n",
    "            # Calculate dimensions using target pixel size\n",
    "            width = int((output_right - output_left) / target_pixel_size_x)\n",
    "            height = int((output_top - output_bottom) / target_pixel_size_y)\n",
    "            \n",
    "            # Validate dimensions\n",
    "            if width <= 0 or height <= 0:\n",
    "                raise ValueError(f\"Invalid dimensions: width={width}, height={height}\")\n",
    "            \n",
    "            # Create transform for output\n",
    "            transform = Affine.translation(output_left, output_top) * Affine.scale(target_pixel_size_x, -target_pixel_size_y)\n",
    "            \n",
    "            print(f\"  ‚úì Transform calculated: {width}x{height} pixels\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Transform calculation failed: {e}\")\n",
    "            print(f\"  Trying alternative approach using source resolution...\")\n",
    "            \n",
    "            # Alternative: use source resolution and calculate output bounds\n",
    "            try:\n",
    "                # Get source pixel size\n",
    "                source_pixel_size_x = abs(ortho_src.transform[0])\n",
    "                source_pixel_size_y = abs(ortho_src.transform[4])\n",
    "                \n",
    "                # Transform source bounds to target CRS\n",
    "                src_bounds_target_crs = transform_bounds(\n",
    "                    source_crs, target_crs,\n",
    "                    source_bounds.left, source_bounds.bottom,\n",
    "                    source_bounds.right, source_bounds.top\n",
    "                )\n",
    "                \n",
    "                # Use source pixel size (approximate)\n",
    "                output_left = src_bounds_target_crs[0]\n",
    "                output_bottom = src_bounds_target_crs[1]\n",
    "                output_right = src_bounds_target_crs[2]\n",
    "                output_top = src_bounds_target_crs[3]\n",
    "                \n",
    "                # Calculate dimensions\n",
    "                width = int((output_right - output_left) / source_pixel_size_x)\n",
    "                height = int((output_top - output_bottom) / source_pixel_size_y)\n",
    "                \n",
    "                transform = Affine.translation(output_left, output_top) * Affine.scale(source_pixel_size_x, -source_pixel_size_y)\n",
    "                \n",
    "                print(f\"  ‚úì Using source resolution approach: {width}x{height} pixels\")\n",
    "                \n",
    "            except Exception as e2:\n",
    "                print(f\"  ‚ùå Alternative approach also failed: {e2}\")\n",
    "                print(f\"  Skipping {ortho_name}...\")\n",
    "                continue\n",
    "        \n",
    "        # Reproject\n",
    "        print(f\"  Reprojecting to {width}x{height}...\")\n",
    "        \n",
    "        # Read source data\n",
    "        source_data = ortho_src.read()\n",
    "        source_count = ortho_src.count\n",
    "        \n",
    "        # Reproject each band\n",
    "        reprojected_data = np.zeros((source_count, height, width), dtype=source_data.dtype)\n",
    "        \n",
    "        for band_idx in range(1, source_count + 1):\n",
    "            reproject(\n",
    "                source=rasterio.band(ortho_src, band_idx),\n",
    "                destination=reprojected_data[band_idx - 1],\n",
    "                src_transform=ortho_src.transform,\n",
    "                src_crs=source_crs,\n",
    "                dst_transform=transform,\n",
    "                dst_crs=target_crs,\n",
    "                resampling=Resampling.bilinear\n",
    "            )\n",
    "        \n",
    "        # Save reprojected file with LZW compression\n",
    "        # Note: We skip saving JPEG here because PIL has a 65500 pixel limit\n",
    "        # JPEG conversion will be done in Step 4 at different resolutions\n",
    "        \n",
    "        # Save GeoTIFF with compression\n",
    "        with rasterio.open(\n",
    "            reprojected_path,\n",
    "            'w',\n",
    "            driver='GTiff',\n",
    "            height=height,\n",
    "            width=width,\n",
    "            count=source_count,\n",
    "            dtype=reprojected_data.dtype,\n",
    "            crs=target_crs,\n",
    "            transform=transform,\n",
    "            compress='lzw',\n",
    "            BIGTIFF='YES',\n",
    "            tiled=True,\n",
    "            blockxsize=512,\n",
    "            blockysize=512,\n",
    "            predictor=2  # Horizontal differencing for better compression\n",
    "        ) as dst:\n",
    "            dst.write(reprojected_data)\n",
    "        \n",
    "        print(f\"  ‚úì Saved: {reprojected_path}\")\n",
    "        print(f\"  Note: JPEG conversion will be done in Step 4 (PIL limit: 65500 pixels)\")\n",
    "        reprojected_paths[ortho_name] = reprojected_path\n",
    "\n",
    "print(f\"\\n‚úì Reprojection complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting files to JPEG at different resolutions...\n",
      "\n",
      "Converting basemap at full resolution...\n"
     ]
    }
   ],
   "source": [
    "def convert_geotiff_to_jpeg(geotiff_path: Path, output_path: Path, downsample_factor: float = 1.0) -> Tuple[np.ndarray, Dict]:\n",
    "    \"\"\"\n",
    "    Convert GeoTIFF to JPEG format at specified resolution.\n",
    "    \n",
    "    Args:\n",
    "        geotiff_path: Path to input GeoTIFF\n",
    "        output_path: Path to save JPEG\n",
    "        downsample_factor: Factor to downsample (1.0 = full res, 0.5 = half, 0.25 = quarter)\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (image array, metadata dict with transform info)\n",
    "    \"\"\"\n",
    "    with rasterio.open(geotiff_path) as src:\n",
    "        # Get metadata\n",
    "        metadata = {\n",
    "            'transform': src.transform,\n",
    "            'crs': src.crs,\n",
    "            'bounds': src.bounds,\n",
    "            'width': src.width,\n",
    "            'height': src.height\n",
    "        }\n",
    "        \n",
    "        # Calculate output dimensions\n",
    "        if downsample_factor < 1.0:\n",
    "            new_height = int(src.height * downsample_factor)\n",
    "            new_width = int(src.width * downsample_factor)\n",
    "        else:\n",
    "            new_height = src.height\n",
    "            new_width = src.width\n",
    "        \n",
    "        print(f\"    Processing {src.width}x{src.height} -> {new_width}x{new_height} (factor: {downsample_factor})\")\n",
    "        \n",
    "        # For very large images, process in tiles to avoid memory issues\n",
    "        # Use tile-based processing for images > 10k pixels\n",
    "        use_tiles = src.width > 10000 or src.height > 10000\n",
    "        \n",
    "        if use_tiles:\n",
    "            # Process in tiles with downsampling\n",
    "            print(f\"    Using tile-based processing (tile size: 2048)...\")\n",
    "            \n",
    "            # Compute global statistics for normalization\n",
    "            print(f\"    Computing image statistics for normalization...\")\n",
    "            if src.count >= 3:\n",
    "                stats = [src.statistics(i) for i in [1, 2, 3]]\n",
    "                data_min = np.array([[s.min] for s in stats])\n",
    "                data_max = np.array([[s.max] for s in stats])\n",
    "            else:\n",
    "                stats = src.statistics(1)\n",
    "                data_min = np.array([[stats.min]])\n",
    "                data_max = np.array([[stats.max]])\n",
    "            \n",
    "            data_range = data_max - data_min\n",
    "            data_range[data_range == 0] = 1\n",
    "            \n",
    "            # Create output array\n",
    "            output_array = np.zeros((new_height, new_width, 3), dtype=np.uint8)\n",
    "            tile_size = 2048\n",
    "            \n",
    "            # Process in tiles\n",
    "            num_tiles_x = (src.width + tile_size - 1) // tile_size\n",
    "            num_tiles_y = (src.height + tile_size - 1) // tile_size\n",
    "            \n",
    "            for tile_y in range(num_tiles_y):\n",
    "                for tile_x in range(num_tiles_x):\n",
    "                    # Calculate tile window\n",
    "                    col_off = tile_x * tile_size\n",
    "                    row_off = tile_y * tile_size\n",
    "                    width = min(tile_size, src.width - col_off)\n",
    "                    height = min(tile_size, src.height - row_off)\n",
    "                    \n",
    "                    window = rasterio.windows.Window(col_off, row_off, width, height)\n",
    "                    \n",
    "                    # Read tile\n",
    "                    if src.count >= 3:\n",
    "                        tile_data = src.read([1, 2, 3], window=window)\n",
    "                    else:\n",
    "                        tile_data = src.read(1, window=window)\n",
    "                        tile_data = np.stack([tile_data] * 3)\n",
    "                    \n",
    "                    # Normalize\n",
    "                    tile_normalized = ((tile_data - data_min) / data_range * 255).astype(np.uint8)\n",
    "                    \n",
    "                    # Downsample tile\n",
    "                    if downsample_factor < 1.0:\n",
    "                        tile_h, tile_w = tile_normalized.shape[1], tile_normalized.shape[2]\n",
    "                        new_tile_h = int(tile_h * downsample_factor)\n",
    "                        new_tile_w = int(tile_w * downsample_factor)\n",
    "                        \n",
    "                        tile_resized = np.zeros((3, new_tile_h, new_tile_w), dtype=np.uint8)\n",
    "                        for i in range(3):\n",
    "                            tile_resized[i] = cv2.resize(tile_normalized[i], (new_tile_w, new_tile_h), interpolation=cv2.INTER_AREA)\n",
    "                        tile_normalized = tile_resized\n",
    "                    \n",
    "                    # Calculate output position\n",
    "                    out_col_off = int(col_off * downsample_factor)\n",
    "                    out_row_off = int(row_off * downsample_factor)\n",
    "                    out_h, out_w = tile_normalized.shape[1], tile_normalized.shape[2]\n",
    "                    \n",
    "                    # Ensure we don't exceed output bounds\n",
    "                    out_h = min(out_h, new_height - out_row_off)\n",
    "                    out_w = min(out_w, new_width - out_col_off)\n",
    "                    \n",
    "                    if out_h > 0 and out_w > 0:\n",
    "                        # Convert to (H, W, C) and place in output\n",
    "                        tile_rgb = tile_normalized[:, :out_h, :out_w].transpose(1, 2, 0)\n",
    "                        output_array[out_row_off:out_row_off+out_h, out_col_off:out_col_off+out_w] = tile_rgb\n",
    "                \n",
    "                if (tile_y + 1) % 10 == 0:\n",
    "                    print(f\"      Processed {tile_y + 1}/{num_tiles_y} tile rows...\")\n",
    "            \n",
    "            img_array = output_array\n",
    "            \n",
    "        else:\n",
    "            # For smaller images, read normally\n",
    "            if src.count >= 3:\n",
    "                data = src.read([1, 2, 3])\n",
    "            else:\n",
    "                data = src.read(1)\n",
    "                data = np.stack([data, data, data])\n",
    "            \n",
    "            # Normalize to 0-255\n",
    "            if data.dtype != np.uint8:\n",
    "                data_min = data.min(axis=(1, 2), keepdims=True)\n",
    "                data_max = data.max(axis=(1, 2), keepdims=True)\n",
    "                data_range = data_max - data_min\n",
    "                data_range[data_range == 0] = 1\n",
    "                data = ((data - data_min) / data_range * 255).astype(np.uint8)\n",
    "            \n",
    "            # Downsample if needed\n",
    "            if downsample_factor < 1.0:\n",
    "                height, width = data.shape[1], data.shape[2]\n",
    "                new_height = int(height * downsample_factor)\n",
    "                new_width = int(width * downsample_factor)\n",
    "                \n",
    "                data_resized = np.zeros((3, new_height, new_width), dtype=np.uint8)\n",
    "                for i in range(3):\n",
    "                    data_resized[i] = cv2.resize(data[i], (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "                data = data_resized\n",
    "            \n",
    "            # Convert to PIL Image format (H, W, C)\n",
    "            img_array = data.transpose(1, 2, 0)\n",
    "        \n",
    "        # Update metadata\n",
    "        metadata['width'] = new_width\n",
    "        metadata['height'] = new_height\n",
    "        if downsample_factor < 1.0:\n",
    "            old_transform = metadata['transform']\n",
    "            metadata['transform'] = Affine(\n",
    "                old_transform[0] / downsample_factor, old_transform[1], old_transform[2],\n",
    "                old_transform[3], old_transform[4] / downsample_factor, old_transform[5]\n",
    "            )\n",
    "        \n",
    "        # Save as JPEG (only if within PIL limits) or PNG\n",
    "        if new_width <= 65500 and new_height <= 65500:\n",
    "            img = Image.fromarray(img_array)\n",
    "            img.save(output_path, 'JPEG', quality=95)\n",
    "            print(f\"    ‚úì Saved JPEG: {output_path} ({new_width}x{new_height})\")\n",
    "        else:\n",
    "            # Save as PNG for very large images (PNG has no dimension limit)\n",
    "            print(f\"    ‚ö†Ô∏è  Image too large for JPEG (PIL limit: 65500), saving as PNG...\")\n",
    "            img = Image.fromarray(img_array)\n",
    "            output_path_png = output_path.with_suffix('.png')\n",
    "            img.save(output_path_png, 'PNG')\n",
    "            print(f\"    ‚úì Saved PNG: {output_path_png} ({new_width}x{new_height})\")\n",
    "            output_path = output_path_png\n",
    "        \n",
    "        return img_array, metadata\n",
    "\n",
    "# Convert basemap and reprojected orthos at different resolutions\n",
    "resolutions = {\n",
    "    'full': 1.0,\n",
    "    'half': 0.5,\n",
    "    'quarter': 0.25\n",
    "}\n",
    "\n",
    "converted_files = {}\n",
    "\n",
    "print(\"Converting files to JPEG at different resolutions...\")\n",
    "\n",
    "# Convert basemap at all resolutions\n",
    "for res_name, factor in resolutions.items():\n",
    "    basemap_jpeg = converted_dir / f\"basemap_{res_name}.jpg\"\n",
    "    if not basemap_jpeg.exists():\n",
    "        print(f\"\\nConverting basemap at {res_name} resolution...\")\n",
    "        basemap_img, basemap_meta = convert_geotiff_to_jpeg(basemap_path, basemap_jpeg, downsample_factor=factor)\n",
    "        if res_name not in converted_files:\n",
    "            converted_files[res_name] = {}\n",
    "        converted_files[res_name]['basemap'] = {'path': basemap_jpeg, 'img': basemap_img, 'meta': basemap_meta}\n",
    "    else:\n",
    "        # Check if PNG was saved instead (for very large images)\n",
    "        basemap_png = basemap_jpeg.with_suffix('.png')\n",
    "        if basemap_png.exists():\n",
    "            print(f\"\\nBasemap PNG ({res_name}) already exists: {basemap_png}\")\n",
    "            basemap_img = np.array(Image.open(basemap_png))\n",
    "            basemap_jpeg = basemap_png  # Update path\n",
    "        else:\n",
    "            print(f\"\\nBasemap JPEG ({res_name}) already exists: {basemap_jpeg}\")\n",
    "            basemap_img = np.array(Image.open(basemap_jpeg))\n",
    "        with rasterio.open(basemap_path) as src:\n",
    "            basemap_meta = {\n",
    "                'transform': src.transform,\n",
    "                'crs': src.crs,\n",
    "                'bounds': src.bounds,\n",
    "                'width': basemap_img.shape[1],\n",
    "                'height': basemap_img.shape[0]\n",
    "            }\n",
    "        if res_name not in converted_files:\n",
    "            converted_files[res_name] = {}\n",
    "        converted_files[res_name]['basemap'] = {'path': basemap_jpeg, 'img': basemap_img, 'meta': basemap_meta}\n",
    "\n",
    "# Convert reprojected orthos at all resolutions\n",
    "for ortho_name, reprojected_path in reprojected_paths.items():\n",
    "    for res_name, factor in resolutions.items():\n",
    "        ortho_jpeg = converted_dir / f\"{ortho_name}_{res_name}.jpg\"\n",
    "        if not ortho_jpeg.exists():\n",
    "            print(f\"\\nConverting {ortho_name} at {res_name} resolution...\")\n",
    "            ortho_img, ortho_meta = convert_geotiff_to_jpeg(reprojected_path, ortho_jpeg, downsample_factor=factor)\n",
    "            converted_files[res_name][ortho_name] = {'path': ortho_jpeg, 'img': ortho_img, 'meta': ortho_meta}\n",
    "        else:\n",
    "            # Check if PNG was saved instead (for very large images)\n",
    "            ortho_png = ortho_jpeg.with_suffix('.png')\n",
    "            if ortho_png.exists():\n",
    "                print(f\"\\n{ortho_name} PNG ({res_name}) already exists: {ortho_png}\")\n",
    "                ortho_img = np.array(Image.open(ortho_png))\n",
    "                ortho_jpeg = ortho_png  # Update path\n",
    "            else:\n",
    "                print(f\"\\n{ortho_name} JPEG ({res_name}) already exists: {ortho_jpeg}\")\n",
    "                ortho_img = np.array(Image.open(ortho_jpeg))\n",
    "            with rasterio.open(reprojected_path) as src:\n",
    "                ortho_meta = {\n",
    "                    'transform': src.transform,\n",
    "                    'crs': src.crs,\n",
    "                    'bounds': src.bounds,\n",
    "                    'width': ortho_img.shape[1],\n",
    "                    'height': ortho_img.shape[0]\n",
    "                }\n",
    "            if res_name not in converted_files:\n",
    "                converted_files[res_name] = {}\n",
    "            converted_files[res_name][ortho_name] = {'path': ortho_jpeg, 'img': ortho_img, 'meta': ortho_meta}\n",
    "\n",
    "print(f\"\\n‚úì Conversion complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_sift_matching(img1: np.ndarray, img2: np.ndarray, max_features: int = 5000) -> Dict:\n",
    "    \"\"\"\n",
    "    Perform SIFT feature matching between two images.\n",
    "    \n",
    "    Args:\n",
    "        img1: First image (numpy array)\n",
    "        img2: Second image (numpy array)\n",
    "        max_features: Maximum number of features to detect\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with matching results\n",
    "    \"\"\"\n",
    "    # Convert to grayscale if needed\n",
    "    if len(img1.shape) == 3:\n",
    "        gray1 = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray1 = img1\n",
    "    \n",
    "    if len(img2.shape) == 3:\n",
    "        gray2 = cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray2 = img2\n",
    "    \n",
    "    # Initialize SIFT detector\n",
    "    sift = cv2.SIFT_create(nfeatures=max_features, contrastThreshold=0.01, edgeThreshold=20)\n",
    "    \n",
    "    # Detect keypoints and descriptors\n",
    "    kp1, des1 = sift.detectAndCompute(gray1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(gray2, None)\n",
    "    \n",
    "    if des1 is None or des2 is None or len(des1) == 0 or len(des2) == 0:\n",
    "        return {\n",
    "            'num_keypoints1': len(kp1) if kp1 else 0,\n",
    "            'num_keypoints2': len(kp2) if kp2 else 0,\n",
    "            'num_matches': 0,\n",
    "            'good_matches': [],\n",
    "            'kp1': kp1,\n",
    "            'kp2': kp2,\n",
    "            'error': 'No descriptors found'\n",
    "        }\n",
    "    \n",
    "    # Match features using FLANN or BFMatcher\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "    search_params = dict(checks=50)\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    \n",
    "    matches = flann.knnMatch(des1, des2, k=2)\n",
    "    \n",
    "    # Apply Lowe's ratio test\n",
    "    good_matches = []\n",
    "    for match_pair in matches:\n",
    "        if len(match_pair) == 2:\n",
    "            m, n = match_pair\n",
    "            if m.distance < 0.75 * n.distance:  # Lowe's ratio test\n",
    "                good_matches.append(m)\n",
    "    \n",
    "    # Calculate offsets\n",
    "    offset_x = None\n",
    "    offset_y = None\n",
    "    rmse_2d = None\n",
    "    H = None\n",
    "    mask = None\n",
    "    \n",
    "    if len(good_matches) >= 4:\n",
    "        # Extract matched points\n",
    "        src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "        \n",
    "        # Find homography\n",
    "        H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "        \n",
    "        if H is not None:\n",
    "            # Calculate mean offset from homography\n",
    "            # Use center point as reference\n",
    "            h, w = gray1.shape\n",
    "            center = np.array([[[w/2, h/2]]], dtype=np.float32)\n",
    "            transformed_center = cv2.perspectiveTransform(center, H)\n",
    "            \n",
    "            offset_x = float(transformed_center[0][0][0] - center[0][0][0])\n",
    "            offset_y = float(transformed_center[0][0][1] - center[0][0][1])\n",
    "            \n",
    "            # Calculate RMSE from inliers\n",
    "            inlier_matches = [good_matches[i] for i in range(len(good_matches)) if mask[i]]\n",
    "            \n",
    "            if len(inlier_matches) > 0:\n",
    "                inlier_src = np.float32([kp1[m.queryIdx].pt for m in inlier_matches])\n",
    "                inlier_dst = np.float32([kp2[m.trainIdx].pt for m in inlier_matches])\n",
    "                \n",
    "                # Transform source points\n",
    "                inlier_src_transformed = cv2.perspectiveTransform(\n",
    "                    inlier_src.reshape(-1, 1, 2), H\n",
    "                ).reshape(-1, 2)\n",
    "                \n",
    "                # Calculate RMSE\n",
    "                errors = inlier_dst - inlier_src_transformed\n",
    "                rmse_2d = float(np.sqrt(np.mean(errors**2)))\n",
    "    \n",
    "    num_inliers = len([m for i, m in enumerate(good_matches) if mask is not None and mask[i]]) if mask is not None and len(good_matches) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'num_keypoints1': len(kp1),\n",
    "        'num_keypoints2': len(kp2),\n",
    "        'num_matches': len(good_matches),\n",
    "        'num_inliers': num_inliers,\n",
    "        'good_matches': good_matches,\n",
    "        'kp1': kp1,\n",
    "        'kp2': kp2,\n",
    "        'offset_x': offset_x,\n",
    "        'offset_y': offset_y,\n",
    "        'rmse_2d': rmse_2d,\n",
    "        'homography': H.tolist() if H is not None else None,\n",
    "        'confidence': len(good_matches) / max(len(kp1), len(kp2)) if len(kp1) > 0 and len(kp2) > 0 else 0.0\n",
    "    }\n",
    "\n",
    "# Perform matching at different resolutions\n",
    "# Use pre-saved JPEG files at each resolution\n",
    "resolutions = {\n",
    "    'full': 1.0,\n",
    "    'half': 0.5,\n",
    "    'quarter': 0.25\n",
    "}\n",
    "\n",
    "matching_results = {}\n",
    "\n",
    "for ortho_name in ['no_gcps', 'with_gcps']:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Matching {ortho_name} to basemap\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    matching_results[ortho_name] = {}\n",
    "    \n",
    "    for res_name, factor in resolutions.items():\n",
    "        print(f\"\\nüìä Resolution: {res_name} (factor: {factor})\")\n",
    "        \n",
    "        # Load pre-saved images at this resolution\n",
    "        basemap_img = converted_files[res_name]['basemap']['img']\n",
    "        ortho_img = converted_files[res_name][ortho_name]['img']\n",
    "        \n",
    "        print(f\"  Basemap: {basemap_img.shape[1]}x{basemap_img.shape[0]}\")\n",
    "        print(f\"  Ortho: {ortho_img.shape[1]}x{ortho_img.shape[0]}\")\n",
    "        \n",
    "        # Perform matching\n",
    "        result = perform_sift_matching(ortho_img, basemap_img)\n",
    "        \n",
    "        print(f\"  Keypoints (ortho): {result['num_keypoints1']}\")\n",
    "        print(f\"  Keypoints (basemap): {result['num_keypoints2']}\")\n",
    "        print(f\"  Matches: {result['num_matches']}\")\n",
    "        print(f\"  Inliers: {result['num_inliers']}\")\n",
    "        \n",
    "        if result['offset_x'] is not None:\n",
    "            print(f\"  Offset X: {result['offset_x']:.2f} px\")\n",
    "            print(f\"  Offset Y: {result['offset_y']:.2f} px\")\n",
    "            print(f\"  RMSE 2D: {result['rmse_2d']:.2f} px\")\n",
    "            print(f\"  Confidence: {result['confidence']:.3f}\")\n",
    "            \n",
    "            # Scale offsets back to full resolution\n",
    "            result['offset_x_full'] = result['offset_x'] / factor\n",
    "            result['offset_y_full'] = result['offset_y'] / factor\n",
    "            result['rmse_2d_full'] = result['rmse_2d'] / factor if result['rmse_2d'] else None\n",
    "        else:\n",
    "            print(f\"  ‚ö†Ô∏è  Matching failed: {result.get('error', 'Unknown error')}\")\n",
    "        \n",
    "        matching_results[ortho_name][res_name] = result\n",
    "        \n",
    "        # Save matching visualization\n",
    "        if result['num_matches'] > 0:\n",
    "            vis_path = matches_dir / f\"{ortho_name}_{res_name}_matches.jpg\"\n",
    "            \n",
    "            # Create visualization\n",
    "            img_matches = cv2.drawMatches(\n",
    "                ortho_img, result['kp1'],\n",
    "                basemap_img, result['kp2'],\n",
    "                result['good_matches'][:50],  # Show first 50 matches\n",
    "                None,\n",
    "                flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS\n",
    "            )\n",
    "            \n",
    "            cv2.imwrite(str(vis_path), img_matches)\n",
    "            print(f\"  ‚úì Saved visualization: {vis_path}\")\n",
    "\n",
    "print(f\"\\n‚úì Feature matching complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('SIFT Feature Matching Results at Different Resolutions', fontsize=16, fontweight='bold')\n",
    "\n",
    "for ortho_idx, ortho_name in enumerate(['no_gcps', 'with_gcps']):\n",
    "    for res_idx, (res_name, factor) in enumerate(resolutions.items()):\n",
    "        ax = axes[ortho_idx, res_idx]\n",
    "        \n",
    "        result = matching_results[ortho_name][res_name]\n",
    "        \n",
    "        if result['num_matches'] > 0 and result['offset_x'] is not None:\n",
    "            # Load visualization if it exists\n",
    "            vis_path = matches_dir / f\"{ortho_name}_{res_name}_matches.jpg\"\n",
    "            if vis_path.exists():\n",
    "                vis_img = plt.imread(vis_path)\n",
    "                ax.imshow(vis_img)\n",
    "                ax.axis('off')\n",
    "                \n",
    "                title = f\"{ortho_name.replace('_', ' ').title()} - {res_name.title()}\\n\"\n",
    "                title += f\"Matches: {result['num_matches']}, \"\n",
    "                title += f\"Offset: ({result['offset_x']:.1f}, {result['offset_y']:.1f}) px\"\n",
    "                ax.set_title(title, fontsize=10)\n",
    "            else:\n",
    "                ax.text(0.5, 0.5, f\"No visualization\\navailable\", \n",
    "                       ha='center', va='center', transform=ax.transAxes)\n",
    "                ax.set_title(f\"{ortho_name} - {res_name}\", fontsize=10)\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, f\"No matches found\\n{result.get('error', '')}\", \n",
    "                   ha='center', va='center', transform=ax.transAxes)\n",
    "            ax.set_title(f\"{ortho_name} - {res_name}\", fontsize=10)\n",
    "            ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "summary_vis_path = matches_dir / \"matching_summary.png\"\n",
    "plt.savefig(summary_vis_path, dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(f\"‚úì Summary visualization saved: {summary_vis_path}\")\n",
    "\n",
    "# Print summary table\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Matching Results Summary\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for ortho_name in ['no_gcps', 'with_gcps']:\n",
    "    print(f\"\\n{ortho_name.replace('_', ' ').title()}:\")\n",
    "    print(f\"  {'Resolution':<12} {'Matches':<10} {'Offset X':<12} {'Offset Y':<12} {'RMSE 2D':<12} {'Confidence':<10}\")\n",
    "    print(f\"  {'-'*12} {'-'*10} {'-'*12} {'-'*12} {'-'*12} {'-'*10}\")\n",
    "    \n",
    "    for res_name in ['full', 'half', 'quarter']:\n",
    "        result = matching_results[ortho_name][res_name]\n",
    "        matches = result['num_matches']\n",
    "        offset_x = f\"{result['offset_x']:.2f}\" if result['offset_x'] is not None else \"N/A\"\n",
    "        offset_y = f\"{result['offset_y']:.2f}\" if result['offset_y'] is not None else \"N/A\"\n",
    "        rmse = f\"{result['rmse_2d']:.2f}\" if result['rmse_2d'] is not None else \"N/A\"\n",
    "        conf = f\"{result['confidence']:.3f}\" if result['confidence'] else \"0.000\"\n",
    "        \n",
    "        print(f\"  {res_name:<12} {matches:<10} {offset_x:<12} {offset_y:<12} {rmse:<12} {conf:<10}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Apply 2D Shift and Register Orthomosaics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_2d_shift_to_image(img: np.ndarray, shift_x: float, shift_y: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply 2D shift to an image.\n",
    "    \n",
    "    Args:\n",
    "        img: Input image array\n",
    "        shift_x: Shift in X direction (pixels)\n",
    "        shift_y: Shift in Y direction (pixels)\n",
    "        \n",
    "    Returns:\n",
    "        Shifted image\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from scipy.ndimage import shift\n",
    "        use_scipy = True\n",
    "    except ImportError:\n",
    "        use_scipy = False\n",
    "    \n",
    "    if use_scipy:\n",
    "        if len(img.shape) == 3:\n",
    "            # RGB image\n",
    "            shifted = np.zeros_like(img)\n",
    "            for i in range(img.shape[2]):\n",
    "                shifted[:, :, i] = shift(img[:, :, i], (shift_y, shift_x), mode='constant', cval=0, order=1)\n",
    "        else:\n",
    "            # Grayscale\n",
    "            shifted = shift(img, (shift_y, shift_x), mode='constant', cval=0, order=1)\n",
    "    else:\n",
    "        # Fallback: integer shift using numpy\n",
    "        shift_x_int = int(round(shift_x))\n",
    "        shift_y_int = int(round(shift_y))\n",
    "        \n",
    "        if len(img.shape) == 3:\n",
    "            shifted = np.zeros_like(img)\n",
    "            h, w = img.shape[:2]\n",
    "            if shift_y_int >= 0 and shift_x_int >= 0:\n",
    "                shifted[shift_y_int:, shift_x_int:] = img[:h-shift_y_int, :w-shift_x_int]\n",
    "            elif shift_y_int < 0 and shift_x_int < 0:\n",
    "                shifted[:h+shift_y_int, :w+shift_x_int] = img[-shift_y_int:, -shift_x_int:]\n",
    "            else:\n",
    "                # Handle other cases\n",
    "                if shift_y_int >= 0:\n",
    "                    shifted[shift_y_int:, :] = img[:h-shift_y_int, :]\n",
    "                if shift_x_int >= 0:\n",
    "                    shifted[:, shift_x_int:] = img[:, :w-shift_x_int]\n",
    "        else:\n",
    "            shifted = np.zeros_like(img)\n",
    "            h, w = img.shape\n",
    "            if shift_y_int >= 0 and shift_x_int >= 0:\n",
    "                shifted[shift_y_int:, shift_x_int:] = img[:h-shift_y_int, :w-shift_x_int]\n",
    "            elif shift_y_int < 0 and shift_x_int < 0:\n",
    "                shifted[:h+shift_y_int, :w+shift_x_int] = img[-shift_y_int:, -shift_x_int:]\n",
    "    \n",
    "    return shifted\n",
    "\n",
    "# Choose best resolution for registration (prefer full res if available, otherwise use best match count)\n",
    "registered_orthos = {}\n",
    "\n",
    "for ortho_name in ['no_gcps', 'with_gcps']:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Registering {ortho_name}...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Find best resolution (prefer full, then highest match count)\n",
    "    best_res = None\n",
    "    best_matches = 0\n",
    "    \n",
    "    for res_name in ['full', 'half', 'quarter']:\n",
    "        result = matching_results[ortho_name][res_name]\n",
    "        if result['num_matches'] > best_matches and result['offset_x'] is not None:\n",
    "            best_matches = result['num_matches']\n",
    "            best_res = res_name\n",
    "    \n",
    "    if best_res is None:\n",
    "        print(f\"  ‚ö†Ô∏è  No valid matches found for {ortho_name}\")\n",
    "        continue\n",
    "    \n",
    "    result = matching_results[ortho_name][best_res]\n",
    "    print(f\"  Using {best_res} resolution results (matches: {result['num_matches']})\")\n",
    "    \n",
    "    # Get full resolution offset\n",
    "    shift_x = result['offset_x_full']\n",
    "    shift_y = result['offset_y_full']\n",
    "    \n",
    "    print(f\"  Applying shift: X={shift_x:.2f} px, Y={shift_y:.2f} px\")\n",
    "    \n",
    "    # Load full resolution image\n",
    "    ortho_img = converted_files['full'][ortho_name]['img']\n",
    "    \n",
    "    # Apply shift\n",
    "    shifted_img = apply_2d_shift_to_image(ortho_img, shift_x, shift_y)\n",
    "    \n",
    "    # Save registered image\n",
    "    registered_path = registered_dir / f\"{ortho_name}_registered.jpg\"\n",
    "    \n",
    "    if len(shifted_img.shape) == 3:\n",
    "        img_pil = Image.fromarray(shifted_img)\n",
    "    else:\n",
    "        img_pil = Image.fromarray(shifted_img).convert('RGB')\n",
    "    \n",
    "    img_pil.save(registered_path, 'JPEG', quality=95)\n",
    "    print(f\"  ‚úì Saved registered image: {registered_path}\")\n",
    "    \n",
    "    registered_orthos[ortho_name] = {\n",
    "        'path': registered_path,\n",
    "        'img': shifted_img,\n",
    "        'shift_x': shift_x,\n",
    "        'shift_y': shift_y,\n",
    "        'resolution_used': best_res\n",
    "    }\n",
    "\n",
    "print(f\"\\n‚úì Registration complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Create Final Visualizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create side-by-side comparison: original vs registered\n",
    "for ortho_name in ['no_gcps', 'with_gcps']:\n",
    "    if ortho_name not in registered_orthos:\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nCreating visualization for {ortho_name}...\")\n",
    "    \n",
    "    # Load images (use full resolution)\n",
    "    original_img = converted_files['full'][ortho_name]['img']\n",
    "    registered_img = registered_orthos[ortho_name]['img']\n",
    "    basemap_img = converted_files['full']['basemap']['img']\n",
    "    \n",
    "    # Resize to same size for comparison (use smallest)\n",
    "    min_h = min(original_img.shape[0], registered_img.shape[0], basemap_img.shape[0])\n",
    "    min_w = min(original_img.shape[1], registered_img.shape[1], basemap_img.shape[1])\n",
    "    \n",
    "    original_resized = cv2.resize(original_img, (min_w, min_h))\n",
    "    registered_resized = cv2.resize(registered_img, (min_w, min_h))\n",
    "    basemap_resized = cv2.resize(basemap_img, (min_w, min_h))\n",
    "    \n",
    "    # Create comparison figure\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 16))\n",
    "    fig.suptitle(f'Registration Results: {ortho_name.replace(\"_\", \" \").title()}', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Basemap (ground truth)\n",
    "    axes[0, 0].imshow(basemap_resized)\n",
    "    axes[0, 0].set_title('Ground Truth Basemap', fontweight='bold')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # Original ortho\n",
    "    axes[0, 1].imshow(original_resized)\n",
    "    axes[0, 1].set_title('Original Orthomosaic', fontweight='bold')\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    # Registered ortho\n",
    "    axes[1, 0].imshow(registered_resized)\n",
    "    shift_info = registered_orthos[ortho_name]\n",
    "    title = f\"Registered Orthomosaic\\n\"\n",
    "    title += f\"Shift: ({shift_info['shift_x']:.2f}, {shift_info['shift_y']:.2f}) px\\n\"\n",
    "    title += f\"Resolution: {shift_info['resolution_used']}\"\n",
    "    axes[1, 0].set_title(title, fontweight='bold')\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    # Difference map\n",
    "    diff = np.abs(registered_resized.astype(float) - basemap_resized.astype(float))\n",
    "    diff_norm = (diff / diff.max() * 255).astype(np.uint8) if diff.max() > 0 else diff.astype(np.uint8)\n",
    "    axes[1, 1].imshow(diff_norm, cmap='hot')\n",
    "    axes[1, 1].set_title('Difference Map (Registered vs Basemap)', fontweight='bold')\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    comparison_path = registered_dir / f\"{ortho_name}_comparison.png\"\n",
    "    plt.savefig(comparison_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"  ‚úì Saved comparison: {comparison_path}\")\n",
    "\n",
    "# Save matching results to JSON\n",
    "results_json_path = matching_output_dir / \"matching_results.json\"\n",
    "\n",
    "def convert_to_native(obj):\n",
    "    \"\"\"Convert numpy types to native Python types for JSON.\"\"\"\n",
    "    if isinstance(obj, np.integer):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, np.floating):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: convert_to_native(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_native(item) for item in obj]\n",
    "    elif hasattr(obj, '__dict__'):\n",
    "        # Handle OpenCV keypoints (skip them for JSON)\n",
    "        return None\n",
    "    return obj\n",
    "\n",
    "# Clean results for JSON (remove OpenCV objects)\n",
    "json_results = {}\n",
    "for ortho_name in matching_results:\n",
    "    json_results[ortho_name] = {}\n",
    "    for res_name in matching_results[ortho_name]:\n",
    "        result = matching_results[ortho_name][res_name].copy()\n",
    "        # Remove OpenCV objects\n",
    "        result.pop('kp1', None)\n",
    "        result.pop('kp2', None)\n",
    "        result.pop('good_matches', None)\n",
    "        json_results[ortho_name][res_name] = convert_to_native(result)\n",
    "\n",
    "with open(results_json_path, 'w') as f:\n",
    "    json.dump(json_results, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úì Results saved to: {results_json_path}\")\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"‚úì Feature Matching and Registration Complete!\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
