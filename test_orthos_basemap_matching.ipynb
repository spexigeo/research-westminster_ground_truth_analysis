{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orthomosaic-Basemap Feature Matching and Registration\n",
    "\n",
    "This notebook performs feature matching between orthomosaics (with/without GCPs) and a ground control basemap using SIFT and evaluates 2D shifting and registration.\n",
    "\n",
    "## Goals:\n",
    "1. **Feature Matching**: Use SIFT to find corresponding features between orthos and basemap\n",
    "2. **Multi-Resolution Analysis**: Evaluate matching at full, half, and quarter resolution\n",
    "3. **2D Registration**: Apply computed shifts to register orthos to basemap\n",
    "4. **Visualization**: Create visualizations of matches and registered orthos\n",
    "\n",
    "## Inputs:\n",
    "- **Ground Control Basemap**: `TestsiteNewWest_Spexigeo_RTK.tiff`\n",
    "- **Orthomosaic (No GCPs)**: `outputs/orthomosaics/orthomosaic_no_gcps.tif`\n",
    "- **Orthomosaic (With GCPs)**: `outputs/orthomosaics/orthomosaic_with_gcps.tif`\n",
    "\n",
    "## Outputs:\n",
    "- All outputs saved to `outputs/test_matching/`\n",
    "- Match visualizations at different resolutions\n",
    "- Registered orthomosaics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Install Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 Dependencies installed\n"
     ]
    }
   ],
   "source": [
    "# Install required packages if needed\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "packages = ['opencv-python', 'scikit-image', 'rasterio', 'numpy', 'matplotlib', 'pillow', 'scipy']\n",
    "for package in packages:\n",
    "    try:\n",
    "        if package == 'opencv-python':\n",
    "            __import__('cv2')\n",
    "        elif package == 'scikit-image':\n",
    "            __import__('skimage')\n",
    "        elif package == 'pillow':\n",
    "            __import__('PIL')\n",
    "        else:\n",
    "            __import__(package)\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "print(\"\u2713 Dependencies installed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 Imports successful!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling, transform_bounds\n",
    "from rasterio import Affine\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import warnings\n",
    "import json\n",
    "from typing import Dict, Tuple, Optional, List\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"\u2713 Imports successful!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup Paths and Output Directories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 Output directory: outputs/test_matching\n",
      "  - Reprojected: outputs/test_matching/reprojected\n",
      "  - Converted: outputs/test_matching/converted\n",
      "  - Matches: outputs/test_matching/matches\n",
      "  - Registered: outputs/test_matching/registered\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "data_dir = Path(\"/Users/mauriciohessflores/Documents/Code/Data/New Westminster Oct _25\")\n",
    "output_dir = Path(\"outputs\")\n",
    "\n",
    "# Input files\n",
    "basemap_path = data_dir / \"Michael_RTK_orthos\" / \"TestsiteNewWest_Spexigeo_RTK.tiff\"\n",
    "ortho_no_gcps_path = output_dir / \"orthomosaics\" / \"orthomosaic_no_gcps.tif\"\n",
    "ortho_with_gcps_path = output_dir / \"orthomosaics\" / \"orthomosaic_with_gcps.tif\"\n",
    "\n",
    "# Output directory structure\n",
    "matching_output_dir = output_dir / \"test_matching\"\n",
    "matching_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Subdirectories\n",
    "reprojected_dir = matching_output_dir / \"reprojected\"\n",
    "reprojected_dir.mkdir(exist_ok=True)\n",
    "\n",
    "converted_dir = matching_output_dir / \"converted\"\n",
    "converted_dir.mkdir(exist_ok=True)\n",
    "\n",
    "matches_dir = matching_output_dir / \"matches\"\n",
    "matches_dir.mkdir(exist_ok=True)\n",
    "\n",
    "registered_dir = matching_output_dir / \"registered\"\n",
    "registered_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"\u2713 Output directory: {matching_output_dir}\")\n",
    "print(f\"  - Reprojected: {reprojected_dir}\")\n",
    "print(f\"  - Converted: {converted_dir}\")\n",
    "print(f\"  - Matches: {matches_dir}\")\n",
    "print(f\"  - Registered: {registered_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load and Check Input Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 All input files found\n",
      "\n",
      "\ud83d\udcca File Information:\n",
      "\n",
      "Basemap:\n",
      "  Path: /Users/mauriciohessflores/Documents/Code/Data/New Westminster Oct _25/Michael_RTK_orthos/TestsiteNewWest_Spexigeo_RTK.tiff\n",
      "  Size: 19804.91 MB\n",
      "  CRS: EPSG:32610\n",
      "  Dimensions: 90129 x 90188\n",
      "  Bands: 4\n",
      "  Bounds: BoundingBox(left=506424.37839793676, bottom=5450017.622213458, right=507501.0951215451, top=5451095.043774429)\n",
      "  Pixel size: 0.0119 m (X), 0.0119 m (Y)\n",
      "\n",
      "Ortho (No GCPs):\n",
      "  Path: outputs/orthomosaics/orthomosaic_no_gcps.tif\n",
      "  Size: 3887.28 MB\n",
      "  CRS: EPSG:4326\n",
      "  Dimensions: 38531 x 39277\n",
      "  Bands: 4\n",
      "  Bounds: BoundingBox(left=-122.91170031378732, bottom=49.20303508811748, right=-122.89720111440005, top=49.212718829461046)\n",
      "  Pixel size: 0.0000 m (X), 0.0000 m (Y)\n",
      "\n",
      "Ortho (With GCPs):\n",
      "  Path: outputs/orthomosaics/orthomosaic_with_gcps.tif\n",
      "  Size: 3867.91 MB\n",
      "  CRS: EPSG:4326\n",
      "  Dimensions: 38538 x 39233\n",
      "  Bands: 4\n",
      "  Bounds: BoundingBox(left=-122.9117167927641, bottom=49.203044960109175, right=-122.89720605758104, top=49.21272378933356)\n",
      "  Pixel size: 0.0000 m (X), 0.0000 m (Y)\n"
     ]
    }
   ],
   "source": [
    "# Check if files exist\n",
    "if not basemap_path.exists():\n",
    "    raise FileNotFoundError(f\"Basemap not found: {basemap_path}\")\n",
    "if not ortho_no_gcps_path.exists():\n",
    "    raise FileNotFoundError(f\"Orthomosaic (no GCPs) not found: {ortho_no_gcps_path}\")\n",
    "if not ortho_with_gcps_path.exists():\n",
    "    raise FileNotFoundError(f\"Orthomosaic (with GCPs) not found: {ortho_with_gcps_path}\")\n",
    "\n",
    "print(\"\u2713 All input files found\")\n",
    "\n",
    "# Get basic info about each file\n",
    "print(\"\\n\ud83d\udcca File Information:\")\n",
    "for name, path in [(\"Basemap\", basemap_path), (\"Ortho (No GCPs)\", ortho_no_gcps_path), (\"Ortho (With GCPs)\", ortho_with_gcps_path)]:\n",
    "    with rasterio.open(path) as src:\n",
    "        file_size_mb = path.stat().st_size / (1024 * 1024)\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"  Path: {path}\")\n",
    "        print(f\"  Size: {file_size_mb:.2f} MB\")\n",
    "        print(f\"  CRS: {src.crs}\")\n",
    "        print(f\"  Dimensions: {src.width} x {src.height}\")\n",
    "        print(f\"  Bands: {src.count}\")\n",
    "        print(f\"  Bounds: {src.bounds}\")\n",
    "        if src.crs:\n",
    "            pixel_size_x = abs(src.transform[0])\n",
    "            pixel_size_y = abs(src.transform[4])\n",
    "            print(f\"  Pixel size: {pixel_size_x:.4f} m (X), {pixel_size_y:.4f} m (Y)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Reproject Orthomosaics to Match Basemap CRS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target CRS: EPSG:32610\n",
      "Target bounds: BoundingBox(left=506424.37839793676, bottom=5450017.622213458, right=507501.0951215451, top=5451095.043774429)\n",
      "Target dimensions: 90129 x 90188\n",
      "\n",
      "============================================================\n",
      "Reprojecting no_gcps...\n",
      "  \u2713 Already reprojected: outputs/test_matching/reprojected/no_gcps_reprojected.tif\n",
      "\n",
      "============================================================\n",
      "Reprojecting with_gcps...\n",
      "  Source CRS: EPSG:4326\n",
      "  Source bounds: BoundingBox(left=-122.9117167927641, bottom=49.203044960109175, right=-122.89720605758104, top=49.21272378933356)\n",
      "  Transforming source bounds to target CRS...\n",
      "  Source bounds in target CRS: (506429.71224202216, 5450031.47560229, 507487.9980312089, 5451108.798120763)\n",
      "  Output bounds (intersection): left=506429.71, bottom=5450031.48, right=507488.00, top=5451095.04\n",
      "  \u2713 Transform calculated: 88586x89028 pixels\n",
      "  Reprojecting to 88586x89028...\n",
      "  \u2713 Saved: outputs/test_matching/reprojected/with_gcps_reprojected.tif\n",
      "\n",
      "\u2713 Reprojection complete!\n"
     ]
    }
   ],
   "source": [
    "# Get basemap CRS (target CRS)\n",
    "with rasterio.open(basemap_path) as basemap_src:\n",
    "    target_crs = basemap_src.crs\n",
    "    target_bounds = basemap_src.bounds\n",
    "    target_transform = basemap_src.transform\n",
    "    target_width = basemap_src.width\n",
    "    target_height = basemap_src.height\n",
    "\n",
    "print(f\"Target CRS: {target_crs}\")\n",
    "print(f\"Target bounds: {target_bounds}\")\n",
    "print(f\"Target dimensions: {target_width} x {target_height}\")\n",
    "\n",
    "# Reproject each orthomosaic\n",
    "ortho_paths = {\n",
    "    'no_gcps': ortho_no_gcps_path,\n",
    "    'with_gcps': ortho_with_gcps_path\n",
    "}\n",
    "\n",
    "reprojected_paths = {}\n",
    "\n",
    "for ortho_name, ortho_path in ortho_paths.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Reprojecting {ortho_name}...\")\n",
    "    \n",
    "    reprojected_path = reprojected_dir / f\"{ortho_name}_reprojected.tif\"\n",
    "    \n",
    "    # Check if already reprojected\n",
    "    if reprojected_path.exists():\n",
    "        print(f\"  \u2713 Already reprojected: {reprojected_path}\")\n",
    "        reprojected_paths[ortho_name] = reprojected_path\n",
    "        continue\n",
    "    \n",
    "    with rasterio.open(ortho_path) as ortho_src:\n",
    "        source_crs = ortho_src.crs\n",
    "        source_bounds = ortho_src.bounds\n",
    "        \n",
    "        print(f\"  Source CRS: {source_crs}\")\n",
    "        print(f\"  Source bounds: {source_bounds}\")\n",
    "        \n",
    "        # Check if reprojection is needed\n",
    "        if source_crs == target_crs:\n",
    "            print(f\"  \u2713 Already in target CRS, copying...\")\n",
    "            import shutil\n",
    "            shutil.copy(ortho_path, reprojected_path)\n",
    "            reprojected_paths[ortho_name] = reprojected_path\n",
    "            continue\n",
    "        \n",
    "        # Calculate transform using source bounds (not target bounds)\n",
    "        # First, transform source bounds to target CRS to get output extent\n",
    "        try:\n",
    "            print(f\"  Transforming source bounds to target CRS...\")\n",
    "            src_bounds_target_crs = transform_bounds(\n",
    "                source_crs, target_crs,\n",
    "                source_bounds.left, source_bounds.bottom,\n",
    "                source_bounds.right, source_bounds.top\n",
    "            )\n",
    "            \n",
    "            print(f\"  Source bounds in target CRS: {src_bounds_target_crs}\")\n",
    "            \n",
    "            # Get target pixel size\n",
    "            target_pixel_size_x = abs(target_transform[0])\n",
    "            target_pixel_size_y = abs(target_transform[4])\n",
    "            \n",
    "            # Use intersection of bounds (where both images overlap)\n",
    "            output_left = max(src_bounds_target_crs[0], target_bounds.left)\n",
    "            output_bottom = max(src_bounds_target_crs[1], target_bounds.bottom)\n",
    "            output_right = min(src_bounds_target_crs[2], target_bounds.right)\n",
    "            output_top = min(src_bounds_target_crs[3], target_bounds.top)\n",
    "            \n",
    "            print(f\"  Output bounds (intersection): left={output_left:.2f}, bottom={output_bottom:.2f}, right={output_right:.2f}, top={output_top:.2f}\")\n",
    "            \n",
    "            # Validate bounds\n",
    "            if output_right <= output_left or output_top <= output_bottom:\n",
    "                raise ValueError(f\"Invalid output bounds: width={output_right-output_left}, height={output_top-output_bottom}\")\n",
    "            \n",
    "            # Calculate dimensions using target pixel size\n",
    "            width = int((output_right - output_left) / target_pixel_size_x)\n",
    "            height = int((output_top - output_bottom) / target_pixel_size_y)\n",
    "            \n",
    "            # Validate dimensions\n",
    "            if width <= 0 or height <= 0:\n",
    "                raise ValueError(f\"Invalid dimensions: width={width}, height={height}\")\n",
    "            \n",
    "            # Create transform for output\n",
    "            transform = Affine.translation(output_left, output_top) * Affine.scale(target_pixel_size_x, -target_pixel_size_y)\n",
    "            \n",
    "            print(f\"  \u2713 Transform calculated: {width}x{height} pixels\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  \u274c Transform calculation failed: {e}\")\n",
    "            print(f\"  Trying alternative approach using source resolution...\")\n",
    "            \n",
    "            # Alternative: use source resolution and calculate output bounds\n",
    "            try:\n",
    "                # Get source pixel size\n",
    "                source_pixel_size_x = abs(ortho_src.transform[0])\n",
    "                source_pixel_size_y = abs(ortho_src.transform[4])\n",
    "                \n",
    "                # Transform source bounds to target CRS\n",
    "                src_bounds_target_crs = transform_bounds(\n",
    "                    source_crs, target_crs,\n",
    "                    source_bounds.left, source_bounds.bottom,\n",
    "                    source_bounds.right, source_bounds.top\n",
    "                )\n",
    "                \n",
    "                # Use source pixel size (approximate)\n",
    "                output_left = src_bounds_target_crs[0]\n",
    "                output_bottom = src_bounds_target_crs[1]\n",
    "                output_right = src_bounds_target_crs[2]\n",
    "                output_top = src_bounds_target_crs[3]\n",
    "                \n",
    "                # Calculate dimensions\n",
    "                width = int((output_right - output_left) / source_pixel_size_x)\n",
    "                height = int((output_top - output_bottom) / source_pixel_size_y)\n",
    "                \n",
    "                transform = Affine.translation(output_left, output_top) * Affine.scale(source_pixel_size_x, -source_pixel_size_y)\n",
    "                \n",
    "                print(f\"  \u2713 Using source resolution approach: {width}x{height} pixels\")\n",
    "                \n",
    "            except Exception as e2:\n",
    "                print(f\"  \u274c Alternative approach also failed: {e2}\")\n",
    "                print(f\"  Skipping {ortho_name}...\")\n",
    "                continue\n",
    "        \n",
    "        # Reproject\n",
    "        print(f\"  Reprojecting to {width}x{height}...\")\n",
    "        \n",
    "        # Read source data\n",
    "        source_data = ortho_src.read()\n",
    "        source_count = ortho_src.count\n",
    "        \n",
    "        # Reproject each band\n",
    "        reprojected_data = np.zeros((source_count, height, width), dtype=source_data.dtype)\n",
    "        \n",
    "        for band_idx in range(1, source_count + 1):\n",
    "            reproject(\n",
    "                source=rasterio.band(ortho_src, band_idx),\n",
    "                destination=reprojected_data[band_idx - 1],\n",
    "                src_transform=ortho_src.transform,\n",
    "                src_crs=source_crs,\n",
    "                dst_transform=transform,\n",
    "                dst_crs=target_crs,\n",
    "                resampling=Resampling.bilinear\n",
    "            )\n",
    "        \n",
    "        # Save reprojected file with LZW compression\n",
    "        # Also save as JPEG directly to avoid large intermediate files\n",
    "        jpeg_path = reprojected_dir / f\"{ortho_name}_reprojected.jpg\"\n",
    "        \n",
    "        # Save GeoTIFF with compression\n",
    "        with rasterio.open(\n",
    "            reprojected_path,\n",
    "            'w',\n",
    "            driver='GTiff',\n",
    "            height=height,\n",
    "            width=width,\n",
    "            count=source_count,\n",
    "            dtype=reprojected_data.dtype,\n",
    "            crs=target_crs,\n",
    "            transform=transform,\n",
    "            compress='lzw',\n",
    "            BIGTIFF='YES',\n",
    "            tiled=True,\n",
    "            blockxsize=512,\n",
    "            blockysize=512,\n",
    "            predictor=2  # Horizontal differencing for better compression\n",
    "        ) as dst:\n",
    "            dst.write(reprojected_data)\n",
    "        \n",
    "        # Also save as JPEG for faster processing (normalize first)\n",
    "        if source_count >= 3:\n",
    "            jpeg_data = reprojected_data[:3]  # RGB\n",
    "        else:\n",
    "            jpeg_data = np.stack([reprojected_data[0]] * 3)  # Grayscale to RGB\n",
    "        \n",
    "        # Normalize to 0-255\n",
    "        if jpeg_data.dtype != np.uint8:\n",
    "            jpeg_data_min = jpeg_data.min(axis=(1, 2), keepdims=True)\n",
    "            jpeg_data_max = jpeg_data.max(axis=(1, 2), keepdims=True)\n",
    "            jpeg_data_range = jpeg_data_max - jpeg_data_min\n",
    "            jpeg_data_range[jpeg_data_range == 0] = 1\n",
    "            jpeg_data = ((jpeg_data - jpeg_data_min) / jpeg_data_range * 255).astype(np.uint8)\n",
    "        \n",
    "        # Convert to (H, W, C) format\n",
    "        jpeg_array = jpeg_data.transpose(1, 2, 0)\n",
    "        jpeg_img = Image.fromarray(jpeg_array)\n",
    "        jpeg_img.save(jpeg_path, 'JPEG', quality=95)\n",
    "        print(f\"  \u2713 Also saved JPEG: {jpeg_path}\")\n",
    "        \n",
    "        print(f\"  \u2713 Saved: {reprojected_path}\")\n",
    "        reprojected_paths[ortho_name] = reprojected_path\n",
    "\n",
    "print(f\"\\n\u2713 Reprojection complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting files to JPEG...\n",
      "\n",
      "Converting basemap...\n",
      "    Downsampling from 90129x90188 to 9993x10000\n",
      "    \u2713 Saved JPEG: outputs/test_matching/converted/basemap.jpg (9993x10000)\n",
      "\n",
      "Converting no_gcps...\n",
      "    Downsampling from 88515x89120 to 9932x10000\n",
      "    \u2713 Saved JPEG: outputs/test_matching/converted/no_gcps.jpg (9932x10000)\n",
      "\n",
      "Converting with_gcps...\n",
      "    Downsampling from 88586x89028 to 9950x10000\n",
      "    \u2713 Saved JPEG: outputs/test_matching/converted/with_gcps.jpg (9950x10000)\n",
      "\n",
      "\u2713 Conversion complete!\n"
     ]
    }
   ],
   "source": [
    "def convert_geotiff_to_jpeg(geotiff_path: Path, output_path: Path, downsample_factor: float = 1.0) -> Tuple[np.ndarray, Dict]:\n",
    "    \"\"\"\n",
    "    Convert GeoTIFF to JPEG format at specified resolution.\n",
    "    \n",
    "    Args:\n",
    "        geotiff_path: Path to input GeoTIFF\n",
    "        output_path: Path to save JPEG\n",
    "        downsample_factor: Factor to downsample (1.0 = full res, 0.5 = half, 0.25 = quarter)\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (image array, metadata dict with transform info)\n",
    "    \"\"\"\n",
    "    with rasterio.open(geotiff_path) as src:\n",
    "        # Read first 3 bands (RGB) or convert to grayscale\n",
    "        if src.count >= 3:\n",
    "            data = src.read([1, 2, 3])\n",
    "        else:\n",
    "            data = src.read(1)\n",
    "            data = np.stack([data, data, data])\n",
    "        \n",
    "        # Get metadata\n",
    "        metadata = {\n",
    "            'transform': src.transform,\n",
    "            'crs': src.crs,\n",
    "            'bounds': src.bounds,\n",
    "            'width': src.width,\n",
    "            'height': src.height\n",
    "        }\n",
    "        \n",
    "        # Normalize to 0-255\n",
    "        if data.dtype != np.uint8:\n",
    "            data_min = data.min(axis=(1, 2), keepdims=True)\n",
    "            data_max = data.max(axis=(1, 2), keepdims=True)\n",
    "            data_range = data_max - data_min\n",
    "            data_range[data_range == 0] = 1  # Avoid division by zero\n",
    "            data = ((data - data_min) / data_range * 255).astype(np.uint8)\n",
    "        \n",
    "        # Downsample if needed\n",
    "        height, width = data.shape[1], data.shape[2]\n",
    "        \n",
    "        if downsample_factor < 1.0:\n",
    "            new_height = int(height * downsample_factor)\n",
    "            new_width = int(width * downsample_factor)\n",
    "            \n",
    "            print(f\"    Downsampling from {width}x{height} to {new_width}x{new_height} (factor: {downsample_factor})\")\n",
    "            \n",
    "            # Use cv2 for resizing\n",
    "            if len(data.shape) == 3:\n",
    "                # RGB\n",
    "                data_resized = np.zeros((3, new_height, new_width), dtype=np.uint8)\n",
    "                for i in range(3):\n",
    "                    data_resized[i] = cv2.resize(data[i], (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "                data = data_resized\n",
    "            else:\n",
    "                data = cv2.resize(data, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "            \n",
    "            # Update metadata\n",
    "            metadata['width'] = new_width\n",
    "            metadata['height'] = new_height\n",
    "            # Adjust transform\n",
    "            old_transform = metadata['transform']\n",
    "            metadata['transform'] = Affine(\n",
    "                old_transform[0] / downsample_factor, old_transform[1], old_transform[2],\n",
    "                old_transform[3], old_transform[4] / downsample_factor, old_transform[5]\n",
    "            )\n",
    "        \n",
    "        # Convert to PIL Image format (H, W, C)\n",
    "        if len(data.shape) == 3:\n",
    "            img_array = data.transpose(1, 2, 0)\n",
    "        else:\n",
    "            img_array = data\n",
    "        \n",
    "        # Save as JPEG\n",
    "        img = Image.fromarray(img_array)\n",
    "        img.save(output_path, 'JPEG', quality=95)\n",
    "        \n",
    "        print(f\"    \u2713 Saved JPEG: {output_path} ({img_array.shape[1]}x{img_array.shape[0]})\")\n",
    "        \n",
    "        return img_array, metadata\n",
    "\n",
    "# Convert basemap and reprojected orthos at different resolutions\n",
    "resolutions = {\n",
    "    'full': 1.0,\n",
    "    'half': 0.5,\n",
    "    'quarter': 0.25\n",
    "}\n",
    "\n",
    "converted_files = {}\n",
    "\n",
    "print(\"Converting files to JPEG at different resolutions...\")\n",
    "\n",
    "# Convert basemap at all resolutions\n",
    "for res_name, factor in resolutions.items():\n",
    "    basemap_jpeg = converted_dir / f\"basemap_{res_name}.jpg\"\n",
    "    if not basemap_jpeg.exists():\n",
    "        print(f\"\\nConverting basemap at {res_name} resolution...\")\n",
    "        basemap_img, basemap_meta = convert_geotiff_to_jpeg(basemap_path, basemap_jpeg, downsample_factor=factor)\n",
    "        if res_name not in converted_files:\n",
    "            converted_files[res_name] = {}\n",
    "        converted_files[res_name]['basemap'] = {'path': basemap_jpeg, 'img': basemap_img, 'meta': basemap_meta}\n",
    "    else:\n",
    "        print(f\"\\nBasemap JPEG ({res_name}) already exists: {basemap_jpeg}\")\n",
    "        basemap_img = np.array(Image.open(basemap_jpeg))\n",
    "        with rasterio.open(basemap_path) as src:\n",
    "            basemap_meta = {\n",
    "                'transform': src.transform,\n",
    "                'crs': src.crs,\n",
    "                'bounds': src.bounds,\n",
    "                'width': basemap_img.shape[1],\n",
    "                'height': basemap_img.shape[0]\n",
    "            }\n",
    "        if res_name not in converted_files:\n",
    "            converted_files[res_name] = {}\n",
    "        converted_files[res_name]['basemap'] = {'path': basemap_jpeg, 'img': basemap_img, 'meta': basemap_meta}\n",
    "\n",
    "# Convert reprojected orthos at all resolutions\n",
    "for ortho_name, reprojected_path in reprojected_paths.items():\n",
    "    for res_name, factor in resolutions.items():\n",
    "        ortho_jpeg = converted_dir / f\"{ortho_name}_{res_name}.jpg\"\n",
    "        if not ortho_jpeg.exists():\n",
    "            print(f\"\\nConverting {ortho_name} at {res_name} resolution...\")\n",
    "            ortho_img, ortho_meta = convert_geotiff_to_jpeg(reprojected_path, ortho_jpeg, downsample_factor=factor)\n",
    "            converted_files[res_name][ortho_name] = {'path': ortho_jpeg, 'img': ortho_img, 'meta': ortho_meta}\n",
    "        else:\n",
    "            print(f\"\\n{ortho_name} JPEG ({res_name}) already exists: {ortho_jpeg}\")\n",
    "            ortho_img = np.array(Image.open(ortho_jpeg))\n",
    "            with rasterio.open(reprojected_path) as src:\n",
    "                ortho_meta = {\n",
    "                    'transform': src.transform,\n",
    "                    'crs': src.crs,\n",
    "                    'bounds': src.bounds,\n",
    "                    'width': ortho_img.shape[1],\n",
    "                    'height': ortho_img.shape[0]\n",
    "                }\n",
    "            if res_name not in converted_files:\n",
    "                converted_files[res_name] = {}\n",
    "            converted_files[res_name][ortho_name] = {'path': ortho_jpeg, 'img': ortho_img, 'meta': ortho_meta}\n",
    "\n",
    "print(f\"\\n\u2713 Conversion complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Matching no_gcps to basemap\n",
      "============================================================\n",
      "\n",
      "\ud83d\udcca Resolution: full (factor: 1.0)\n",
      "  Basemap: 9993x10000\n",
      "  Ortho: 9932x10000\n",
      "  Keypoints (ortho): 5000\n",
      "  Keypoints (basemap): 5001\n",
      "  Matches: 118\n",
      "  Inliers: 20\n",
      "  Offset X: 22.19 px\n",
      "  Offset Y: -51.32 px\n",
      "  RMSE 2D: 1.55 px\n",
      "  Confidence: 0.024\n",
      "  \u2713 Saved visualization: outputs/test_matching/matches/no_gcps_full_matches.jpg\n",
      "\n",
      "\ud83d\udcca Resolution: half (factor: 0.5)\n",
      "  Basemap: 4996x5000\n",
      "  Ortho: 4966x5000\n",
      "  Keypoints (ortho): 5000\n",
      "  Keypoints (basemap): 5000\n",
      "  Matches: 110\n",
      "  Inliers: 25\n",
      "  Offset X: 11.09 px\n",
      "  Offset Y: -26.38 px\n",
      "  RMSE 2D: 0.68 px\n",
      "  Confidence: 0.022\n",
      "  \u2713 Saved visualization: outputs/test_matching/matches/no_gcps_half_matches.jpg\n",
      "\n",
      "\ud83d\udcca Resolution: quarter (factor: 0.25)\n",
      "  Basemap: 2498x2500\n",
      "  Ortho: 2483x2500\n",
      "  Keypoints (ortho): 5001\n",
      "  Keypoints (basemap): 5000\n",
      "  Matches: 92\n",
      "  Inliers: 37\n",
      "  Offset X: 5.00 px\n",
      "  Offset Y: -12.93 px\n",
      "  RMSE 2D: 0.70 px\n",
      "  Confidence: 0.018\n",
      "  \u2713 Saved visualization: outputs/test_matching/matches/no_gcps_quarter_matches.jpg\n",
      "\n",
      "============================================================\n",
      "Matching with_gcps to basemap\n",
      "============================================================\n",
      "\n",
      "\ud83d\udcca Resolution: full (factor: 1.0)\n",
      "  Basemap: 9993x10000\n",
      "  Ortho: 9950x10000\n",
      "  Keypoints (ortho): 5000\n",
      "  Keypoints (basemap): 5001\n",
      "  Matches: 125\n",
      "  Inliers: 39\n",
      "  Offset X: 4.21 px\n",
      "  Offset Y: -58.85 px\n",
      "  RMSE 2D: 1.19 px\n",
      "  Confidence: 0.025\n",
      "  \u2713 Saved visualization: outputs/test_matching/matches/with_gcps_full_matches.jpg\n",
      "\n",
      "\ud83d\udcca Resolution: half (factor: 0.5)\n",
      "  Basemap: 4996x5000\n",
      "  Ortho: 4975x5000\n",
      "  Keypoints (ortho): 5000\n",
      "  Keypoints (basemap): 5000\n",
      "  Matches: 104\n",
      "  Inliers: 18\n",
      "  Offset X: 2.75 px\n",
      "  Offset Y: -28.97 px\n",
      "  RMSE 2D: 0.65 px\n",
      "  Confidence: 0.021\n",
      "  \u2713 Saved visualization: outputs/test_matching/matches/with_gcps_half_matches.jpg\n",
      "\n",
      "\ud83d\udcca Resolution: quarter (factor: 0.25)\n",
      "  Basemap: 2498x2500\n",
      "  Ortho: 2487x2500\n",
      "  Keypoints (ortho): 5001\n",
      "  Keypoints (basemap): 5000\n",
      "  Matches: 109\n",
      "  Inliers: 39\n",
      "  Offset X: 1.37 px\n",
      "  Offset Y: -14.47 px\n",
      "  RMSE 2D: 0.50 px\n",
      "  Confidence: 0.022\n",
      "  \u2713 Saved visualization: outputs/test_matching/matches/with_gcps_quarter_matches.jpg\n",
      "\n",
      "\u2713 Feature matching complete!\n"
     ]
    }
   ],
   "source": [
    "def perform_sift_matching(img1: np.ndarray, img2: np.ndarray, max_features: int = 5000) -> Dict:\n",
    "    \"\"\"\n",
    "    Perform SIFT feature matching between two images.\n",
    "    \n",
    "    Args:\n",
    "        img1: First image (numpy array)\n",
    "        img2: Second image (numpy array)\n",
    "        max_features: Maximum number of features to detect\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with matching results\n",
    "    \"\"\"\n",
    "    # Convert to grayscale if needed\n",
    "    if len(img1.shape) == 3:\n",
    "        gray1 = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray1 = img1\n",
    "    \n",
    "    if len(img2.shape) == 3:\n",
    "        gray2 = cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray2 = img2\n",
    "    \n",
    "    # Initialize SIFT detector\n",
    "    sift = cv2.SIFT_create(nfeatures=max_features, contrastThreshold=0.01, edgeThreshold=20)\n",
    "    \n",
    "    # Detect keypoints and descriptors\n",
    "    kp1, des1 = sift.detectAndCompute(gray1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(gray2, None)\n",
    "    \n",
    "    if des1 is None or des2 is None or len(des1) == 0 or len(des2) == 0:\n",
    "        return {\n",
    "            'num_keypoints1': len(kp1) if kp1 else 0,\n",
    "            'num_keypoints2': len(kp2) if kp2 else 0,\n",
    "            'num_matches': 0,\n",
    "            'good_matches': [],\n",
    "            'kp1': kp1,\n",
    "            'kp2': kp2,\n",
    "            'error': 'No descriptors found'\n",
    "        }\n",
    "    \n",
    "    # Match features using FLANN or BFMatcher\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "    search_params = dict(checks=50)\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    \n",
    "    matches = flann.knnMatch(des1, des2, k=2)\n",
    "    \n",
    "    # Apply Lowe's ratio test\n",
    "    good_matches = []\n",
    "    for match_pair in matches:\n",
    "        if len(match_pair) == 2:\n",
    "            m, n = match_pair\n",
    "            if m.distance < 0.75 * n.distance:  # Lowe's ratio test\n",
    "                good_matches.append(m)\n",
    "    \n",
    "    # Calculate offsets\n",
    "    offset_x = None\n",
    "    offset_y = None\n",
    "    rmse_2d = None\n",
    "    H = None\n",
    "    mask = None\n",
    "    \n",
    "    if len(good_matches) >= 4:\n",
    "        # Extract matched points\n",
    "        src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "        \n",
    "        # Find homography\n",
    "        H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "        \n",
    "        if H is not None:\n",
    "            # Calculate mean offset from homography\n",
    "            # Use center point as reference\n",
    "            h, w = gray1.shape\n",
    "            center = np.array([[[w/2, h/2]]], dtype=np.float32)\n",
    "            transformed_center = cv2.perspectiveTransform(center, H)\n",
    "            \n",
    "            offset_x = float(transformed_center[0][0][0] - center[0][0][0])\n",
    "            offset_y = float(transformed_center[0][0][1] - center[0][0][1])\n",
    "            \n",
    "            # Calculate RMSE from inliers\n",
    "            inlier_matches = [good_matches[i] for i in range(len(good_matches)) if mask[i]]\n",
    "            \n",
    "            if len(inlier_matches) > 0:\n",
    "                inlier_src = np.float32([kp1[m.queryIdx].pt for m in inlier_matches])\n",
    "                inlier_dst = np.float32([kp2[m.trainIdx].pt for m in inlier_matches])\n",
    "                \n",
    "                # Transform source points\n",
    "                inlier_src_transformed = cv2.perspectiveTransform(\n",
    "                    inlier_src.reshape(-1, 1, 2), H\n",
    "                ).reshape(-1, 2)\n",
    "                \n",
    "                # Calculate RMSE\n",
    "                errors = inlier_dst - inlier_src_transformed\n",
    "                rmse_2d = float(np.sqrt(np.mean(errors**2)))\n",
    "    \n",
    "    num_inliers = len([m for i, m in enumerate(good_matches) if mask is not None and mask[i]]) if mask is not None and len(good_matches) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'num_keypoints1': len(kp1),\n",
    "        'num_keypoints2': len(kp2),\n",
    "        'num_matches': len(good_matches),\n",
    "        'num_inliers': num_inliers,\n",
    "        'good_matches': good_matches,\n",
    "        'kp1': kp1,\n",
    "        'kp2': kp2,\n",
    "        'offset_x': offset_x,\n",
    "        'offset_y': offset_y,\n",
    "        'rmse_2d': rmse_2d,\n",
    "        'homography': H.tolist() if H is not None else None,\n",
    "        'confidence': len(good_matches) / max(len(kp1), len(kp2)) if len(kp1) > 0 and len(kp2) > 0 else 0.0\n",
    "    }\n",
    "\n",
    "# Perform matching at different resolutions\n",
    "# Use pre-saved JPEG files at each resolution\n",
    "resolutions = {\n",
    "    'full': 1.0,\n",
    "    'half': 0.5,\n",
    "    'quarter': 0.25\n",
    "}\n",
    "\n",
    "matching_results = {}\n",
    "\n",
    "for ortho_name in ['no_gcps', 'with_gcps']:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Matching {ortho_name} to basemap\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    matching_results[ortho_name] = {}\n",
    "    \n",
    "    for res_name, factor in resolutions.items():\n",
    "        print(f\"\\n\ud83d\udcca Resolution: {res_name} (factor: {factor})\")\n",
    "        \n",
    "        # Load pre-saved images at this resolution\n",
    "        basemap_img = converted_files[res_name]['basemap']['img']\n",
    "        ortho_img = converted_files[res_name][ortho_name]['img']\n",
    "        \n",
    "        print(f\"  Basemap: {basemap_img.shape[1]}x{basemap_img.shape[0]}\")\n",
    "        print(f\"  Ortho: {ortho_img.shape[1]}x{ortho_img.shape[0]}\")\n",
    "        \n",
    "        # Perform matching\n",
    "        result = perform_sift_matching(ortho_img, basemap_img)\n",
    "        \n",
    "        print(f\"  Keypoints (ortho): {result['num_keypoints1']}\")\n",
    "        print(f\"  Keypoints (basemap): {result['num_keypoints2']}\")\n",
    "        print(f\"  Matches: {result['num_matches']}\")\n",
    "        print(f\"  Inliers: {result['num_inliers']}\")\n",
    "        \n",
    "        if result['offset_x'] is not None:\n",
    "            print(f\"  Offset X: {result['offset_x']:.2f} px\")\n",
    "            print(f\"  Offset Y: {result['offset_y']:.2f} px\")\n",
    "            print(f\"  RMSE 2D: {result['rmse_2d']:.2f} px\")\n",
    "            print(f\"  Confidence: {result['confidence']:.3f}\")\n",
    "            \n",
    "            # Scale offsets back to full resolution\n",
    "            result['offset_x_full'] = result['offset_x'] / factor\n",
    "            result['offset_y_full'] = result['offset_y'] / factor\n",
    "            result['rmse_2d_full'] = result['rmse_2d'] / factor if result['rmse_2d'] else None\n",
    "        else:\n",
    "            print(f\"  \u26a0\ufe0f  Matching failed: {result.get('error', 'Unknown error')}\")\n",
    "        \n",
    "        matching_results[ortho_name][res_name] = result\n",
    "        \n",
    "        # Save matching visualization\n",
    "        if result['num_matches'] > 0:\n",
    "            vis_path = matches_dir / f\"{ortho_name}_{res_name}_matches.jpg\"\n",
    "            \n",
    "            # Create visualization\n",
    "            img_matches = cv2.drawMatches(\n",
    "                ortho_img, result['kp1'],\n",
    "                basemap_img, result['kp2'],\n",
    "                result['good_matches'][:50],  # Show first 50 matches\n",
    "                None,\n",
    "                flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS\n",
    "            )\n",
    "            \n",
    "            cv2.imwrite(str(vis_path), img_matches)\n",
    "            print(f\"  \u2713 Saved visualization: {vis_path}\")\n",
    "\n",
    "print(f\"\\n\u2713 Feature matching complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "DecompressionBombError",
     "evalue": "Image size (199250000 pixels) exceeds limit of 178956970 pixels, could be decompression bomb DOS attack.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDecompressionBombError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m vis_path \u001b[38;5;241m=\u001b[39m matches_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mortho_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_matches.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m vis_path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m---> 15\u001b[0m     vis_img \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvis_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     ax\u001b[38;5;241m.\u001b[39mimshow(vis_img)\n\u001b[1;32m     17\u001b[0m     ax\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/matplotlib/pyplot.py:2597\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   2593\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(matplotlib\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimread)\n\u001b[1;32m   2594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mimread\u001b[39m(\n\u001b[1;32m   2595\u001b[0m         fname: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath \u001b[38;5;241m|\u001b[39m BinaryIO, \u001b[38;5;28mformat\u001b[39m: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2596\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m-> 2597\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmatplotlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/matplotlib/image.py:1544\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fname, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(parse\u001b[38;5;241m.\u001b[39murlparse(fname)\u001b[38;5;241m.\u001b[39mscheme) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1538\u001b[0m     \u001b[38;5;66;03m# Pillow doesn't handle URLs directly.\u001b[39;00m\n\u001b[1;32m   1539\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease open the URL for reading and pass the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1541\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult to Pillow, e.g. with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1542\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m``np.array(PIL.Image.open(urllib.request.urlopen(url)))``.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1543\u001b[0m         )\n\u001b[0;32m-> 1544\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mimg_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m image:\n\u001b[1;32m   1545\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (_pil_png_to_float_array(image)\n\u001b[1;32m   1546\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(image, PIL\u001b[38;5;241m.\u001b[39mPngImagePlugin\u001b[38;5;241m.\u001b[39mPngImageFile) \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[1;32m   1547\u001b[0m             pil_to_array(image))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/PIL/Image.py:3559\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3556\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m   3557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 3559\u001b[0m im \u001b[38;5;241m=\u001b[39m \u001b[43m_open_core\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m formats \u001b[38;5;129;01mis\u001b[39;00m ID:\n\u001b[1;32m   3562\u001b[0m     checked_formats \u001b[38;5;241m=\u001b[39m ID\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/PIL/Image.py:3548\u001b[0m, in \u001b[0;36mopen.<locals>._open_core\u001b[0;34m(fp, filename, prefix, formats)\u001b[0m\n\u001b[1;32m   3546\u001b[0m         fp\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   3547\u001b[0m         im \u001b[38;5;241m=\u001b[39m factory(fp, filename)\n\u001b[0;32m-> 3548\u001b[0m         \u001b[43m_decompression_bomb_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3549\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m im\n\u001b[1;32m   3550\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mSyntaxError\u001b[39;00m, \u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m, struct\u001b[38;5;241m.\u001b[39merror) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/PIL/Image.py:3449\u001b[0m, in \u001b[0;36m_decompression_bomb_check\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m   3444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pixels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m MAX_IMAGE_PIXELS:\n\u001b[1;32m   3445\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   3446\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpixels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m pixels) exceeds limit of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m2\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39mMAX_IMAGE_PIXELS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3447\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpixels, could be decompression bomb DOS attack.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3448\u001b[0m     )\n\u001b[0;32m-> 3449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DecompressionBombError(msg)\n\u001b[1;32m   3451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pixels \u001b[38;5;241m>\u001b[39m MAX_IMAGE_PIXELS:\n\u001b[1;32m   3452\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   3453\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpixels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m pixels) exceeds limit of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMAX_IMAGE_PIXELS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m pixels, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3454\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould be decompression bomb DOS attack.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3455\u001b[0m         DecompressionBombWarning,\n\u001b[1;32m   3456\u001b[0m     )\n",
      "\u001b[0;31mDecompressionBombError\u001b[0m: Image size (199250000 pixels) exceeds limit of 178956970 pixels, could be decompression bomb DOS attack."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x1200 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create summary visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('SIFT Feature Matching Results at Different Resolutions', fontsize=16, fontweight='bold')\n",
    "\n",
    "for ortho_idx, ortho_name in enumerate(['no_gcps', 'with_gcps']):\n",
    "    for res_idx, (res_name, factor) in enumerate(resolutions.items()):\n",
    "        ax = axes[ortho_idx, res_idx]\n",
    "        \n",
    "        result = matching_results[ortho_name][res_name]\n",
    "        \n",
    "        if result['num_matches'] > 0 and result['offset_x'] is not None:\n",
    "            # Load visualization if it exists\n",
    "            vis_path = matches_dir / f\"{ortho_name}_{res_name}_matches.jpg\"\n",
    "            if vis_path.exists():\n",
    "                vis_img = plt.imread(vis_path)\n",
    "                ax.imshow(vis_img)\n",
    "                ax.axis('off')\n",
    "                \n",
    "                title = f\"{ortho_name.replace('_', ' ').title()} - {res_name.title()}\\n\"\n",
    "                title += f\"Matches: {result['num_matches']}, \"\n",
    "                title += f\"Offset: ({result['offset_x']:.1f}, {result['offset_y']:.1f}) px\"\n",
    "                ax.set_title(title, fontsize=10)\n",
    "            else:\n",
    "                ax.text(0.5, 0.5, f\"No visualization\\navailable\", \n",
    "                       ha='center', va='center', transform=ax.transAxes)\n",
    "                ax.set_title(f\"{ortho_name} - {res_name}\", fontsize=10)\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, f\"No matches found\\n{result.get('error', '')}\", \n",
    "                   ha='center', va='center', transform=ax.transAxes)\n",
    "            ax.set_title(f\"{ortho_name} - {res_name}\", fontsize=10)\n",
    "            ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "summary_vis_path = matches_dir / \"matching_summary.png\"\n",
    "plt.savefig(summary_vis_path, dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(f\"\u2713 Summary visualization saved: {summary_vis_path}\")\n",
    "\n",
    "# Print summary table\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Matching Results Summary\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for ortho_name in ['no_gcps', 'with_gcps']:\n",
    "    print(f\"\\n{ortho_name.replace('_', ' ').title()}:\")\n",
    "    print(f\"  {'Resolution':<12} {'Matches':<10} {'Offset X':<12} {'Offset Y':<12} {'RMSE 2D':<12} {'Confidence':<10}\")\n",
    "    print(f\"  {'-'*12} {'-'*10} {'-'*12} {'-'*12} {'-'*12} {'-'*10}\")\n",
    "    \n",
    "    for res_name in ['full', 'half', 'quarter']:\n",
    "        result = matching_results[ortho_name][res_name]\n",
    "        matches = result['num_matches']\n",
    "        offset_x = f\"{result['offset_x']:.2f}\" if result['offset_x'] is not None else \"N/A\"\n",
    "        offset_y = f\"{result['offset_y']:.2f}\" if result['offset_y'] is not None else \"N/A\"\n",
    "        rmse = f\"{result['rmse_2d']:.2f}\" if result['rmse_2d'] is not None else \"N/A\"\n",
    "        conf = f\"{result['confidence']:.3f}\" if result['confidence'] else \"0.000\"\n",
    "        \n",
    "        print(f\"  {res_name:<12} {matches:<10} {offset_x:<12} {offset_y:<12} {rmse:<12} {conf:<10}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Apply 2D Shift and Register Orthomosaics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_2d_shift_to_image(img: np.ndarray, shift_x: float, shift_y: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply 2D shift to an image.\n",
    "    \n",
    "    Args:\n",
    "        img: Input image array\n",
    "        shift_x: Shift in X direction (pixels)\n",
    "        shift_y: Shift in Y direction (pixels)\n",
    "        \n",
    "    Returns:\n",
    "        Shifted image\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from scipy.ndimage import shift\n",
    "        use_scipy = True\n",
    "    except ImportError:\n",
    "        use_scipy = False\n",
    "    \n",
    "    if use_scipy:\n",
    "        if len(img.shape) == 3:\n",
    "            # RGB image\n",
    "            shifted = np.zeros_like(img)\n",
    "            for i in range(img.shape[2]):\n",
    "                shifted[:, :, i] = shift(img[:, :, i], (shift_y, shift_x), mode='constant', cval=0, order=1)\n",
    "        else:\n",
    "            # Grayscale\n",
    "            shifted = shift(img, (shift_y, shift_x), mode='constant', cval=0, order=1)\n",
    "    else:\n",
    "        # Fallback: integer shift using numpy\n",
    "        shift_x_int = int(round(shift_x))\n",
    "        shift_y_int = int(round(shift_y))\n",
    "        \n",
    "        if len(img.shape) == 3:\n",
    "            shifted = np.zeros_like(img)\n",
    "            h, w = img.shape[:2]\n",
    "            if shift_y_int >= 0 and shift_x_int >= 0:\n",
    "                shifted[shift_y_int:, shift_x_int:] = img[:h-shift_y_int, :w-shift_x_int]\n",
    "            elif shift_y_int < 0 and shift_x_int < 0:\n",
    "                shifted[:h+shift_y_int, :w+shift_x_int] = img[-shift_y_int:, -shift_x_int:]\n",
    "            else:\n",
    "                # Handle other cases\n",
    "                if shift_y_int >= 0:\n",
    "                    shifted[shift_y_int:, :] = img[:h-shift_y_int, :]\n",
    "                if shift_x_int >= 0:\n",
    "                    shifted[:, shift_x_int:] = img[:, :w-shift_x_int]\n",
    "        else:\n",
    "            shifted = np.zeros_like(img)\n",
    "            h, w = img.shape\n",
    "            if shift_y_int >= 0 and shift_x_int >= 0:\n",
    "                shifted[shift_y_int:, shift_x_int:] = img[:h-shift_y_int, :w-shift_x_int]\n",
    "            elif shift_y_int < 0 and shift_x_int < 0:\n",
    "                shifted[:h+shift_y_int, :w+shift_x_int] = img[-shift_y_int:, -shift_x_int:]\n",
    "    \n",
    "    return shifted\n",
    "\n",
    "# Choose best resolution for registration (prefer full res if available, otherwise use best match count)\n",
    "registered_orthos = {}\n",
    "\n",
    "for ortho_name in ['no_gcps', 'with_gcps']:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Registering {ortho_name}...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Find best resolution (prefer full, then highest match count)\n",
    "    best_res = None\n",
    "    best_matches = 0\n",
    "    \n",
    "    for res_name in ['full', 'half', 'quarter']:\n",
    "        result = matching_results[ortho_name][res_name]\n",
    "        if result['num_matches'] > best_matches and result['offset_x'] is not None:\n",
    "            best_matches = result['num_matches']\n",
    "            best_res = res_name\n",
    "    \n",
    "    if best_res is None:\n",
    "        print(f\"  \u26a0\ufe0f  No valid matches found for {ortho_name}\")\n",
    "        continue\n",
    "    \n",
    "    result = matching_results[ortho_name][best_res]\n",
    "    print(f\"  Using {best_res} resolution results (matches: {result['num_matches']})\")\n",
    "    \n",
    "    # Get full resolution offset\n",
    "    shift_x = result['offset_x_full']\n",
    "    shift_y = result['offset_y_full']\n",
    "    \n",
    "    print(f\"  Applying shift: X={shift_x:.2f} px, Y={shift_y:.2f} px\")\n",
    "    \n",
    "    # Load full resolution image\n",
    "    ortho_img = converted_files['full'][ortho_name]['img']\n",
    "    \n",
    "    # Apply shift\n",
    "    shifted_img = apply_2d_shift_to_image(ortho_img, shift_x, shift_y)\n",
    "    \n",
    "    # Save registered image\n",
    "    registered_path = registered_dir / f\"{ortho_name}_registered.jpg\"\n",
    "    \n",
    "    if len(shifted_img.shape) == 3:\n",
    "        img_pil = Image.fromarray(shifted_img)\n",
    "    else:\n",
    "        img_pil = Image.fromarray(shifted_img).convert('RGB')\n",
    "    \n",
    "    img_pil.save(registered_path, 'JPEG', quality=95)\n",
    "    print(f\"  \u2713 Saved registered image: {registered_path}\")\n",
    "    \n",
    "    registered_orthos[ortho_name] = {\n",
    "        'path': registered_path,\n",
    "        'img': shifted_img,\n",
    "        'shift_x': shift_x,\n",
    "        'shift_y': shift_y,\n",
    "        'resolution_used': best_res\n",
    "    }\n",
    "\n",
    "print(f\"\\n\u2713 Registration complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Create Final Visualizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create side-by-side comparison: original vs registered\n",
    "for ortho_name in ['no_gcps', 'with_gcps']:\n",
    "    if ortho_name not in registered_orthos:\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nCreating visualization for {ortho_name}...\")\n",
    "    \n",
    "    # Load images (use full resolution)\n",
    "    original_img = converted_files['full'][ortho_name]['img']\n",
    "    registered_img = registered_orthos[ortho_name]['img']\n",
    "    basemap_img = converted_files['full']['basemap']['img']\n",
    "    \n",
    "    # Resize to same size for comparison (use smallest)\n",
    "    min_h = min(original_img.shape[0], registered_img.shape[0], basemap_img.shape[0])\n",
    "    min_w = min(original_img.shape[1], registered_img.shape[1], basemap_img.shape[1])\n",
    "    \n",
    "    original_resized = cv2.resize(original_img, (min_w, min_h))\n",
    "    registered_resized = cv2.resize(registered_img, (min_w, min_h))\n",
    "    basemap_resized = cv2.resize(basemap_img, (min_w, min_h))\n",
    "    \n",
    "    # Create comparison figure\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 16))\n",
    "    fig.suptitle(f'Registration Results: {ortho_name.replace(\"_\", \" \").title()}', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Basemap (ground truth)\n",
    "    axes[0, 0].imshow(basemap_resized)\n",
    "    axes[0, 0].set_title('Ground Truth Basemap', fontweight='bold')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # Original ortho\n",
    "    axes[0, 1].imshow(original_resized)\n",
    "    axes[0, 1].set_title('Original Orthomosaic', fontweight='bold')\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    # Registered ortho\n",
    "    axes[1, 0].imshow(registered_resized)\n",
    "    shift_info = registered_orthos[ortho_name]\n",
    "    title = f\"Registered Orthomosaic\\n\"\n",
    "    title += f\"Shift: ({shift_info['shift_x']:.2f}, {shift_info['shift_y']:.2f}) px\\n\"\n",
    "    title += f\"Resolution: {shift_info['resolution_used']}\"\n",
    "    axes[1, 0].set_title(title, fontweight='bold')\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    # Difference map\n",
    "    diff = np.abs(registered_resized.astype(float) - basemap_resized.astype(float))\n",
    "    diff_norm = (diff / diff.max() * 255).astype(np.uint8) if diff.max() > 0 else diff.astype(np.uint8)\n",
    "    axes[1, 1].imshow(diff_norm, cmap='hot')\n",
    "    axes[1, 1].set_title('Difference Map (Registered vs Basemap)', fontweight='bold')\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    comparison_path = registered_dir / f\"{ortho_name}_comparison.png\"\n",
    "    plt.savefig(comparison_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"  \u2713 Saved comparison: {comparison_path}\")\n",
    "\n",
    "# Save matching results to JSON\n",
    "results_json_path = matching_output_dir / \"matching_results.json\"\n",
    "\n",
    "def convert_to_native(obj):\n",
    "    \"\"\"Convert numpy types to native Python types for JSON.\"\"\"\n",
    "    if isinstance(obj, np.integer):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, np.floating):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: convert_to_native(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_native(item) for item in obj]\n",
    "    elif hasattr(obj, '__dict__'):\n",
    "        # Handle OpenCV keypoints (skip them for JSON)\n",
    "        return None\n",
    "    return obj\n",
    "\n",
    "# Clean results for JSON (remove OpenCV objects)\n",
    "json_results = {}\n",
    "for ortho_name in matching_results:\n",
    "    json_results[ortho_name] = {}\n",
    "    for res_name in matching_results[ortho_name]:\n",
    "        result = matching_results[ortho_name][res_name].copy()\n",
    "        # Remove OpenCV objects\n",
    "        result.pop('kp1', None)\n",
    "        result.pop('kp2', None)\n",
    "        result.pop('good_matches', None)\n",
    "        json_results[ortho_name][res_name] = convert_to_native(result)\n",
    "\n",
    "with open(results_json_path, 'w') as f:\n",
    "    json.dump(json_results, f, indent=2)\n",
    "\n",
    "print(f\"\\n\u2713 Results saved to: {results_json_path}\")\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"\u2713 Feature Matching and Registration Complete!\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}