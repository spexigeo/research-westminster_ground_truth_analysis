{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orthomosaic-Basemap Feature Matching and Registration\n",
    "\n",
    "This notebook performs feature matching between orthomosaics (with/without GCPs) and a ground control basemap using SIFT and evaluates 2D shifting and registration.\n",
    "\n",
    "## Goals:\n",
    "1. **Feature Matching**: Use SIFT to find corresponding features between orthos and basemap\n",
    "2. **Multi-Resolution Analysis**: Evaluate matching at full, half, and quarter resolution\n",
    "3. **2D Registration**: Apply computed shifts to register orthos to basemap\n",
    "4. **Visualization**: Create visualizations of matches and registered orthos\n",
    "\n",
    "## Inputs:\n",
    "- **Ground Control Basemap**: `TestsiteNewWest_Spexigeo_RTK.tiff`\n",
    "- **Orthomosaic (No GCPs)**: `outputs/orthomosaics/orthomosaic_no_gcps.tif`\n",
    "- **Orthomosaic (With GCPs)**: `outputs/orthomosaics/orthomosaic_with_gcps.tif`\n",
    "\n",
    "## Outputs:\n",
    "- All outputs saved to `outputs/test_matching/`\n",
    "- Match visualizations at different resolutions\n",
    "- Registered orthomosaics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Install Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 Dependencies installed\n"
     ]
    }
   ],
   "source": [
    "# Install required packages if needed\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "packages = ['opencv-python', 'scikit-image', 'rasterio', 'numpy', 'matplotlib', 'pillow', 'scipy']\n",
    "for package in packages:\n",
    "    try:\n",
    "        if package == 'opencv-python':\n",
    "            __import__('cv2')\n",
    "        elif package == 'scikit-image':\n",
    "            __import__('skimage')\n",
    "        elif package == 'pillow':\n",
    "            __import__('PIL')\n",
    "        else:\n",
    "            __import__(package)\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "print(\"\u2713 Dependencies installed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 Imports successful!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling, transform_bounds\n",
    "from rasterio import Affine\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import warnings\n",
    "import json\n",
    "from typing import Dict, Tuple, Optional, List\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"\u2713 Imports successful!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup Paths and Output Directories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 Output directory: outputs/test_matching\n",
      "  - Reprojected: outputs/test_matching/reprojected\n",
      "  - Converted: outputs/test_matching/converted\n",
      "  - Matches: outputs/test_matching/matches\n",
      "  - Registered: outputs/test_matching/registered\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "data_dir = Path(\"/Users/mauriciohessflores/Documents/Code/Data/New Westminster Oct _25\")\n",
    "output_dir = Path(\"outputs\")\n",
    "\n",
    "# Input files\n",
    "basemap_path = data_dir / \"Michael_RTK_orthos\" / \"TestsiteNewWest_Spexigeo_RTK.tiff\"\n",
    "ortho_no_gcps_path = output_dir / \"orthomosaics\" / \"orthomosaic_no_gcps.tif\"\n",
    "ortho_with_gcps_path = output_dir / \"orthomosaics\" / \"orthomosaic_with_gcps.tif\"\n",
    "\n",
    "# Output directory structure\n",
    "matching_output_dir = output_dir / \"test_matching\"\n",
    "matching_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Subdirectories\n",
    "reprojected_dir = matching_output_dir / \"reprojected\"\n",
    "reprojected_dir.mkdir(exist_ok=True)\n",
    "\n",
    "converted_dir = matching_output_dir / \"converted\"\n",
    "converted_dir.mkdir(exist_ok=True)\n",
    "\n",
    "matches_dir = matching_output_dir / \"matches\"\n",
    "matches_dir.mkdir(exist_ok=True)\n",
    "\n",
    "registered_dir = matching_output_dir / \"registered\"\n",
    "registered_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"\u2713 Output directory: {matching_output_dir}\")\n",
    "print(f\"  - Reprojected: {reprojected_dir}\")\n",
    "print(f\"  - Converted: {converted_dir}\")\n",
    "print(f\"  - Matches: {matches_dir}\")\n",
    "print(f\"  - Registered: {registered_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load and Check Input Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 All input files found\n",
      "\n",
      "\ud83d\udcca File Information:\n",
      "\n",
      "Basemap:\n",
      "  Path: /Users/mauriciohessflores/Documents/Code/Data/New Westminster Oct _25/Michael_RTK_orthos/TestsiteNewWest_Spexigeo_RTK.tiff\n",
      "  Size: 19804.91 MB\n",
      "  CRS: EPSG:32610\n",
      "  Dimensions: 90129 x 90188\n",
      "  Bands: 4\n",
      "  Bounds: BoundingBox(left=506424.37839793676, bottom=5450017.622213458, right=507501.0951215451, top=5451095.043774429)\n",
      "  Pixel size: 0.0119 m (X), 0.0119 m (Y)\n",
      "\n",
      "Ortho (No GCPs):\n",
      "  Path: outputs/orthomosaics/orthomosaic_no_gcps.tif\n",
      "  Size: 3887.28 MB\n",
      "  CRS: EPSG:4326\n",
      "  Dimensions: 38531 x 39277\n",
      "  Bands: 4\n",
      "  Bounds: BoundingBox(left=-122.91170031378732, bottom=49.20303508811748, right=-122.89720111440005, top=49.212718829461046)\n",
      "  Pixel size: 0.0000 m (X), 0.0000 m (Y)\n",
      "\n",
      "Ortho (With GCPs):\n",
      "  Path: outputs/orthomosaics/orthomosaic_with_gcps.tif\n",
      "  Size: 3867.91 MB\n",
      "  CRS: EPSG:4326\n",
      "  Dimensions: 38538 x 39233\n",
      "  Bands: 4\n",
      "  Bounds: BoundingBox(left=-122.9117167927641, bottom=49.203044960109175, right=-122.89720605758104, top=49.21272378933356)\n",
      "  Pixel size: 0.0000 m (X), 0.0000 m (Y)\n"
     ]
    }
   ],
   "source": [
    "# Check if files exist\n",
    "if not basemap_path.exists():\n",
    "    raise FileNotFoundError(f\"Basemap not found: {basemap_path}\")\n",
    "if not ortho_no_gcps_path.exists():\n",
    "    raise FileNotFoundError(f\"Orthomosaic (no GCPs) not found: {ortho_no_gcps_path}\")\n",
    "if not ortho_with_gcps_path.exists():\n",
    "    raise FileNotFoundError(f\"Orthomosaic (with GCPs) not found: {ortho_with_gcps_path}\")\n",
    "\n",
    "print(\"\u2713 All input files found\")\n",
    "\n",
    "# Get basic info about each file\n",
    "print(\"\\n\ud83d\udcca File Information:\")\n",
    "for name, path in [(\"Basemap\", basemap_path), (\"Ortho (No GCPs)\", ortho_no_gcps_path), (\"Ortho (With GCPs)\", ortho_with_gcps_path)]:\n",
    "    with rasterio.open(path) as src:\n",
    "        file_size_mb = path.stat().st_size / (1024 * 1024)\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"  Path: {path}\")\n",
    "        print(f\"  Size: {file_size_mb:.2f} MB\")\n",
    "        print(f\"  CRS: {src.crs}\")\n",
    "        print(f\"  Dimensions: {src.width} x {src.height}\")\n",
    "        print(f\"  Bands: {src.count}\")\n",
    "        print(f\"  Bounds: {src.bounds}\")\n",
    "        if src.crs:\n",
    "            pixel_size_x = abs(src.transform[0])\n",
    "            pixel_size_y = abs(src.transform[4])\n",
    "            print(f\"  Pixel size: {pixel_size_x:.4f} m (X), {pixel_size_y:.4f} m (Y)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Reproject Orthomosaics to Match Basemap CRS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target CRS: EPSG:32610\n",
      "Target bounds: BoundingBox(left=506424.37839793676, bottom=5450017.622213458, right=507501.0951215451, top=5451095.043774429)\n",
      "Target dimensions: 90129 x 90188\n",
      "\n",
      "============================================================\n",
      "Reprojecting no_gcps...\n",
      "  \u2713 Already reprojected: outputs/test_matching/reprojected/no_gcps_reprojected.tif\n",
      "    Dimensions: 88515x89120, CRS: EPSG:32610\n",
      "\n",
      "============================================================\n",
      "Reprojecting with_gcps...\n",
      "  \u2713 Already reprojected: outputs/test_matching/reprojected/with_gcps_reprojected.tif\n",
      "    Dimensions: 88586x89028, CRS: EPSG:32610\n",
      "\n",
      "\u2713 Reprojection complete!\n"
     ]
    }
   ],
   "source": [
    "# Get basemap CRS (target CRS)\n",
    "with rasterio.open(basemap_path) as basemap_src:\n",
    "    target_crs = basemap_src.crs\n",
    "    target_bounds = basemap_src.bounds\n",
    "    target_transform = basemap_src.transform\n",
    "    target_width = basemap_src.width\n",
    "    target_height = basemap_src.height\n",
    "\n",
    "print(f\"Target CRS: {target_crs}\")\n",
    "print(f\"Target bounds: {target_bounds}\")\n",
    "print(f\"Target dimensions: {target_width} x {target_height}\")\n",
    "\n",
    "# Reproject each orthomosaic\n",
    "ortho_paths = {\n",
    "    'no_gcps': ortho_no_gcps_path,\n",
    "    'with_gcps': ortho_with_gcps_path\n",
    "}\n",
    "\n",
    "reprojected_paths = {}\n",
    "\n",
    "for ortho_name, ortho_path in ortho_paths.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Reprojecting {ortho_name}...\")\n",
    "    \n",
    "    reprojected_path = reprojected_dir / f\"{ortho_name}_reprojected.tif\"\n",
    "    \n",
    "    # Check if already reprojected (skip if file exists and is valid)\n",
    "    if reprojected_path.exists():\n",
    "        try:\n",
    "            # Verify the file is valid by checking its properties\n",
    "            with rasterio.open(reprojected_path) as check_src:\n",
    "                if check_src.crs == target_crs:\n",
    "                    print(f\"  \u2713 Already reprojected: {reprojected_path}\")\n",
    "                    print(f\"    Dimensions: {check_src.width}x{check_src.height}, CRS: {check_src.crs}\")\n",
    "                    reprojected_paths[ortho_name] = reprojected_path\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"  \u26a0\ufe0f  Existing file has wrong CRS, will reproject...\")\n",
    "        except Exception as e:\n",
    "            print(f\"  \u26a0\ufe0f  Existing file is invalid ({e}), will reproject...\")\n",
    "    \n",
    "    with rasterio.open(ortho_path) as ortho_src:\n",
    "        source_crs = ortho_src.crs\n",
    "        source_bounds = ortho_src.bounds\n",
    "        \n",
    "        print(f\"  Source CRS: {source_crs}\")\n",
    "        print(f\"  Source bounds: {source_bounds}\")\n",
    "        \n",
    "        # Check if reprojection is needed\n",
    "        if source_crs == target_crs:\n",
    "            print(f\"  \u2713 Already in target CRS, copying...\")\n",
    "            import shutil\n",
    "            shutil.copy(ortho_path, reprojected_path)\n",
    "            reprojected_paths[ortho_name] = reprojected_path\n",
    "            continue\n",
    "        \n",
    "        # Calculate transform using source bounds (not target bounds)\n",
    "        # First, transform source bounds to target CRS to get output extent\n",
    "        try:\n",
    "            print(f\"  Transforming source bounds to target CRS...\")\n",
    "            src_bounds_target_crs = transform_bounds(\n",
    "                source_crs, target_crs,\n",
    "                source_bounds.left, source_bounds.bottom,\n",
    "                source_bounds.right, source_bounds.top\n",
    "            )\n",
    "            \n",
    "            print(f\"  Source bounds in target CRS: {src_bounds_target_crs}\")\n",
    "            \n",
    "            # Get target pixel size\n",
    "            target_pixel_size_x = abs(target_transform[0])\n",
    "            target_pixel_size_y = abs(target_transform[4])\n",
    "            \n",
    "            # Use intersection of bounds (where both images overlap)\n",
    "            output_left = max(src_bounds_target_crs[0], target_bounds.left)\n",
    "            output_bottom = max(src_bounds_target_crs[1], target_bounds.bottom)\n",
    "            output_right = min(src_bounds_target_crs[2], target_bounds.right)\n",
    "            output_top = min(src_bounds_target_crs[3], target_bounds.top)\n",
    "            \n",
    "            print(f\"  Output bounds (intersection): left={output_left:.2f}, bottom={output_bottom:.2f}, right={output_right:.2f}, top={output_top:.2f}\")\n",
    "            \n",
    "            # Validate bounds\n",
    "            if output_right <= output_left or output_top <= output_bottom:\n",
    "                raise ValueError(f\"Invalid output bounds: width={output_right-output_left}, height={output_top-output_bottom}\")\n",
    "            \n",
    "            # Calculate dimensions using target pixel size\n",
    "            width = int((output_right - output_left) / target_pixel_size_x)\n",
    "            height = int((output_top - output_bottom) / target_pixel_size_y)\n",
    "            \n",
    "            # Validate dimensions\n",
    "            if width <= 0 or height <= 0:\n",
    "                raise ValueError(f\"Invalid dimensions: width={width}, height={height}\")\n",
    "            \n",
    "            # Create transform for output\n",
    "            transform = Affine.translation(output_left, output_top) * Affine.scale(target_pixel_size_x, -target_pixel_size_y)\n",
    "            \n",
    "            print(f\"  \u2713 Transform calculated: {width}x{height} pixels\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  \u274c Transform calculation failed: {e}\")\n",
    "            print(f\"  Trying alternative approach using source resolution...\")\n",
    "            \n",
    "            # Alternative: use source resolution and calculate output bounds\n",
    "            try:\n",
    "                # Get source pixel size\n",
    "                source_pixel_size_x = abs(ortho_src.transform[0])\n",
    "                source_pixel_size_y = abs(ortho_src.transform[4])\n",
    "                \n",
    "                # Transform source bounds to target CRS\n",
    "                src_bounds_target_crs = transform_bounds(\n",
    "                    source_crs, target_crs,\n",
    "                    source_bounds.left, source_bounds.bottom,\n",
    "                    source_bounds.right, source_bounds.top\n",
    "                )\n",
    "                \n",
    "                # Use source pixel size (approximate)\n",
    "                output_left = src_bounds_target_crs[0]\n",
    "                output_bottom = src_bounds_target_crs[1]\n",
    "                output_right = src_bounds_target_crs[2]\n",
    "                output_top = src_bounds_target_crs[3]\n",
    "                \n",
    "                # Calculate dimensions\n",
    "                width = int((output_right - output_left) / source_pixel_size_x)\n",
    "                height = int((output_top - output_bottom) / source_pixel_size_y)\n",
    "                \n",
    "                transform = Affine.translation(output_left, output_top) * Affine.scale(source_pixel_size_x, -source_pixel_size_y)\n",
    "                \n",
    "                print(f\"  \u2713 Using source resolution approach: {width}x{height} pixels\")\n",
    "                \n",
    "            except Exception as e2:\n",
    "                print(f\"  \u274c Alternative approach also failed: {e2}\")\n",
    "                print(f\"  Skipping {ortho_name}...\")\n",
    "                continue\n",
    "        \n",
    "        # Reproject\n",
    "        print(f\"  Reprojecting to {width}x{height}...\")\n",
    "        \n",
    "        # Read source data\n",
    "        source_data = ortho_src.read()\n",
    "        source_count = ortho_src.count\n",
    "        \n",
    "        # Reproject each band\n",
    "        reprojected_data = np.zeros((source_count, height, width), dtype=source_data.dtype)\n",
    "        \n",
    "        for band_idx in range(1, source_count + 1):\n",
    "            reproject(\n",
    "                source=rasterio.band(ortho_src, band_idx),\n",
    "                destination=reprojected_data[band_idx - 1],\n",
    "                src_transform=ortho_src.transform,\n",
    "                src_crs=source_crs,\n",
    "                dst_transform=transform,\n",
    "                dst_crs=target_crs,\n",
    "                resampling=Resampling.bilinear\n",
    "            )\n",
    "        \n",
    "        # Save reprojected file with LZW compression\n",
    "        # Note: We skip saving JPEG here because PIL has a 65500 pixel limit\n",
    "        # JPEG conversion will be done in Step 4 at different resolutions\n",
    "        \n",
    "        # Save GeoTIFF with compression\n",
    "        with rasterio.open(\n",
    "            reprojected_path,\n",
    "            'w',\n",
    "            driver='GTiff',\n",
    "            height=height,\n",
    "            width=width,\n",
    "            count=source_count,\n",
    "            dtype=reprojected_data.dtype,\n",
    "            crs=target_crs,\n",
    "            transform=transform,\n",
    "            compress='lzw',\n",
    "            BIGTIFF='YES',\n",
    "            tiled=True,\n",
    "            blockxsize=512,\n",
    "            blockysize=512,\n",
    "            predictor=2  # Horizontal differencing for better compression\n",
    "        ) as dst:\n",
    "            dst.write(reprojected_data)\n",
    "        \n",
    "        print(f\"  \u2713 Saved: {reprojected_path}\")\n",
    "        print(f\"  Note: JPEG conversion will be done in Step 4 (PIL limit: 65500 pixels)\")\n",
    "        reprojected_paths[ortho_name] = reprojected_path\n",
    "\n",
    "print(f\"\\n\u2713 Reprojection complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting files to JPEG at different resolutions...\n",
      "\n",
      "Basemap JPEG (half) already exists: outputs/test_matching/converted/basemap_half.jpg\n",
      "\n",
      "Basemap JPEG (quarter) already exists: outputs/test_matching/converted/basemap_quarter.jpg\n",
      "\n",
      "no_gcps JPEG (half) already exists: outputs/test_matching/converted/no_gcps_half.jpg\n",
      "\n",
      "no_gcps JPEG (quarter) already exists: outputs/test_matching/converted/no_gcps_quarter.jpg\n",
      "\n",
      "with_gcps JPEG (half) already exists: outputs/test_matching/converted/with_gcps_half.jpg\n",
      "\n",
      "with_gcps JPEG (quarter) already exists: outputs/test_matching/converted/with_gcps_quarter.jpg\n",
      "\n",
      "\u2713 Conversion complete!\n"
     ]
    }
   ],
   "source": [
    "# Ensure imports are available\n",
    "try:\n",
    "    from pathlib import Path\n",
    "    import numpy as np\n",
    "    import rasterio\n",
    "    from rasterio import Affine\n",
    "    from PIL import Image\n",
    "# Increase PIL image size limit to handle large images\n",
    "    import cv2\n",
    "    from typing import Tuple, Dict\n",
    "except (NameError, ImportError):\n",
    "    # Re-import if not available\n",
    "    from pathlib import Path\n",
    "    import numpy as np\n",
    "    import rasterio\n",
    "    from rasterio import Affine\n",
    "    import cv2\n",
    "    from typing import Tuple, Dict\n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = None  # Disable decompression bomb protection\n",
    "\n",
    "def convert_geotiff_to_jpeg(geotiff_path: Path, output_path: Path, downsample_factor: float = 1.0) -> Tuple[np.ndarray, Dict]:\n",
    "    \"\"\"\n",
    "    Convert GeoTIFF to JPEG format at specified resolution.\n",
    "    \n",
    "    Args:\n",
    "        geotiff_path: Path to input GeoTIFF\n",
    "        output_path: Path to save JPEG\n",
    "        downsample_factor: Factor to downsample (1.0 = full res, 0.5 = half, 0.25 = quarter)\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (image array, metadata dict with transform info)\n",
    "    \"\"\"\n",
    "    with rasterio.open(geotiff_path) as src:\n",
    "        # Get metadata\n",
    "        metadata = {\n",
    "            'transform': src.transform,\n",
    "            'crs': src.crs,\n",
    "            'bounds': src.bounds,\n",
    "            'width': src.width,\n",
    "            'height': src.height\n",
    "        }\n",
    "        \n",
    "        # Calculate output dimensions\n",
    "        if downsample_factor < 1.0:\n",
    "            new_height = int(src.height * downsample_factor)\n",
    "            new_width = int(src.width * downsample_factor)\n",
    "        else:\n",
    "            new_height = src.height\n",
    "            new_width = src.width\n",
    "        \n",
    "        print(f\"    Processing {src.width}x{src.height} -> {new_width}x{new_height} (factor: {downsample_factor})\")\n",
    "        \n",
    "        # For very large images, process in tiles to avoid memory issues\n",
    "        # Use tile-based processing for images > 10k pixels\n",
    "        use_tiles = src.width > 10000 or src.height > 10000\n",
    "        \n",
    "        if use_tiles:\n",
    "            # Process in tiles with downsampling\n",
    "            print(f\"    Using tile-based processing (tile size: 2048)...\")\n",
    "            \n",
    "            # Compute global statistics for normalization\n",
    "            # Use a sample-based approach for memory efficiency\n",
    "            print(f\"    Computing image statistics for normalization...\")\n",
    "            \n",
    "            # Read a representative sample (center region) to estimate min/max\n",
    "            sample_size = min(5000, src.width, src.height)\n",
    "            center_x = src.width // 2\n",
    "            center_y = src.height // 2\n",
    "            sample_x = max(0, center_x - sample_size // 2)\n",
    "            sample_y = max(0, center_y - sample_size // 2)\n",
    "            sample_w = min(sample_size, src.width - sample_x)\n",
    "            sample_h = min(sample_size, src.height - sample_y)\n",
    "            \n",
    "            window = rasterio.windows.Window(sample_x, sample_y, sample_w, sample_h)\n",
    "            \n",
    "            if src.count >= 3:\n",
    "                sample_data = src.read([1, 2, 3], window=window)  # Shape: (3, H, W)\n",
    "                data_min = sample_data.min(axis=(1, 2), keepdims=True)  # Shape: (3, 1, 1)\n",
    "                data_max = sample_data.max(axis=(1, 2), keepdims=True)  # Shape: (3, 1, 1)\n",
    "            else:\n",
    "                sample_data = src.read(1, window=window)  # Shape: (H, W)\n",
    "                data_min_val = sample_data.min()\n",
    "                data_max_val = sample_data.max()\n",
    "                data_min = np.array([[[data_min_val]]])  # Shape: (1, 1, 1)\n",
    "                data_max = np.array([[[data_max_val]]])  # Shape: (1, 1, 1)\n",
    "                # Expand to 3 channels\n",
    "                data_min = np.repeat(data_min, 3, axis=0)  # Shape: (3, 1, 1)\n",
    "                data_max = np.repeat(data_max, 3, axis=0)  # Shape: (3, 1, 1)\n",
    "            \n",
    "            data_range = data_max - data_min\n",
    "            data_range[data_range == 0] = 1\n",
    "            \n",
    "            # Create output array\n",
    "            output_array = np.zeros((new_height, new_width, 3), dtype=np.uint8)\n",
    "            tile_size = 2048\n",
    "            \n",
    "            # Process in tiles\n",
    "            num_tiles_x = (src.width + tile_size - 1) // tile_size\n",
    "            num_tiles_y = (src.height + tile_size - 1) // tile_size\n",
    "            \n",
    "            for tile_y in range(num_tiles_y):\n",
    "                for tile_x in range(num_tiles_x):\n",
    "                    # Calculate tile window\n",
    "                    col_off = tile_x * tile_size\n",
    "                    row_off = tile_y * tile_size\n",
    "                    width = min(tile_size, src.width - col_off)\n",
    "                    height = min(tile_size, src.height - row_off)\n",
    "                    \n",
    "                    window = rasterio.windows.Window(col_off, row_off, width, height)\n",
    "                    \n",
    "                    # Read tile\n",
    "                    if src.count >= 3:\n",
    "                        tile_data = src.read([1, 2, 3], window=window)\n",
    "                    else:\n",
    "                        tile_data = src.read(1, window=window)\n",
    "                        tile_data = np.stack([tile_data] * 3)\n",
    "                    \n",
    "                    # Normalize\n",
    "                    tile_normalized = ((tile_data - data_min) / data_range * 255).astype(np.uint8)\n",
    "                    \n",
    "                    # Ensure tile_normalized has correct shape (3, H, W)\n",
    "                    if len(tile_normalized.shape) == 2:\n",
    "                        # Single band, convert to 3 channels\n",
    "                        tile_normalized = np.stack([tile_normalized] * 3)\n",
    "                    elif tile_normalized.shape[0] != 3:\n",
    "                        # Wrong number of channels, fix it\n",
    "                        if tile_normalized.shape[0] == 1:\n",
    "                            tile_normalized = np.repeat(tile_normalized, 3, axis=0)\n",
    "                        else:\n",
    "                            tile_normalized = tile_normalized[:3]  # Take first 3 channels\n",
    "                    \n",
    "                    # Downsample tile\n",
    "                    if downsample_factor < 1.0:\n",
    "                        tile_h, tile_w = tile_normalized.shape[1], tile_normalized.shape[2]\n",
    "                        new_tile_h = int(tile_h * downsample_factor)\n",
    "                        new_tile_w = int(tile_w * downsample_factor)\n",
    "                        \n",
    "                        if new_tile_h > 0 and new_tile_w > 0:\n",
    "                            tile_resized = np.zeros((3, new_tile_h, new_tile_w), dtype=np.uint8)\n",
    "                            for i in range(3):\n",
    "                                tile_resized[i] = cv2.resize(tile_normalized[i], (new_tile_w, new_tile_h), interpolation=cv2.INTER_AREA)\n",
    "                            tile_normalized = tile_resized\n",
    "                    \n",
    "                    # Calculate output position\n",
    "                    out_col_off = int(col_off * downsample_factor)\n",
    "                    out_row_off = int(row_off * downsample_factor)\n",
    "                    tile_h, tile_w = tile_normalized.shape[1], tile_normalized.shape[2]\n",
    "                    \n",
    "                    # Ensure we don't exceed output bounds\n",
    "                    out_h = min(tile_h, new_height - out_row_off)\n",
    "                    out_w = min(tile_w, new_width - out_col_off)\n",
    "                    \n",
    "                    if out_h > 0 and out_w > 0 and out_row_off >= 0 and out_col_off >= 0:\n",
    "                        # Ensure we don't exceed tile dimensions\n",
    "                        slice_h = min(out_h, tile_h)\n",
    "                        slice_w = min(out_w, tile_w)\n",
    "                        \n",
    "                        # Verify tile_normalized has correct shape\n",
    "                        if len(tile_normalized.shape) == 3 and tile_normalized.shape[0] == 3:\n",
    "                            # Slice tile to fit output bounds, then convert to (H, W, C) and place in output\n",
    "                            tile_slice = tile_normalized[:, :slice_h, :slice_w]  # Shape: (3, slice_h, slice_w)\n",
    "                            tile_rgb = tile_slice.transpose(1, 2, 0)  # Shape: (slice_h, slice_w, 3)\n",
    "                            # Place in output array (use actual slice dimensions)\n",
    "                            output_array[out_row_off:out_row_off+slice_h, out_col_off:out_col_off+slice_w] = tile_rgb\n",
    "                        else:\n",
    "                            print(f\"      Warning: Unexpected tile shape {tile_normalized.shape}, skipping tile\")\n",
    "                \n",
    "                if (tile_y + 1) % 10 == 0:\n",
    "                    print(f\"      Processed {tile_y + 1}/{num_tiles_y} tile rows...\")\n",
    "            \n",
    "            img_array = output_array\n",
    "            \n",
    "        else:\n",
    "            # For smaller images, read normally\n",
    "            if src.count >= 3:\n",
    "                data = src.read([1, 2, 3])\n",
    "            else:\n",
    "                data = src.read(1)\n",
    "                data = np.stack([data, data, data])\n",
    "            \n",
    "            # Normalize to 0-255\n",
    "            if data.dtype != np.uint8:\n",
    "                data_min = data.min(axis=(1, 2), keepdims=True)\n",
    "                data_max = data.max(axis=(1, 2), keepdims=True)\n",
    "                data_range = data_max - data_min\n",
    "                data_range[data_range == 0] = 1\n",
    "                data = ((data - data_min) / data_range * 255).astype(np.uint8)\n",
    "            \n",
    "            # Downsample if needed\n",
    "            if downsample_factor < 1.0:\n",
    "                height, width = data.shape[1], data.shape[2]\n",
    "                new_height = int(height * downsample_factor)\n",
    "                new_width = int(width * downsample_factor)\n",
    "                \n",
    "                data_resized = np.zeros((3, new_height, new_width), dtype=np.uint8)\n",
    "                for i in range(3):\n",
    "                    data_resized[i] = cv2.resize(data[i], (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "                data = data_resized\n",
    "            \n",
    "            # Convert to PIL Image format (H, W, C)\n",
    "            img_array = data.transpose(1, 2, 0)\n",
    "        \n",
    "        # Update metadata\n",
    "        metadata['width'] = new_width\n",
    "        metadata['height'] = new_height\n",
    "        if downsample_factor < 1.0:\n",
    "            old_transform = metadata['transform']\n",
    "            metadata['transform'] = Affine(\n",
    "                old_transform[0] / downsample_factor, old_transform[1], old_transform[2],\n",
    "                old_transform[3], old_transform[4] / downsample_factor, old_transform[5]\n",
    "            )\n",
    "        \n",
    "        # Save as JPEG (only if within PIL limits) or PNG\n",
    "        # Validate array before saving\n",
    "        if img_array.dtype != np.uint8:\n",
    "            print(f\"    \u26a0\ufe0f  Converting array from {img_array.dtype} to uint8...\")\n",
    "            img_array = np.clip(img_array, 0, 255).astype(np.uint8)\n",
    "        \n",
    "        if len(img_array.shape) != 3 or img_array.shape[2] != 3:\n",
    "            raise ValueError(f\"Invalid image array shape: {img_array.shape}, expected (H, W, 3)\")\n",
    "        \n",
    "        try:\n",
    "            img = Image.fromarray(img_array, 'RGB')\n",
    "            \n",
    "            if new_width <= 65500 and new_height <= 65500:\n",
    "                # Save as JPEG\n",
    "                img.save(output_path, 'JPEG', quality=95, optimize=True)\n",
    "                \n",
    "                # Verify file was written correctly\n",
    "                if output_path.exists() and output_path.stat().st_size > 0:\n",
    "                    print(f\"    \u2713 Saved JPEG: {output_path} ({new_width}x{new_height}, {output_path.stat().st_size / 1024 / 1024:.2f} MB)\")\n",
    "                else:\n",
    "                    raise IOError(f\"JPEG file was not written correctly: {output_path}\")\n",
    "            else:\n",
    "                # Save as PNG for very large images (PNG has no dimension limit)\n",
    "                print(f\"    \u26a0\ufe0f  Image too large for JPEG (PIL limit: 65500), saving as PNG...\")\n",
    "                output_path_png = output_path.with_suffix('.png')\n",
    "                img.save(output_path_png, 'PNG', compress_level=6)\n",
    "                \n",
    "                # Verify file was written correctly\n",
    "                if output_path_png.exists() and output_path_png.stat().st_size > 0:\n",
    "                    print(f\"    \u2713 Saved PNG: {output_path_png} ({new_width}x{new_height}, {output_path_png.stat().st_size / 1024 / 1024:.2f} MB)\")\n",
    "                    output_path = output_path_png\n",
    "                else:\n",
    "                    raise IOError(f\"PNG file was not written correctly: {output_path_png}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"    \u274c Error saving image: {e}\")\n",
    "            raise\n",
    "        \n",
    "        return img_array, metadata\n",
    "\n",
    "# Check if required variables are defined\n",
    "try:\n",
    "    from pathlib import Path\n",
    "except ImportError:\n",
    "    from pathlib import Path\n",
    "\n",
    "try:\n",
    "    _ = converted_dir\n",
    "except NameError:\n",
    "    try:\n",
    "        _ = output_dir\n",
    "    except NameError:\n",
    "        output_dir = Path(\"outputs\")\n",
    "    converted_dir = output_dir / \"test_matching\" / \"converted\"\n",
    "    converted_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"\u2139\ufe0f  converted_dir not defined, using default: {converted_dir}\")\n",
    "\n",
    "try:\n",
    "    _ = basemap_path\n",
    "except NameError:\n",
    "    try:\n",
    "        _ = data_dir\n",
    "    except NameError:\n",
    "        data_dir = Path(\"/Users/mauriciohessflores/Documents/Code/Data/New Westminster Oct _25\")\n",
    "    basemap_path = data_dir / \"Michael_RTK_orthos\" / \"TestsiteNewWest_Spexigeo_RTK.tiff\"\n",
    "    if not basemap_path.exists():\n",
    "        raise FileNotFoundError(f\"Basemap not found: {basemap_path}\")\n",
    "\n",
    "try:\n",
    "    _ = reprojected_paths\n",
    "except NameError:\n",
    "    try:\n",
    "        _ = reprojected_dir\n",
    "    except NameError:\n",
    "        try:\n",
    "            _ = output_dir\n",
    "        except NameError:\n",
    "            output_dir = Path(\"outputs\")\n",
    "        reprojected_dir = output_dir / \"test_matching\" / \"reprojected\"\n",
    "    \n",
    "    # Try to find reprojected files\n",
    "    reprojected_paths = {}\n",
    "    for ortho_name in ['no_gcps', 'with_gcps']:\n",
    "        reproj_path = reprojected_dir / f\"{ortho_name}_reprojected.tif\"\n",
    "        if reproj_path.exists():\n",
    "            reprojected_paths[ortho_name] = reproj_path\n",
    "            print(f\"\u2139\ufe0f  Found existing reprojected file: {reproj_path}\")\n",
    "        else:\n",
    "            print(f\"\u26a0\ufe0f  Reprojected file not found: {reproj_path}\")\n",
    "            print(f\"   Please run Step 3 first to create reprojected files\")\n",
    "\n",
    "# Convert basemap and reprojected orthos at different resolutions\n",
    "# Skip full resolution for now (too large, causes kernel crashes)\n",
    "# Can enable later if needed\n",
    "resolutions = {\n",
    "    # 'full': 1.0,  # Skipped - too large for memory\n",
    "    'half': 0.5,\n",
    "    'quarter': 0.25\n",
    "}\n",
    "\n",
    "converted_files = {}\n",
    "\n",
    "print(\"Converting files to JPEG at different resolutions...\")\n",
    "\n",
    "# Convert basemap at all resolutions\n",
    "for res_name, factor in resolutions.items():\n",
    "    basemap_jpeg = converted_dir / f\"basemap_{res_name}.jpg\"\n",
    "    if not basemap_jpeg.exists():\n",
    "        print(f\"\\nConverting basemap at {res_name} resolution...\")\n",
    "        basemap_img, basemap_meta = convert_geotiff_to_jpeg(basemap_path, basemap_jpeg, downsample_factor=factor)\n",
    "        if res_name not in converted_files:\n",
    "            converted_files[res_name] = {}\n",
    "        converted_files[res_name]['basemap'] = {'path': basemap_jpeg, 'img': basemap_img, 'meta': basemap_meta}\n",
    "    else:\n",
    "        # Check if PNG was saved instead (for very large images)\n",
    "        basemap_png = basemap_jpeg.with_suffix('.png')\n",
    "        if basemap_png.exists():\n",
    "            print(f\"\\nBasemap PNG ({res_name}) already exists: {basemap_png}\")\n",
    "            basemap_img = np.array(Image.open(basemap_png))\n",
    "            basemap_jpeg = basemap_png  # Update path\n",
    "        else:\n",
    "            print(f\"\\nBasemap JPEG ({res_name}) already exists: {basemap_jpeg}\")\n",
    "            basemap_img = np.array(Image.open(basemap_jpeg))\n",
    "        with rasterio.open(basemap_path) as src:\n",
    "            basemap_meta = {\n",
    "                'transform': src.transform,\n",
    "                'crs': src.crs,\n",
    "                'bounds': src.bounds,\n",
    "                'width': basemap_img.shape[1],\n",
    "                'height': basemap_img.shape[0]\n",
    "            }\n",
    "        if res_name not in converted_files:\n",
    "            converted_files[res_name] = {}\n",
    "        converted_files[res_name]['basemap'] = {'path': basemap_jpeg, 'img': basemap_img, 'meta': basemap_meta}\n",
    "\n",
    "# Convert reprojected orthos at all resolutions\n",
    "for ortho_name, reprojected_path in reprojected_paths.items():\n",
    "    for res_name, factor in resolutions.items():\n",
    "        ortho_jpeg = converted_dir / f\"{ortho_name}_{res_name}.jpg\"\n",
    "        if not ortho_jpeg.exists():\n",
    "            print(f\"\\nConverting {ortho_name} at {res_name} resolution...\")\n",
    "            ortho_img, ortho_meta = convert_geotiff_to_jpeg(reprojected_path, ortho_jpeg, downsample_factor=factor)\n",
    "            converted_files[res_name][ortho_name] = {'path': ortho_jpeg, 'img': ortho_img, 'meta': ortho_meta}\n",
    "        else:\n",
    "            # Check if PNG was saved instead (for very large images)\n",
    "            ortho_png = ortho_jpeg.with_suffix('.png')\n",
    "            if ortho_png.exists():\n",
    "                print(f\"\\n{ortho_name} PNG ({res_name}) already exists: {ortho_png}\")\n",
    "                ortho_img = np.array(Image.open(ortho_png))\n",
    "                ortho_jpeg = ortho_png  # Update path\n",
    "            else:\n",
    "                print(f\"\\n{ortho_name} JPEG ({res_name}) already exists: {ortho_jpeg}\")\n",
    "                ortho_img = np.array(Image.open(ortho_jpeg))\n",
    "            with rasterio.open(reprojected_path) as src:\n",
    "                ortho_meta = {\n",
    "                    'transform': src.transform,\n",
    "                    'crs': src.crs,\n",
    "                    'bounds': src.bounds,\n",
    "                    'width': ortho_img.shape[1],\n",
    "                    'height': ortho_img.shape[0]\n",
    "                }\n",
    "            if res_name not in converted_files:\n",
    "                converted_files[res_name] = {}\n",
    "            converted_files[res_name][ortho_name] = {'path': ortho_jpeg, 'img': ortho_img, 'meta': ortho_meta}\n",
    "\n",
    "print(f\"\\n\u2713 Conversion complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_tile_based_orb_matching(img1: np.ndarray, img2: np.ndarray, tile_size: int = 4000, overlap: int = 800, max_features: int = 2000) -> Dict:\n",
    "    \"\"\"\n",
    "    Perform ORB feature matching using tile-based approach for memory efficiency.\n",
    "    \n",
    "    Args:\n",
    "        img1: First image (numpy array)\n",
    "        img2: Second image (numpy array)\n",
    "        tile_size: Size of each tile in pixels (default: 4000)\n",
    "        overlap: Overlap between tiles in pixels (default: 800)\n",
    "        max_features: Maximum features per tile (default: 2000)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with matching results aggregated from all tiles\n",
    "    \"\"\"\n",
    "    # Convert to grayscale if needed\n",
    "    if len(img1.shape) == 3:\n",
    "        gray1 = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray1 = img1\n",
    "    \n",
    "    if len(img2.shape) == 3:\n",
    "        gray2 = cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray2 = img2\n",
    "    \n",
    "    h1, w1 = gray1.shape\n",
    "\n",
    "    # First, try coarse alignment using phase correlation\n",
    "    # This helps if images are significantly offset\n",
    "    try:\n",
    "        from scipy import signal\n",
    "        # Downsample for phase correlation (much faster)\n",
    "        ds_factor = 8  # Downsample by 8x for speed\n",
    "        gray1_small = cv2.resize(gray1, (w1//ds_factor, h1//ds_factor), interpolation=cv2.INTER_AREA)\n",
    "        gray2_small = cv2.resize(gray2, (w2//ds_factor, h2//ds_factor), interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        # Find overlap region (use smaller image as template)\n",
    "        h_small, w_small = min(gray1_small.shape[0], gray2_small.shape[0]), min(gray1_small.shape[1], gray2_small.shape[1])\n",
    "        template = gray1_small[:h_small, :w_small]\n",
    "        search = gray2_small\n",
    "        \n",
    "        # Phase correlation to find offset\n",
    "        correlation = signal.correlate2d(search, template, mode='full')\n",
    "        y_peak, x_peak = np.unravel_index(np.argmax(correlation), correlation.shape)\n",
    "        \n",
    "        # Calculate offset (account for correlation padding)\n",
    "        coarse_offset_y = (y_peak - search.shape[0] + 1) * ds_factor\n",
    "        coarse_offset_x = (x_peak - search.shape[1] + 1) * ds_factor\n",
    "        \n",
    "        print(f\"    Coarse alignment: offset_x={coarse_offset_x:.1f}, offset_y={coarse_offset_y:.1f} px\")\n",
    "        \n",
    "        # Use this offset to constrain tile matching\n",
    "        use_coarse_alignment = True\n",
    "        alignment_tolerance = max(w1, h1) * 0.1  # 10% of image size\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    \u26a0\ufe0f  Coarse alignment failed: {e}, proceeding without it\")\n",
    "        use_coarse_alignment = False\n",
    "        coarse_offset_x = 0\n",
    "        coarse_offset_y = 0\n",
    "    h2, w2 = gray2.shape\n",
    "    \n",
    "    # Calculate number of tiles\n",
    "    step = tile_size - overlap\n",
    "    tiles_x1 = max(1, (w1 + step - 1) // step)\n",
    "    tiles_y1 = max(1, (h1 + step - 1) // step)\n",
    "    tiles_x2 = max(1, (w2 + step - 1) // step)\n",
    "    tiles_y2 = max(1, (h2 + step - 1) // step)\n",
    "    \n",
    "    print(f\"    Processing {tiles_y1}x{tiles_x1} tiles for img1, {tiles_y2}x{tiles_x2} tiles for img2\")\n",
    "    \n",
    "    all_offsets_x = []\n",
    "    all_offsets_y = []\n",
    "    all_matches = []\n",
    "    total_keypoints1 = 0\n",
    "    total_keypoints2 = 0\n",
    "    \n",
    "    # Process tiles from img1\n",
    "    for ty1 in range(tiles_y1):\n",
    "        for tx1 in range(tiles_x1):\n",
    "            y1_start = ty1 * step\n",
    "            y1_end = min(y1_start + tile_size, h1)\n",
    "            x1_start = tx1 * step\n",
    "            x1_end = min(x1_start + tile_size, w1)\n",
    "            \n",
    "            tile1 = gray1[y1_start:y1_end, x1_start:x1_end]\n",
    "            \n",
    "            # Find corresponding region in img2\n",
    "            best_match_count = 0\n",
    "            best_offset_x = None\n",
    "            best_offset_y = None\n",
    "            \n",
    "            for ty2 in range(tiles_y2):\n",
    "                for tx2 in range(tiles_x2):\n",
    "                    y2_start = ty2 * step\n",
    "                    y2_end = min(y2_start + tile_size, h2)\n",
    "                    x2_start = tx2 * step\n",
    "                    x2_end = min(x2_start + tile_size, w2)\n",
    "                    \n",
    "                    tile2 = gray2[y2_start:y2_end, x2_start:x2_end]\n",
    "                    \n",
    "                    # Use ORB for faster, more memory-efficient matching\n",
    "                    orb = cv2.ORB_create(nfeatures=max_features, edgeThreshold=31, patchSize=31)\n",
    "                    kp1_tile, des1_tile = orb.detectAndCompute(tile1, None)\n",
    "                    kp2_tile, des2_tile = orb.detectAndCompute(tile2, None)\n",
    "                    \n",
    "                    if des1_tile is None or des2_tile is None or len(des1_tile) == 0 or len(des2_tile) == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    # ORB uses binary descriptors - use Hamming distance matcher\n",
    "                    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)\n",
    "                    \n",
    "                    try:\n",
    "                        matches = bf.knnMatch(des1_tile, des2_tile, k=2)\n",
    "                    except:\n",
    "                        continue\n",
    "                    \n",
    "                    # Apply Lowe's ratio test\n",
    "                    good_matches = []\n",
    "                    for match_pair in matches:\n",
    "                        if len(match_pair) == 2:\n",
    "                            m, n = match_pair\n",
    "                            if m.distance < 0.7 * n.distance:\n",
    "                                good_matches.append(m)\n",
    "                    \n",
    "                    if len(good_matches) >= 4:\n",
    "                        # Calculate offset for this tile pair\n",
    "                        src_pts = np.float32([kp1_tile[m.queryIdx].pt for m in good_matches])\n",
    "                        dst_pts = np.float32([kp2_tile[m.trainIdx].pt for m in good_matches])\n",
    "                        \n",
    "                        # Calculate mean offset\n",
    "                        offsets = dst_pts - src_pts\n",
    "                        mean_offset_x = float(np.mean(offsets[:, 0]))\n",
    "                        mean_offset_y = float(np.mean(offsets[:, 1]))\n",
    "                        \n",
    "                        # Adjust for tile positions\n",
    "                        global_offset_x = mean_offset_x + (x2_start - x1_start)\n",
    "                        global_offset_y = mean_offset_y + (y2_start - y1_start)\n",
    "                        \n",
    "                        if len(good_matches) > best_match_count:\n",
    "                            best_match_count = len(good_matches)\n",
    "                            best_offset_x = global_offset_x\n",
    "                            best_offset_y = global_offset_y\n",
    "                    \n",
    "                    total_keypoints1 += len(kp1_tile) if kp1_tile else 0\n",
    "                    total_keypoints2 += len(kp2_tile) if kp2_tile else 0\n",
    "            \n",
    "            if best_offset_x is not None:\n",
    "                all_offsets_x.append(best_offset_x)\n",
    "                all_offsets_y.append(best_offset_y)\n",
    "                all_matches.append(best_match_count)\n",
    "    \n",
    "    # Aggregate results\n",
    "    if len(all_offsets_x) > 0:\n",
    "        # Use median offset (more robust than mean)\n",
    "        offset_x = float(np.median(all_offsets_x))\n",
    "        offset_y = float(np.median(all_offsets_y))\n",
    "        total_matches = sum(all_matches)\n",
    "        \n",
    "        # Calculate RMSE from offsets\n",
    "        if len(all_offsets_x) > 1:\n",
    "            errors_x = np.array(all_offsets_x) - offset_x\n",
    "            errors_y = np.array(all_offsets_y) - offset_y\n",
    "            rmse_2d = float(np.sqrt(np.mean(errors_x**2 + errors_y**2)))\n",
    "        else:\n",
    "            rmse_2d = 0.0\n",
    "    else:\n",
    "        offset_x = None\n",
    "        offset_y = None\n",
    "        total_matches = 0\n",
    "        rmse_2d = None\n",
    "    \n",
    "    return {\n",
    "        'num_keypoints1': total_keypoints1,\n",
    "        'num_keypoints2': total_keypoints2,\n",
    "        'num_matches': total_matches,\n",
    "        'num_inliers': total_matches,  # All matches are considered inliers\n",
    "        'offset_x': offset_x,\n",
    "        'offset_y': offset_y,\n",
    "        'rmse_2d': rmse_2d,\n",
    "        'homography': None,  # Not computed for tile-based\n",
    "        'confidence': total_matches / max(total_keypoints1, total_keypoints2) if total_keypoints1 > 0 and total_keypoints2 > 0 else 0.0,\n",
    "        'good_matches': [],  # Not stored for tile-based\n",
    "        'kp1': [],  # Not stored for tile-based\n",
    "        'kp2': []  # Not stored for tile-based\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Matching no_gcps to basemap\n",
      "============================================================\n",
      "\n",
      "\ud83d\udcca Resolution: quarter (factor: 0.25)\n",
      "  Basemap: 22532x22547\n",
      "  Ortho: 22128x22280\n",
      "    Processing 7x7 tiles for img1, 8x8 tiles for img2\n",
      "  Keypoints (ortho): 4015488\n",
      "  Keypoints (basemap): 3709650\n",
      "  Matches: 650\n",
      "  Inliers: 650\n",
      "  Offset X: 255.66 px\n",
      "  Offset Y: 200.45 px\n",
      "  RMSE 2D: 10797.95 px\n",
      "  Confidence: 0.000\n",
      "\n",
      "============================================================\n",
      "Matching with_gcps to basemap\n",
      "============================================================\n",
      "\n",
      "\ud83d\udcca Resolution: quarter (factor: 0.25)\n",
      "  Basemap: 22532x22547\n",
      "  Ortho: 22146x22257\n",
      "    Processing 7x7 tiles for img1, 8x8 tiles for img2\n",
      "  Keypoints (ortho): 3949920\n",
      "  Keypoints (basemap): 3709650\n",
      "  Matches: 647\n",
      "  Inliers: 647\n",
      "  Offset X: 449.58 px\n",
      "  Offset Y: 87.06 px\n",
      "  RMSE 2D: 8986.82 px\n",
      "  Confidence: 0.000\n",
      "\n",
      "\u2713 Feature matching complete!\n"
     ]
    }
   ],
   "source": [
    "## Step 5: Perform Feature Matching\n",
    "\n",
    "# Perform matching at different resolutions\n",
    "# Use pre-saved JPEG files at each resolution\n",
    "# Note: Only quarter resolution (half skipped due to memory)\n",
    "resolutions = {\n",
    "    # 'full': 1.0,  # Skipped - too large for memory\n",
    "    # 'half': 0.5,  # Skipped - too large, causes kernel crashes\n",
    "    'quarter': 0.25\n",
    "}\n",
    "\n",
    "# Ensure required variables and imports are available\n",
    "try:\n",
    "    import numpy as np\n",
    "    from PIL import Image\n",
    "    from pathlib import Path\n",
    "    import cv2\n",
    "    from typing import Dict\n",
    "except (NameError, ImportError):\n",
    "    import numpy as np\n",
    "    from PIL import Image\n",
    "    from pathlib import Path\n",
    "    import cv2\n",
    "    from typing import Dict\n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = None  # Disable decompression bomb protection\n",
    "\n",
    "# Ensure converted_dir is defined\n",
    "try:\n",
    "    _ = converted_dir\n",
    "except NameError:\n",
    "    try:\n",
    "        _ = output_dir\n",
    "    except NameError:\n",
    "        output_dir = Path(\"outputs\")\n",
    "    converted_dir = output_dir / \"test_matching\" / \"converted\"\n",
    "    print(f\"\u2139\ufe0f  converted_dir not defined, using default: {converted_dir}\")\n",
    "\n",
    "# Ensure matches_dir is defined\n",
    "try:\n",
    "    _ = matches_dir\n",
    "except NameError:\n",
    "    try:\n",
    "        _ = output_dir\n",
    "    except NameError:\n",
    "        output_dir = Path(\"outputs\")\n",
    "    matches_dir = output_dir / \"test_matching\" / \"matches\"\n",
    "    matches_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"\u2139\ufe0f  matches_dir not defined, using default: {matches_dir}\")\n",
    "\n",
    "matching_results = {}\n",
    "\n",
    "for ortho_name in ['no_gcps', 'with_gcps']:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Matching {ortho_name} to basemap\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    matching_results[ortho_name] = {}\n",
    "    \n",
    "    for res_name, factor in resolutions.items():\n",
    "        print(f\"\\n\ud83d\udcca Resolution: {res_name} (factor: {factor})\")\n",
    "        \n",
    "        # Load pre-saved images at this resolution\n",
    "        # Check if converted_files is available, otherwise load from disk\n",
    "        try:\n",
    "            _ = converted_files\n",
    "        except NameError:\n",
    "            print(\"  \u26a0\ufe0f  converted_files not defined, loading from disk...\")\n",
    "            converted_files = {}\n",
    "        \n",
    "        # Load basemap image\n",
    "        if res_name in converted_files and 'basemap' in converted_files[res_name]:\n",
    "            basemap_img = converted_files[res_name]['basemap']['img']\n",
    "        else:\n",
    "            # Load from disk\n",
    "            basemap_jpeg = converted_dir / f\"basemap_{res_name}.jpg\"\n",
    "            basemap_png = converted_dir / f\"basemap_{res_name}.png\"\n",
    "            if basemap_png.exists():\n",
    "                basemap_img = np.array(Image.open(basemap_png))\n",
    "            elif basemap_jpeg.exists():\n",
    "                basemap_img = np.array(Image.open(basemap_jpeg))\n",
    "            else:\n",
    "                print(f\"  \u274c Basemap image not found for {res_name} resolution\")\n",
    "                continue\n",
    "        \n",
    "        # Load ortho image\n",
    "        if res_name in converted_files and ortho_name in converted_files[res_name]:\n",
    "            ortho_img = converted_files[res_name][ortho_name]['img']\n",
    "        else:\n",
    "            # Load from disk\n",
    "            ortho_jpeg = converted_dir / f\"{ortho_name}_{res_name}.jpg\"\n",
    "            ortho_png = converted_dir / f\"{ortho_name}_{res_name}.png\"\n",
    "            if ortho_png.exists():\n",
    "                ortho_img = np.array(Image.open(ortho_png))\n",
    "            elif ortho_jpeg.exists():\n",
    "                ortho_img = np.array(Image.open(ortho_jpeg))\n",
    "            else:\n",
    "                print(f\"  \u274c Ortho image not found for {ortho_name} at {res_name} resolution\")\n",
    "                continue\n",
    "        \n",
    "        print(f\"  Basemap: {basemap_img.shape[1]}x{basemap_img.shape[0]}\")\n",
    "        print(f\"  Ortho: {ortho_img.shape[1]}x{ortho_img.shape[0]}\")\n",
    "        \n",
    "        # Perform matching using tile-based ORB\n",
    "        result = perform_tile_based_orb_matching(ortho_img, basemap_img, tile_size=4000, overlap=800, max_features=2000)\n",
    "        \n",
    "        # Clean up memory\n",
    "        import gc\n",
    "        del basemap_img, ortho_img\n",
    "        gc.collect()\n",
    "        \n",
    "        print(f\"  Keypoints (ortho): {result['num_keypoints1']}\")\n",
    "        print(f\"  Keypoints (basemap): {result['num_keypoints2']}\")\n",
    "        print(f\"  Matches: {result['num_matches']}\")\n",
    "        print(f\"  Inliers: {result['num_inliers']}\")\n",
    "        \n",
    "        if result['offset_x'] is not None:\n",
    "            print(f\"  Offset X: {result['offset_x']:.2f} px\")\n",
    "            print(f\"  Offset Y: {result['offset_y']:.2f} px\")\n",
    "            print(f\"  RMSE 2D: {result['rmse_2d']:.2f} px\")\n",
    "            print(f\"  Confidence: {result['confidence']:.3f}\")\n",
    "            \n",
    "            # Scale offsets back to full resolution\n",
    "            result['offset_x_full'] = result['offset_x'] / factor\n",
    "            result['offset_y_full'] = result['offset_y'] / factor\n",
    "            result['rmse_2d_full'] = result['rmse_2d'] / factor if result['rmse_2d'] else None\n",
    "        else:\n",
    "            print(f\"  \u26a0\ufe0f  Matching failed: {result.get('error', 'Unknown error')}\")\n",
    "        \n",
    "        matching_results[ortho_name][res_name] = result\n",
    "\n",
    "print(f\"\\n\u2713 Feature matching complete!\")\n",
    "\n",
    "# Save matching results to JSON file\n",
    "import json\n",
    "try:\n",
    "    _ = matches_dir\n",
    "except NameError:\n",
    "    try:\n",
    "        _ = output_dir\n",
    "    except NameError:\n",
    "        output_dir = Path(\"outputs\")\n",
    "    matches_dir = output_dir / \"test_matching\" / \"matches\"\n",
    "    matches_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "matching_results_file = matches_dir / \"matching_results.json\"\n",
    "\n",
    "# Convert numpy types to native Python types for JSON serialization\n",
    "def convert_to_native_types(obj):\n",
    "    \"\"\"Recursively convert numpy types to native Python types.\"\"\"\n",
    "    import numpy as np\n",
    "    if isinstance(obj, np.integer):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, np.floating):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, dict):\n",
    "        return {key: convert_to_native_types(value) for key, value in obj.items()}\n",
    "    elif isinstance(obj, (list, tuple)):\n",
    "        return [convert_to_native_types(item) for item in obj]\n",
    "    return obj\n",
    "\n",
    "matching_results_serializable = convert_to_native_types(matching_results)\n",
    "with open(matching_results_file, 'w') as f:\n",
    "    json.dump(matching_results_serializable, f, indent=2)\n",
    "print(f\"\u2713 Saved matching results to: {matching_results_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u26a0\ufe0f  matching_results not defined. Attempting to load from JSON file...\n",
      "   JSON file not found: outputs/test_matching/matches/matching_results.json\n",
      "   Please run Step 5 (matching loop) first.\n",
      "   Skipping visualization...\n",
      "\u26a0\ufe0f  No matching results available. Please run Step 5 (matching loop) first.\n",
      "\u2713 Summary visualization saved: outputs/test_matching/matches/matching_summary.png\n",
      "\n",
      "============================================================\n",
      "Matching Results Summary\n",
      "============================================================\n",
      "\n",
      "No Gcps:\n",
      "  Resolution   Matches    Offset X     Offset Y     RMSE 2D      Confidence\n",
      "  ------------ ---------- ------------ ------------ ------------ ----------\n",
      "\n",
      "With Gcps:\n",
      "  Resolution   Matches    Offset X     Offset Y     RMSE 2D      Confidence\n",
      "  ------------ ---------- ------------ ------------ ------------ ----------\n"
     ]
    }
   ],
   "source": [
    "# Create summary visualization\n",
    "# Ensure imports are available\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    from pathlib import Path\n",
    "except (NameError, ImportError):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from pathlib import Path\n",
    "\n",
    "# Ensure required variables are defined\n",
    "try:\n",
    "    _ = matching_results\n",
    "except NameError:\n",
    "    print(\"\u26a0\ufe0f  matching_results not defined. Attempting to load from JSON file...\")\n",
    "    try:\n",
    "        import json\n",
    "        from pathlib import Path\n",
    "        try:\n",
    "            _ = matches_dir\n",
    "        except NameError:\n",
    "            try:\n",
    "                _ = output_dir\n",
    "            except NameError:\n",
    "                output_dir = Path(\"outputs\")\n",
    "            matches_dir = output_dir / \"test_matching\" / \"matches\"\n",
    "        matching_results_file = matches_dir / \"matching_results.json\"\n",
    "        if matching_results_file.exists():\n",
    "            with open(matching_results_file, 'r') as f:\n",
    "                matching_results = json.load(f)\n",
    "            print(f\"\u2713 Loaded matching results from: {matching_results_file}\")\n",
    "        else:\n",
    "            print(f\"   JSON file not found: {matching_results_file}\")\n",
    "            print(\"   Please run Step 5 (matching loop) first.\")\n",
    "            matching_results = {}\n",
    "    except Exception as e:\n",
    "        print(f\"   Error loading JSON: {e}\")\n",
    "        matching_results = {}\n",
    "    print(\"   Skipping visualization...\")\n",
    "    matching_results = {}\n",
    "\n",
    "try:\n",
    "    _ = resolutions\n",
    "except NameError:\n",
    "    resolutions = {'quarter': 0.25}  # Default\n",
    "\n",
    "try:\n",
    "    _ = matches_dir\n",
    "except NameError:\n",
    "    try:\n",
    "        _ = output_dir\n",
    "    except NameError:\n",
    "        output_dir = Path(\"outputs\")\n",
    "    matches_dir = output_dir / \"test_matching\" / \"matches\"\n",
    "    matches_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Determine subplot dimensions dynamically\n",
    "# Calculate max resolutions dynamically\n",
    "max_resolutions = 1\n",
    "for on in ['no_gcps', 'with_gcps']:\n",
    "    if on in matching_results:\n",
    "        num_res = len(matching_results[on].keys())\n",
    "        if num_res > max_resolutions:\n",
    "            max_resolutions = num_res\n",
    "\n",
    "# Check if we have any results to visualize\n",
    "has_results = False\n",
    "if matching_results:\n",
    "    for on in ['no_gcps', 'with_gcps']:\n",
    "        if on in matching_results and matching_results[on]:\n",
    "            has_results = True\n",
    "            break\n",
    "\n",
    "if not has_results:\n",
    "    print(\"\u26a0\ufe0f  No matching results available. Please run Step 5 (matching loop) first.\")\n",
    "    fig, axes = plt.subplots(2, max_resolutions, figsize=(6*max_resolutions, 12))\n",
    "    if max_resolutions == 1:\n",
    "        axes = axes.reshape(2, 1)  # Ensure 2D array for indexing\n",
    "    fig.suptitle('SIFT Feature Matching Results at Different Resolutions', fontsize=16, fontweight='bold')\n",
    "\n",
    "for ortho_idx, ortho_name in enumerate(['no_gcps', 'with_gcps']):\n",
    "    # Get available resolutions for this ortho\n",
    "    available_resolutions = list(matching_results[ortho_name].keys()) if ortho_name in matching_results else []\n",
    "    for res_idx, res_name in enumerate(available_resolutions):\n",
    "        if res_name not in matching_results[ortho_name]:\n",
    "            continue\n",
    "        # Get factor for this resolution\n",
    "        factor = resolutions.get(res_name, 0.25)  # Default to quarter if not found\n",
    "        ax = axes[ortho_idx, res_idx]\n",
    "        \n",
    "        result = matching_results[ortho_name][res_name]\n",
    "        \n",
    "        if result['num_matches'] > 0 and result['offset_x'] is not None:\n",
    "            # Load visualization if it exists\n",
    "            vis_path = matches_dir / f\"{ortho_name}_{res_name}_matches.jpg\"\n",
    "            if vis_path.exists():\n",
    "                vis_img = plt.imread(vis_path)\n",
    "                ax.imshow(vis_img)\n",
    "                ax.axis('off')\n",
    "                \n",
    "                title = f\"{ortho_name.replace('_', ' ').title()} - {res_name.title()}\\n\"\n",
    "                title += f\"Matches: {result['num_matches']}, \"\n",
    "                title += f\"Offset: ({result['offset_x']:.1f}, {result['offset_y']:.1f}) px\"\n",
    "                ax.set_title(title, fontsize=10)\n",
    "            else:\n",
    "                ax.text(0.5, 0.5, f\"No visualization\\navailable\", \n",
    "                       ha='center', va='center', transform=ax.transAxes)\n",
    "                ax.set_title(f\"{ortho_name} - {res_name}\", fontsize=10)\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, f\"No matches found\\n{result.get('error', '')}\", \n",
    "                   ha='center', va='center', transform=ax.transAxes)\n",
    "            ax.set_title(f\"{ortho_name} - {res_name}\", fontsize=10)\n",
    "            ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "summary_vis_path = matches_dir / \"matching_summary.png\"\n",
    "plt.savefig(summary_vis_path, dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(f\"\u2713 Summary visualization saved: {summary_vis_path}\")\n",
    "\n",
    "# Print summary table\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Matching Results Summary\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for ortho_name in ['no_gcps', 'with_gcps']:\n",
    "    print(f\"\\n{ortho_name.replace('_', ' ').title()}:\")\n",
    "    print(f\"  {'Resolution':<12} {'Matches':<10} {'Offset X':<12} {'Offset Y':<12} {'RMSE 2D':<12} {'Confidence':<10}\")\n",
    "    print(f\"  {'-'*12} {'-'*10} {'-'*12} {'-'*12} {'-'*12} {'-'*10}\")\n",
    "    \n",
    "    # Only show resolutions that were actually processed\n",
    "    available_resolutions = list(matching_results[ortho_name].keys()) if ortho_name in matching_results else []\n",
    "    for res_name in available_resolutions:\n",
    "        result = matching_results[ortho_name][res_name]\n",
    "        matches = result['num_matches']\n",
    "        offset_x = f\"{result['offset_x']:.2f}\" if result['offset_x'] is not None else \"N/A\"\n",
    "        offset_y = f\"{result['offset_y']:.2f}\" if result['offset_y'] is not None else \"N/A\"\n",
    "        rmse = f\"{result['rmse_2d']:.2f}\" if result['rmse_2d'] is not None else \"N/A\"\n",
    "        conf = f\"{result['confidence']:.3f}\" if result['confidence'] else \"0.000\"\n",
    "        \n",
    "        print(f\"  {res_name:<12} {matches:<10} {offset_x:<12} {offset_y:<12} {rmse:<12} {conf:<10}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Apply 2D Shift and Register Orthomosaics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure imports are available\n",
    "try:\n",
    "    import numpy as np\n",
    "    from typing import Tuple\n",
    "except (NameError, ImportError):\n",
    "    import numpy as np\n",
    "    from typing import Tuple\n",
    "\n",
    "def apply_2d_shift_to_image(img: np.ndarray, shift_x: float, shift_y: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply 2D shift to an image.\n",
    "    \n",
    "    Args:\n",
    "        img: Input image array\n",
    "        shift_x: Shift in X direction (pixels)\n",
    "        shift_y: Shift in Y direction (pixels)\n",
    "        \n",
    "    Returns:\n",
    "        Shifted image\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from scipy.ndimage import shift\n",
    "        use_scipy = True\n",
    "    except ImportError:\n",
    "        use_scipy = False\n",
    "    \n",
    "    if use_scipy:\n",
    "        if len(img.shape) == 3:\n",
    "            # RGB image\n",
    "            shifted = np.zeros_like(img)\n",
    "            for i in range(img.shape[2]):\n",
    "                shifted[:, :, i] = shift(img[:, :, i], (shift_y, shift_x), mode='constant', cval=0, order=1)\n",
    "        else:\n",
    "            # Grayscale\n",
    "            shifted = shift(img, (shift_y, shift_x), mode='constant', cval=0, order=1)\n",
    "    else:\n",
    "        # Fallback: integer shift using numpy\n",
    "        shift_x_int = int(round(shift_x))\n",
    "        shift_y_int = int(round(shift_y))\n",
    "        \n",
    "        if len(img.shape) == 3:\n",
    "            shifted = np.zeros_like(img)\n",
    "            h, w = img.shape[:2]\n",
    "            if shift_y_int >= 0 and shift_x_int >= 0:\n",
    "                shifted[shift_y_int:, shift_x_int:] = img[:h-shift_y_int, :w-shift_x_int]\n",
    "            elif shift_y_int < 0 and shift_x_int < 0:\n",
    "                shifted[:h+shift_y_int, :w+shift_x_int] = img[-shift_y_int:, -shift_x_int:]\n",
    "            else:\n",
    "                # Handle other cases\n",
    "                if shift_y_int >= 0:\n",
    "                    shifted[shift_y_int:, :] = img[:h-shift_y_int, :]\n",
    "                if shift_x_int >= 0:\n",
    "                    shifted[:, shift_x_int:] = img[:, :w-shift_x_int]\n",
    "        else:\n",
    "            shifted = np.zeros_like(img)\n",
    "            h, w = img.shape\n",
    "            if shift_y_int >= 0 and shift_x_int >= 0:\n",
    "                shifted[shift_y_int:, shift_x_int:] = img[:h-shift_y_int, :w-shift_x_int]\n",
    "            elif shift_y_int < 0 and shift_x_int < 0:\n",
    "                shifted[:h+shift_y_int, :w+shift_x_int] = img[-shift_y_int:, -shift_x_int:]\n",
    "    \n",
    "    return shifted\n",
    "\n",
    "# Choose best resolution for registration (prefer full res if available, otherwise use best match count)\n",
    "registered_orthos = {}\n",
    "\n",
    "for ortho_name in ['no_gcps', 'with_gcps']:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Registering {ortho_name}...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Find best resolution (prefer full, then highest match count)\n",
    "    best_res = None\n",
    "    best_matches = 0\n",
    "    \n",
    "    # Use available resolutions from matching_results\n",
    "    available_resolutions = [r for r in matching_results[ortho_name].keys()]\n",
    "    for res_name in available_resolutions:\n",
    "        result = matching_results[ortho_name][res_name]\n",
    "        if result['num_matches'] > best_matches and result['offset_x'] is not None:\n",
    "            best_matches = result['num_matches']\n",
    "            best_res = res_name\n",
    "    \n",
    "    if best_res is None:\n",
    "        print(f\"  \u26a0\ufe0f  No valid matches found for {ortho_name}\")\n",
    "        continue\n",
    "    \n",
    "    result = matching_results[ortho_name][best_res]\n",
    "    print(f\"  Using {best_res} resolution results (matches: {result['num_matches']})\")\n",
    "    \n",
    "    # Get offset scaled to the resolution we'll use for registration\n",
    "    # Scale offsets back to the resolution we're using (half or quarter)\n",
    "    if resolution_used_for_registration == 'half':\n",
    "        scale_factor = 0.5\n",
    "    else:  # quarter\n",
    "        scale_factor = 0.25\n",
    "    \n",
    "    # The offsets from matching are already at the matching resolution\n",
    "    # Scale them to the registration resolution\n",
    "    shift_x = result['offset_x'] / scale_factor if result['offset_x'] is not None else 0\n",
    "    shift_y = result['offset_y'] / scale_factor if result['offset_y'] is not None else 0\n",
    "    \n",
    "    print(f\"  Applying shift: X={shift_x:.2f} px, Y={shift_y:.2f} px\")\n",
    "    \n",
    "    # Load full resolution image\n",
    "    # Load highest available resolution image (prefer half, fallback to quarter)\n",
    "    # Full resolution skipped due to memory constraints\n",
    "    if 'half' in converted_files and ortho_name in converted_files['half']:\n",
    "        ortho_img = converted_files['half'][ortho_name]['img']\n",
    "        resolution_used_for_registration = 'half'\n",
    "    elif 'quarter' in converted_files and ortho_name in converted_files['quarter']:\n",
    "        ortho_img = converted_files['quarter'][ortho_name]['img']\n",
    "        resolution_used_for_registration = 'quarter'\n",
    "    else:\n",
    "        print(f\"  \u26a0\ufe0f  No converted images found for {ortho_name}\")\n",
    "        continue\n",
    "    # Apply shift\n",
    "    shifted_img = apply_2d_shift_to_image(ortho_img, shift_x, shift_y)\n",
    "    \n",
    "    # Save registered image\n",
    "    registered_path = registered_dir / f\"{ortho_name}_registered.jpg\"\n",
    "    \n",
    "    if len(shifted_img.shape) == 3:\n",
    "        img_pil = Image.fromarray(shifted_img)\n",
    "    else:\n",
    "        img_pil = Image.fromarray(shifted_img).convert('RGB')\n",
    "    \n",
    "    img_pil.save(registered_path, 'JPEG', quality=95)\n",
    "    print(f\"  \u2713 Saved registered image: {registered_path}\")\n",
    "    \n",
    "    registered_orthos[ortho_name] = {\n",
    "        'path': registered_path,\n",
    "        'img': shifted_img,\n",
    "        'shift_x': shift_x,\n",
    "        'shift_y': shift_y,\n",
    "        'resolution_used': best_res\n",
    "    }\n",
    "\n",
    "print(f\"\\n\u2713 Registration complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Create Final Visualizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure imports are available\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import cv2\n",
    "    from pathlib import Path\n",
    "except (NameError, ImportError):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import cv2\n",
    "    from pathlib import Path\n",
    "\n",
    "# Create side-by-side comparison: original vs registered\n",
    "for ortho_name in ['no_gcps', 'with_gcps']:\n",
    "    if ortho_name not in registered_orthos:\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nCreating visualization for {ortho_name}...\")\n",
    "    \n",
    "    # Load images (use full resolution)\n",
    "    # Load images (use highest available resolution - half or quarter)\n",
    "    if 'half' in converted_files and ortho_name in converted_files['half']:\n",
    "        resolution_key = 'half'\n",
    "    elif 'quarter' in converted_files and ortho_name in converted_files['quarter']:\n",
    "        resolution_key = 'quarter'\n",
    "    else:\n",
    "        print(f\"  \u26a0\ufe0f  No converted images found for {ortho_name}, skipping visualization\")\n",
    "        continue\n",
    "    \n",
    "    original_img = converted_files[resolution_key][ortho_name]['img']\n",
    "    registered_img = registered_orthos[ortho_name]['img']\n",
    "    basemap_img = converted_files[resolution_key]['basemap']['img']\n",
    "    \n",
    "    # Resize to same size for comparison (use smallest)\n",
    "    min_h = min(original_img.shape[0], registered_img.shape[0], basemap_img.shape[0])\n",
    "    min_w = min(original_img.shape[1], registered_img.shape[1], basemap_img.shape[1])\n",
    "    \n",
    "    original_resized = cv2.resize(original_img, (min_w, min_h))\n",
    "    registered_resized = cv2.resize(registered_img, (min_w, min_h))\n",
    "    basemap_resized = cv2.resize(basemap_img, (min_w, min_h))\n",
    "    \n",
    "    # Create comparison figure\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 16))\n",
    "    fig.suptitle(f'Registration Results: {ortho_name.replace(\"_\", \" \").title()}', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Basemap (ground truth)\n",
    "    axes[0, 0].imshow(basemap_resized)\n",
    "    axes[0, 0].set_title('Ground Truth Basemap', fontweight='bold')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # Original ortho\n",
    "    axes[0, 1].imshow(original_resized)\n",
    "    axes[0, 1].set_title('Original Orthomosaic', fontweight='bold')\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    # Registered ortho\n",
    "    axes[1, 0].imshow(registered_resized)\n",
    "    shift_info = registered_orthos[ortho_name]\n",
    "    title = f\"Registered Orthomosaic\\n\"\n",
    "    title += f\"Shift: ({shift_info['shift_x']:.2f}, {shift_info['shift_y']:.2f}) px\\n\"\n",
    "    title += f\"Resolution: {shift_info['resolution_used']}\"\n",
    "    axes[1, 0].set_title(title, fontweight='bold')\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    # Difference map\n",
    "    diff = np.abs(registered_resized.astype(float) - basemap_resized.astype(float))\n",
    "    diff_norm = (diff / diff.max() * 255).astype(np.uint8) if diff.max() > 0 else diff.astype(np.uint8)\n",
    "    axes[1, 1].imshow(diff_norm, cmap='hot')\n",
    "    axes[1, 1].set_title('Difference Map (Registered vs Basemap)', fontweight='bold')\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    comparison_path = registered_dir / f\"{ortho_name}_comparison.png\"\n",
    "    plt.savefig(comparison_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"  \u2713 Saved comparison: {comparison_path}\")\n",
    "\n",
    "# Save matching results to JSON\n",
    "results_json_path = matching_output_dir / \"matching_results.json\"\n",
    "\n",
    "def convert_to_native(obj):\n",
    "    \"\"\"Convert numpy types to native Python types for JSON.\"\"\"\n",
    "    if isinstance(obj, np.integer):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, np.floating):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: convert_to_native(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_native(item) for item in obj]\n",
    "    elif hasattr(obj, '__dict__'):\n",
    "        # Handle OpenCV keypoints (skip them for JSON)\n",
    "        return None\n",
    "    return obj\n",
    "\n",
    "# Clean results for JSON (remove OpenCV objects)\n",
    "json_results = {}\n",
    "for ortho_name in matching_results:\n",
    "    json_results[ortho_name] = {}\n",
    "    for res_name in matching_results[ortho_name]:\n",
    "        result = matching_results[ortho_name][res_name].copy()\n",
    "        # Remove OpenCV objects\n",
    "        result.pop('kp1', None)\n",
    "        result.pop('kp2', None)\n",
    "        result.pop('good_matches', None)\n",
    "        json_results[ortho_name][res_name] = convert_to_native(result)\n",
    "\n",
    "with open(results_json_path, 'w') as f:\n",
    "    json.dump(json_results, f, indent=2)\n",
    "\n",
    "print(f\"\\n\u2713 Results saved to: {results_json_path}\")\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"\u2713 Feature Matching and Registration Complete!\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}