{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load GCPs - try existing WGS84 files first, otherwise parse CSV\n",
    "import json\n",
    "import csv\n",
    "\n",
    "# Check for existing WGS84 GCP files from ground control comparison\n",
    "gcps_wgs84_geojson = output_dir / \"ground_control_comparison\" / \"gcps_wgs84.geojson\"\n",
    "gcps_wgs84_csv = output_dir / \"ground_control_comparison\" / \"gcps_wgs84.csv\"\n",
    "\n",
    "gcps = []\n",
    "\n",
    "# Try GeoJSON first (preferred)\n",
    "if gcps_wgs84_geojson.exists():\n",
    "    print(f\"Loading GCPs from GeoJSON: {gcps_wgs84_geojson}\")\n",
    "    with open(gcps_wgs84_geojson, 'r') as f:\n",
    "        geojson_data = json.load(f)\n",
    "    \n",
    "    if 'features' in geojson_data:\n",
    "        for feature in geojson_data['features']:\n",
    "            props = feature.get('properties', {})\n",
    "            geom = feature.get('geometry', {})\n",
    "            \n",
    "            if geom.get('type') == 'Point':\n",
    "                coords = geom.get('coordinates', [])\n",
    "                if len(coords) >= 2:\n",
    "                    lon, lat = coords[0], coords[1]\n",
    "                    \n",
    "                    # Get UTM coordinates from properties or convert\n",
    "                    x_utm = props.get('x_utm')\n",
    "                    y_utm = props.get('y_utm')\n",
    "                    \n",
    "                    if x_utm is None or y_utm is None:\n",
    "                        # Convert WGS84 to UTM\n",
    "                        import utm\n",
    "                        x_utm, y_utm, zone_num, zone_letter = utm.from_latlon(lat, lon)\n",
    "                    \n",
    "                    gcps.append({\n",
    "                        'id': props.get('id', props.get('name', f\"GCP_{len(gcps)+1}\")),\n",
    "                        'lat': lat,\n",
    "                        'lon': lon,\n",
    "                        'x_utm': x_utm,\n",
    "                        'y_utm': y_utm\n",
    "                    })\n",
    "    \n",
    "    print(f\"\u2713 Loaded {len(gcps)} GCPs from GeoJSON\")\n",
    "\n",
    "# Try CSV if GeoJSON not found\n",
    "elif gcps_wgs84_csv.exists():\n",
    "    print(f\"Loading GCPs from WGS84 CSV: {gcps_wgs84_csv}\")\n",
    "    with open(gcps_wgs84_csv, 'r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            try:\n",
    "                lat = float(row.get('lat', row.get('latitude', 0)))\n",
    "                lon = float(row.get('lon', row.get('longitude', row.get('lon', 0))))\n",
    "                gcp_id = row.get('id', row.get('name', row.get('label', f\"GCP_{len(gcps)+1}\")))\n",
    "                \n",
    "                # Get UTM from row or convert\n",
    "                x_utm = row.get('x_utm')\n",
    "                y_utm = row.get('y_utm')\n",
    "                \n",
    "                if x_utm:\n",
    "                    x_utm = float(x_utm)\n",
    "                else:\n",
    "                    import utm\n",
    "                    x_utm, y_utm, zone_num, zone_letter = utm.from_latlon(lat, lon)\n",
    "                \n",
    "                if y_utm:\n",
    "                    y_utm = float(y_utm)\n",
    "                else:\n",
    "                    import utm\n",
    "                    x_utm, y_utm, zone_num, zone_letter = utm.from_latlon(lat, lon)\n",
    "                \n",
    "                gcps.append({\n",
    "                    'id': gcp_id,\n",
    "                    'lat': lat,\n",
    "                    'lon': lon,\n",
    "                    'x_utm': x_utm,\n",
    "                    'y_utm': y_utm\n",
    "                })\n",
    "            except (ValueError, KeyError) as e:\n",
    "                print(f\"\u26a0\ufe0f  Skipping row: {e}\")\n",
    "                continue\n",
    "    \n",
    "    print(f\"\u2713 Loaded {len(gcps)} GCPs from WGS84 CSV\")\n",
    "\n",
    "# Fallback to parsing UTM CSV\n",
    "if len(gcps) == 0:\n",
    "    print(f\"\\nNo WGS84 GCP files found, parsing UTM CSV: {gcp_csv_path}\")\n",
    "    gcps = load_gcps_from_csv(gcp_csv_path)\n",
    "    print(f\"\u2713 Loaded {len(gcps)} GCPs from UTM CSV\")\n",
    "\n",
    "if len(gcps) > 0:\n",
    "    print(f\"\\nFirst few GCPs:\")\n",
    "    for gcp in gcps[:3]:\n",
    "        print(f\"  {gcp['id']}: UTM=({gcp['x_utm']:.2f}, {gcp['y_utm']:.2f}), WGS84=({gcp['lat']:.6f}, {gcp['lon']:.6f})\")\n",
    "else:\n",
    "    print(f\"\u26a0\ufe0f  No GCPs loaded!\")\n",
    "    print(f\"   Checked:\")\n",
    "    print(f\"   - {gcps_wgs84_geojson}\")\n",
    "    print(f\"   - {gcps_wgs84_csv}\")\n",
    "    print(f\"   - {gcp_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing opencv-python...\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python in /Users/mauriciohessflores/Library/Python/3.9/lib/python/site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in /Users/mauriciohessflores/Library/Python/3.9/lib/python/site-packages (from opencv-python) (2.0.2)\n",
      "Installing pillow...\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pillow in /Users/mauriciohessflores/Library/Python/3.9/lib/python/site-packages (11.3.0)\n",
      "\u2713 Dependencies installed\n"
     ]
    }
   ],
   "source": [
    "# Install required packages if needed\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "packages = [\n",
    "    'rasterio',\n",
    "    'numpy',\n",
    "    'matplotlib',\n",
    "    'opencv-python',\n",
    "    'scipy',\n",
    "    'utm',\n",
    "    'pillow'\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    try:\n",
    "        __import__(package.replace('-', '_'))\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])\n",
    "\n",
    "print(\"\u2713 Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup - Imports and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 Output directory: outputs/gcp_matching\n",
      "  - Patches: outputs/gcp_matching/patches\n",
      "  - Matches: outputs/gcp_matching/matches\n",
      "  - Registered: outputs/gcp_matching/registered\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.transform import xy\n",
    "from rasterio.warp import transform as transform_coords\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "import json\n",
    "import csv\n",
    "import utm\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup paths\n",
    "data_dir = Path(\"/Users/mauriciohessflores/Documents/Code/Data/New Westminster Oct _25\")\n",
    "output_dir = Path(\"outputs\")\n",
    "\n",
    "# Input files\n",
    "basemap_path = data_dir / \"Michael_RTK_orthos\" / \"TestsiteNewWest_Spexigeo_RTK.tiff\"\n",
    "gcp_csv_path = data_dir / \"25-3288-CONTROL-NAD83-UTM10N-EGM2008.csv\"\n",
    "ortho_no_gcps_path = output_dir / \"orthomosaics\" / \"orthomosaic_no_gcps.tif\"\n",
    "ortho_with_gcps_path = output_dir / \"orthomosaics\" / \"orthomosaic_with_gcps.tif\"\n",
    "\n",
    "# Output directories\n",
    "gcp_matching_dir = output_dir / \"gcp_matching\"\n",
    "gcp_matching_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "patches_dir = gcp_matching_dir / \"patches\"\n",
    "patches_dir.mkdir(exist_ok=True)\n",
    "\n",
    "matches_dir = gcp_matching_dir / \"matches\"\n",
    "matches_dir.mkdir(exist_ok=True)\n",
    "\n",
    "registered_dir = gcp_matching_dir / \"registered\"\n",
    "registered_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"\u2713 Output directory: {gcp_matching_dir}\")\n",
    "print(f\"  - Patches: {patches_dir}\")\n",
    "print(f\"  - Matches: {matches_dir}\")\n",
    "print(f\"  - Registered: {registered_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load GCPs from CSV and Convert to WGS84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GCPs from GeoJSON: outputs/ground_control_comparison/gcps_wgs84.geojson\n",
      "\u2713 Loaded 23 GCPs from GeoJSON\n",
      "\n",
      "First few GCPs:\n",
      "  GCP1: UTM=(506914.12, 5450945.53), WGS84=(49.211262, -122.905068)\n",
      "  GCP2: UTM=(506657.79, 5450730.01), WGS84=(49.209326, -122.908591)\n",
      "  GCP3: UTM=(506577.77, 5450480.01), WGS84=(49.207078, -122.909694)\n"
     ]
    }
   ],
   "source": [
    "# Load GCPs - try existing WGS84 files first, otherwise parse CSV\n",
    "import json\n",
    "\n",
    "# Check for existing WGS84 GCP files from ground control comparison\n",
    "gcps_wgs84_geojson = output_dir / \"ground_control_comparison\" / \"gcps_wgs84.geojson\"\n",
    "gcps_wgs84_csv = output_dir / \"ground_control_comparison\" / \"gcps_wgs84.csv\"\n",
    "\n",
    "gcps = []\n",
    "\n",
    "# Try GeoJSON first (preferred)\n",
    "if gcps_wgs84_geojson.exists():\n",
    "    print(f\"Loading GCPs from GeoJSON: {gcps_wgs84_geojson}\")\n",
    "    with open(gcps_wgs84_geojson, 'r') as f:\n",
    "        geojson_data = json.load(f)\n",
    "    \n",
    "    if 'features' in geojson_data:\n",
    "        for feature in geojson_data['features']:\n",
    "            props = feature.get('properties', {})\n",
    "            geom = feature.get('geometry', {})\n",
    "            \n",
    "            if geom.get('type') == 'Point':\n",
    "                coords = geom.get('coordinates', [])\n",
    "                if len(coords) >= 2:\n",
    "                    lon, lat = coords[0], coords[1]\n",
    "                    \n",
    "                    # Get UTM coordinates from properties or convert\n",
    "                    x_utm = props.get('x_utm')\n",
    "                    y_utm = props.get('y_utm')\n",
    "                    \n",
    "                    if x_utm is None or y_utm is None:\n",
    "                        # Convert WGS84 to UTM\n",
    "                        import utm\n",
    "                        x_utm, y_utm, zone_num, zone_letter = utm.from_latlon(lat, lon)\n",
    "                    \n",
    "                    gcps.append({\n",
    "                        'id': props.get('id', props.get('name', f\"GCP_{len(gcps)+1}\")),\n",
    "                        'lat': lat,\n",
    "                        'lon': lon,\n",
    "                        'x_utm': float(x_utm),\n",
    "                        'y_utm': float(y_utm)\n",
    "                    })\n",
    "    \n",
    "    print(f\"\u2713 Loaded {len(gcps)} GCPs from GeoJSON\")\n",
    "\n",
    "# Try CSV if GeoJSON not found\n",
    "elif gcps_wgs84_csv.exists():\n",
    "    print(f\"Loading GCPs from WGS84 CSV: {gcps_wgs84_csv}\")\n",
    "    with open(gcps_wgs84_csv, 'r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            try:\n",
    "                lat = float(row.get('lat', row.get('latitude', 0)))\n",
    "                lon = float(row.get('lon', row.get('longitude', row.get('lon', 0))))\n",
    "                gcp_id = row.get('id', row.get('name', row.get('label', f\"GCP_{len(gcps)+1}\")))\n",
    "                \n",
    "                # Get UTM from row or convert\n",
    "                x_utm_str = row.get('x_utm', '')\n",
    "                y_utm_str = row.get('y_utm', '')\n",
    "                \n",
    "                if x_utm_str and y_utm_str:\n",
    "                    x_utm = float(x_utm_str)\n",
    "                    y_utm = float(y_utm_str)\n",
    "                else:\n",
    "                    import utm\n",
    "                    x_utm, y_utm, zone_num, zone_letter = utm.from_latlon(lat, lon)\n",
    "                \n",
    "                gcps.append({\n",
    "                    'id': gcp_id,\n",
    "                    'lat': lat,\n",
    "                    'lon': lon,\n",
    "                    'x_utm': x_utm,\n",
    "                    'y_utm': y_utm\n",
    "                })\n",
    "            except (ValueError, KeyError) as e:\n",
    "                print(f\"\u26a0\ufe0f  Skipping row: {e}\")\n",
    "                continue\n",
    "    \n",
    "    print(f\"\u2713 Loaded {len(gcps)} GCPs from WGS84 CSV\")\n",
    "\n",
    "# Fallback to parsing UTM CSV\n",
    "if len(gcps) == 0:\n",
    "    print(f\"\\nNo WGS84 GCP files found, parsing UTM CSV: {gcp_csv_path}\")\n",
    "    gcps = load_gcps_from_csv(gcp_csv_path)\n",
    "    print(f\"\u2713 Loaded {len(gcps)} GCPs from UTM CSV\")\n",
    "\n",
    "if len(gcps) > 0:\n",
    "    print(f\"\\nFirst few GCPs:\")\n",
    "    for gcp in gcps[:3]:\n",
    "        print(f\"  {gcp['id']}: UTM=({gcp['x_utm']:.2f}, {gcp['y_utm']:.2f}), WGS84=({gcp['lat']:.6f}, {gcp['lon']:.6f})\")\n",
    "else:\n",
    "    print(f\"\u26a0\ufe0f  No GCPs loaded!\")\n",
    "    print(f\"   Checked:\")\n",
    "    print(f\"   - {gcps_wgs84_geojson}\")\n",
    "    print(f\"   - {gcps_wgs84_csv}\")\n",
    "    print(f\"   - {gcp_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Convert GCPs to Pixel Coordinates in Basemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basemap CRS: EPSG:32610\n",
      "Basemap dimensions: 90129x90188\n",
      "Basemap bounds: BoundingBox(left=506424.37839793676, bottom=5450017.622213458, right=507501.0951215451, top=5451095.043774429)\n",
      "Basemap transform: | 0.01, 0.00, 506424.38|\n",
      "| 0.00,-0.01, 5451095.04|\n",
      "| 0.00, 0.00, 1.00|\n",
      "\n",
      "GCP GCP1: UTM=(506914.12, 5450945.53)\n",
      "  \u2713 Found at pixel: col=40995, row=12515\n",
      "\n",
      "GCP GCP2: UTM=(506657.79, 5450730.01)\n",
      "  \u2713 Found at pixel: col=19538, row=30556\n",
      "\n",
      "GCP GCP3: UTM=(506577.77, 5450480.01)\n",
      "  \u2713 Found at pixel: col=12840, row=51482\n",
      "\n",
      "GCP GCP4: UTM=(506765.03, 5450578.63)\n",
      "  \u2713 Found at pixel: col=28515, row=43227\n",
      "\n",
      "GCP GCP5: UTM=(506926.13, 5450715.96)\n",
      "  \u2713 Found at pixel: col=42000, row=31732\n",
      "\n",
      "GCP GCP6: UTM=(507071.92, 5450992.66)\n",
      "  \u2713 Found at pixel: col=54203, row=8570\n",
      "\n",
      "GCP GCP7: UTM=(507089.40, 5450794.23)\n",
      "  \u2713 Found at pixel: col=55667, row=25180\n",
      "\n",
      "GCP GCP8: UTM=(507315.01, 5450717.85)\n",
      "  \u2713 Found at pixel: col=74551, row=31574\n",
      "\n",
      "GCP GCP9: UTM=(507252.65, 5450536.03)\n",
      "  \u2713 Found at pixel: col=69332, row=46793\n",
      "\n",
      "GCP GCP10: UTM=(507072.02, 5450500.33)\n",
      "  \u2713 Found at pixel: col=54212, row=49782\n",
      "\n",
      "GCP GCP11: UTM=(507020.05, 5450595.29)\n",
      "  \u2713 Found at pixel: col=49861, row=41832\n",
      "\n",
      "GCP GCP12: UTM=(506885.91, 5450346.64)\n",
      "  \u2713 Found at pixel: col=38633, row=62646\n",
      "\n",
      "GCP GCP13: UTM=(506586.74, 5450323.69)\n",
      "  \u2713 Found at pixel: col=13590, row=64568\n",
      "\n",
      "GCP GCP14: UTM=(506746.87, 5450378.55)\n",
      "  \u2713 Found at pixel: col=26994, row=59975\n",
      "\n",
      "GCP GCP15: UTM=(506903.07, 5450193.68)\n",
      "  \u2713 Found at pixel: col=40069, row=75450\n",
      "\n",
      "GCP GCP16: UTM=(506977.00, 5450109.82)\n",
      "  \u2713 Found at pixel: col=46258, row=82470\n",
      "\n",
      "GCP CP1: UTM=(507060.63, 5450345.17)\n",
      "  \u2713 Found at pixel: col=53258, row=62769\n",
      "\n",
      "GCP CP2: UTM=(506911.89, 5450506.71)\n",
      "  \u2713 Found at pixel: col=40808, row=49247\n",
      "\n",
      "GCP CP3: UTM=(506821.64, 5450292.79)\n",
      "  \u2713 Found at pixel: col=33254, row=67154\n",
      "\n",
      "GCP CP4: UTM=(507148.30, 5450712.13)\n",
      "  \u2713 Found at pixel: col=60597, row=32052\n",
      "\n",
      "GCP CP5: UTM=(506800.86, 5450859.45)\n",
      "  \u2713 Found at pixel: col=31514, row=19720\n",
      "\n",
      "GCP OMON 6076: UTM=(506864.18, 5450326.10)\n",
      "  \u2713 Found at pixel: col=36814, row=64366\n",
      "\n",
      "GCP OMON 6066: UTM=(507163.74, 5450716.44)\n",
      "  \u2713 Found at pixel: col=61889, row=31691\n",
      "\n",
      "\u2713 Found 23 GCPs within basemap bounds\n",
      "\n",
      "First few GCP pixel coordinates:\n",
      "  GCP1: col=40995, row=12515\n",
      "  GCP2: col=19538, row=30556\n",
      "  GCP3: col=12840, row=51482\n"
     ]
    }
   ],
   "source": [
    "# Convert GCPs (UTM) to pixel coordinates in basemap\n",
    "def gcp_to_pixel_coords_from_utm(gcp_x_utm: float, gcp_y_utm: float, raster_path: Path) -> Optional[Tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    Convert GCP UTM coordinates to pixel coordinates in raster.\n",
    "    \n",
    "    Args:\n",
    "        gcp_x_utm: UTM Easting (EPSG:32610)\n",
    "        gcp_y_utm: UTM Northing (EPSG:32610)\n",
    "        raster_path: Path to raster file\n",
    "    \n",
    "    Returns:\n",
    "        (col, row) or None if outside bounds.\n",
    "    \"\"\"\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        # Raster should be in EPSG:32610 (UTM Zone 10N)\n",
    "        if src.crs != 'EPSG:32610':\n",
    "            # Transform UTM to raster CRS if needed\n",
    "            x, y = transform_coords(\n",
    "                'EPSG:32610',\n",
    "                src.crs,\n",
    "                [gcp_x_utm],\n",
    "                [gcp_y_utm]\n",
    "            )\n",
    "            utm_x, utm_y = x[0], y[0]\n",
    "        else:\n",
    "            utm_x, utm_y = gcp_x_utm, gcp_y_utm\n",
    "        \n",
    "        # Convert to pixel coordinates\n",
    "        row, col = rasterio.transform.rowcol(src.transform, utm_x, utm_y)\n",
    "        \n",
    "        # Check if within bounds\n",
    "        if 0 <= row < src.height and 0 <= col < src.width:\n",
    "            return (col, row)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "# Get basemap CRS and transform\n",
    "with rasterio.open(basemap_path) as basemap_src:\n",
    "    basemap_crs = basemap_src.crs\n",
    "    basemap_transform = basemap_src.transform\n",
    "    basemap_width = basemap_src.width\n",
    "    basemap_height = basemap_src.height\n",
    "    basemap_bounds = basemap_src.bounds\n",
    "\n",
    "print(f\"Basemap CRS: {basemap_crs}\")\n",
    "print(f\"Basemap dimensions: {basemap_width}x{basemap_height}\")\n",
    "print(f\"Basemap bounds: {basemap_bounds}\")\n",
    "print(f\"Basemap transform: {basemap_transform}\")\n",
    "\n",
    "# Convert all GCPs to pixel coordinates\n",
    "gcp_pixel_coords = {}\n",
    "for gcp in gcps:\n",
    "    # Debug: show GCP UTM coordinates\n",
    "    print(f\"\\nGCP {gcp['id']}: UTM=({gcp['x_utm']:.2f}, {gcp['y_utm']:.2f})\")\n",
    "    \n",
    "    pixel_coords = gcp_to_pixel_coords_from_utm(gcp['x_utm'], gcp['y_utm'], basemap_path)\n",
    "    if pixel_coords:\n",
    "        gcp_pixel_coords[gcp['id']] = {\n",
    "            'gcp': gcp,\n",
    "            'pixel_col': pixel_coords[0],\n",
    "            'pixel_row': pixel_coords[1],\n",
    "            'utm_x': gcp.get('x_utm'),\n",
    "            'utm_y': gcp.get('y_utm'),\n",
    "        }\n",
    "        print(f\"  \u2713 Found at pixel: col={pixel_coords[0]}, row={pixel_coords[1]}\")\n",
    "    else:\n",
    "        # Debug: show why it's outside bounds\n",
    "        with rasterio.open(basemap_path) as src:\n",
    "            row, col = rasterio.transform.rowcol(src.transform, gcp['x_utm'], gcp['y_utm'])\n",
    "            print(f\"  \u26a0\ufe0f  Outside bounds: col={col}, row={row}\")\n",
    "            print(f\"     Basemap: {src.width}x{src.height}\")\n",
    "            print(f\"     Basemap bounds: {src.bounds}\")\n",
    "            # Check if coordinates are in bounds in UTM space\n",
    "            in_x = src.bounds.left <= gcp['x_utm'] <= src.bounds.right\n",
    "            in_y = src.bounds.bottom <= gcp['y_utm'] <= src.bounds.top\n",
    "            print(f\"     UTM X in bounds: {in_x} ({src.bounds.left:.2f} <= {gcp['x_utm']:.2f} <= {src.bounds.right:.2f})\")\n",
    "            print(f\"     UTM Y in bounds: {in_y} ({src.bounds.bottom:.2f} <= {gcp['y_utm']:.2f} <= {src.bounds.top:.2f})\")\n",
    "\n",
    "print(f\"\\n\u2713 Found {len(gcp_pixel_coords)} GCPs within basemap bounds\")\n",
    "if len(gcp_pixel_coords) > 0:\n",
    "    print(f\"\\nFirst few GCP pixel coordinates:\")\n",
    "    for gcp_id, coords in list(gcp_pixel_coords.items())[:3]:\n",
    "        print(f\"  {gcp_id}: col={coords['pixel_col']}, row={coords['pixel_row']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Extract Patches from Basemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 Extracted 23 patches of size 29x29\n",
      "\u2713 Extracted 23 patches of size 39x39\n",
      "\u2713 Extracted 23 patches of size 49x49\n",
      "\u2713 Extracted 23 patches of size 59x59\n",
      "\n",
      "\u2713 Patch extraction complete!\n"
     ]
    }
   ],
   "source": [
    "# Extract patches from basemap centered on GCPs\n",
    "def extract_patch(raster_path: Path, center_col: int, center_row: int, patch_size: int) -> Optional[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Extract a patch from raster centered on given pixel coordinates.\n",
    "    \n",
    "    Args:\n",
    "        raster_path: Path to raster file\n",
    "        center_col: Center column (x)\n",
    "        center_row: Center row (y)\n",
    "        patch_size: Size of patch (must be odd, e.g., 29, 39, 49)\n",
    "    \n",
    "    Returns:\n",
    "        Patch array (H, W, C) or None if out of bounds\n",
    "    \"\"\"\n",
    "    half_size = patch_size // 2\n",
    "    \n",
    "    with rasterio.open(raster_path) as src:\n",
    "        # Calculate bounds\n",
    "        col_start = max(0, center_col - half_size)\n",
    "        col_end = min(src.width, center_col + half_size + 1)\n",
    "        row_start = max(0, center_row - half_size)\n",
    "        row_end = min(src.height, center_row + half_size + 1)\n",
    "        \n",
    "        # Check if patch would be out of bounds\n",
    "        if col_end - col_start < patch_size or row_end - row_start < patch_size:\n",
    "            return None\n",
    "        \n",
    "        # Read patch\n",
    "        patch = src.read(\n",
    "            window=rasterio.windows.Window(col_start, row_start, col_end - col_start, row_end - row_start)\n",
    "        )\n",
    "        \n",
    "        # Transpose to (H, W, C) format\n",
    "        if len(patch.shape) == 3:\n",
    "            patch = np.transpose(patch, (1, 2, 0))\n",
    "        \n",
    "        # If single band, convert to 3-channel grayscale\n",
    "        if len(patch.shape) == 2:\n",
    "            patch = np.stack([patch, patch, patch], axis=-1)\n",
    "        \n",
    "        return patch\n",
    "\n",
    "def create_gcp_patch_visualization(\n",
    "    patch: np.ndarray,\n",
    "    patch_size: int,\n",
    "    output_path: Path\n",
    "):\n",
    "    \"\"\"\n",
    "    Create visualization of patch with GCP location marked.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.patches as mpatches\n",
    "    \n",
    "    # Normalize patch if needed\n",
    "    if patch.dtype != np.uint8:\n",
    "        patch_min = patch.min()\n",
    "        patch_max = patch.max()\n",
    "        if patch_max > patch_min:\n",
    "            patch = ((patch - patch_min) / (patch_max - patch_min) * 255).astype(np.uint8)\n",
    "        else:\n",
    "            patch = np.zeros_like(patch, dtype=np.uint8)\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    ax.imshow(patch)\n",
    "    \n",
    "    # Mark center (GCP location) with bright red dot\n",
    "    center_row, center_col = patch.shape[0] // 2, patch.shape[1] // 2\n",
    "    ax.plot(center_col, center_row, 'ro', markersize=15, markeredgewidth=2, markeredgecolor='white')\n",
    "    \n",
    "    # Draw yellow square around patch boundary\n",
    "    rect = mpatches.Rectangle(\n",
    "        (0, 0), patch.shape[1], patch.shape[0],\n",
    "        linewidth=3, edgecolor='yellow', facecolor='none'\n",
    "    )\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "    ax.set_title(f'Matched Patch ({patch_size}x{patch_size})', fontsize=14, fontweight='bold')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Extract patches for different patch sizes\n",
    "patch_sizes = [29, 39, 49, 59]  # Try different sizes\n",
    "basemap_patches = {}\n",
    "\n",
    "for patch_size in patch_sizes:\n",
    "    basemap_patches[patch_size] = {}\n",
    "    \n",
    "    for gcp_id, coords in gcp_pixel_coords.items():\n",
    "        patch = extract_patch(\n",
    "            basemap_path,\n",
    "            coords['pixel_col'],\n",
    "            coords['pixel_row'],\n",
    "            patch_size\n",
    "        )\n",
    "        \n",
    "        if patch is not None:\n",
    "            basemap_patches[patch_size][gcp_id] = patch\n",
    "            \n",
    "            # Save patch as image for visualization\n",
    "            patch_path = patches_dir / f\"basemap_{gcp_id}_{patch_size}x{patch_size}.png\"\n",
    "            plt.imsave(patch_path, patch.astype(np.uint8))\n",
    "    \n",
    "    print(f\"\u2713 Extracted {len(basemap_patches[patch_size])} patches of size {patch_size}x{patch_size}\")\n",
    "\n",
    "print(f\"\\n\u2713 Patch extraction complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Reproject Orthomosaics to Match Basemap CRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found existing reprojected file: outputs/test_matching/reprojected/no_gcps_reprojected.tif\n",
      "  \u2713 Already exists: outputs/gcp_matching/reprojected/no_gcps_reprojected.tif\n",
      "\n",
      "Found existing reprojected file: outputs/test_matching/reprojected/with_gcps_reprojected.tif\n",
      "  \u2713 Already exists: outputs/gcp_matching/reprojected/with_gcps_reprojected.tif\n",
      "\n",
      "\u2713 Reprojection complete!\n"
     ]
    }
   ],
   "source": [
    "from rasterio.warp import calculate_default_transform, reproject, Resampling, transform_bounds\n",
    "from rasterio.transform import from_bounds\n",
    "from rasterio.enums import Resampling as RasterioResampling\n",
    "from affine import Affine\n",
    "\n",
    "# Reproject orthos to match basemap CRS and resolution\n",
    "def reproject_ortho_to_basemap(ortho_path: Path, basemap_path: Path, output_path: Path) -> Path:\n",
    "    \"\"\"\n",
    "    Reproject orthomosaic to match basemap CRS and bounds.\n",
    "    Uses manual transform construction to avoid CPLE_AppDefinedError.\n",
    "    \"\"\"\n",
    "    if output_path.exists():\n",
    "        print(f\"  \u2713 Already reprojected: {output_path}\")\n",
    "        return output_path\n",
    "    \n",
    "    with rasterio.open(basemap_path) as basemap_src:\n",
    "        target_crs = basemap_src.crs\n",
    "        target_bounds = basemap_src.bounds\n",
    "        target_transform = basemap_src.transform\n",
    "        target_width = basemap_src.width\n",
    "        target_height = basemap_src.height\n",
    "    \n",
    "    with rasterio.open(ortho_path) as ortho_src:\n",
    "        source_crs = ortho_src.crs\n",
    "        source_bounds = ortho_src.bounds\n",
    "        \n",
    "        if source_crs == target_crs:\n",
    "            print(f\"  \u2713 Already in target CRS\")\n",
    "            import shutil\n",
    "            shutil.copy(ortho_path, output_path)\n",
    "            return output_path\n",
    "        \n",
    "        # Transform source bounds to target CRS\n",
    "        print(f\"  Transforming source bounds to target CRS...\")\n",
    "        src_bounds_target_crs = transform_bounds(\n",
    "            source_crs, target_crs,\n",
    "            source_bounds.left, source_bounds.bottom,\n",
    "            source_bounds.right, source_bounds.top\n",
    "        )\n",
    "        \n",
    "        print(f\"  Source bounds in target CRS: {src_bounds_target_crs}\")\n",
    "        \n",
    "        # Get target pixel size\n",
    "        target_pixel_size_x = abs(target_transform[0])\n",
    "        target_pixel_size_y = abs(target_transform[4])\n",
    "        \n",
    "        # Use intersection of bounds\n",
    "        output_left = max(src_bounds_target_crs[0], target_bounds.left)\n",
    "        output_bottom = max(src_bounds_target_crs[1], target_bounds.bottom)\n",
    "        output_right = min(src_bounds_target_crs[2], target_bounds.right)\n",
    "        output_top = min(src_bounds_target_crs[3], target_bounds.top)\n",
    "        \n",
    "        print(f\"  Output bounds (intersection): left={output_left:.2f}, bottom={output_bottom:.2f}, right={output_right:.2f}, top={output_top:.2f}\")\n",
    "        \n",
    "        # Validate bounds\n",
    "        if output_right <= output_left or output_top <= output_bottom:\n",
    "            raise ValueError(f\"Invalid output bounds: width={output_right-output_left}, height={output_top-output_bottom}\")\n",
    "        \n",
    "        # Calculate dimensions using target pixel size\n",
    "        width = int((output_right - output_left) / target_pixel_size_x)\n",
    "        height = int((output_top - output_bottom) / target_pixel_size_y)\n",
    "        \n",
    "        # Validate dimensions\n",
    "        if width <= 0 or height <= 0:\n",
    "            raise ValueError(f\"Invalid dimensions: width={width}, height={height}\")\n",
    "        \n",
    "        # Create transform for output\n",
    "        transform = Affine.translation(output_left, output_top) * Affine.scale(target_pixel_size_x, -target_pixel_size_y)\n",
    "        \n",
    "        print(f\"  \u2713 Transform calculated: {width}x{height} pixels\")\n",
    "        \n",
    "        # Read source data\n",
    "        source_data = ortho_src.read()\n",
    "        source_count = ortho_src.count\n",
    "        \n",
    "        # Reproject\n",
    "        reprojected_data = np.zeros((source_count, height, width), dtype=source_data.dtype)\n",
    "        \n",
    "        for band_idx in range(1, source_count + 1):\n",
    "            reproject(\n",
    "                source=rasterio.band(ortho_src, band_idx),\n",
    "                destination=reprojected_data[band_idx - 1],\n",
    "                src_transform=ortho_src.transform,\n",
    "                src_crs=source_crs,\n",
    "                dst_transform=transform,\n",
    "                dst_crs=target_crs,\n",
    "                resampling=Resampling.bilinear\n",
    "            )\n",
    "        \n",
    "        # Save\n",
    "        with rasterio.open(\n",
    "            output_path,\n",
    "            'w',\n",
    "            driver='GTiff',\n",
    "            height=height,\n",
    "            width=width,\n",
    "            count=source_count,\n",
    "            dtype=reprojected_data.dtype,\n",
    "            crs=target_crs,\n",
    "            transform=transform,\n",
    "            compress='lzw',\n",
    "            BIGTIFF='YES',\n",
    "            tiled=True,\n",
    "            blockxsize=512,\n",
    "            blockysize=512\n",
    "        ) as dst:\n",
    "            dst.write(reprojected_data)\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "# Check for existing reprojected files from test_matching notebook\n",
    "existing_reprojected_dir = output_dir / \"test_matching\" / \"reprojected\"\n",
    "reprojected_dir = gcp_matching_dir / \"reprojected\"\n",
    "reprojected_dir.mkdir(exist_ok=True)\n",
    "\n",
    "ortho_paths = {\n",
    "    'no_gcps': ortho_no_gcps_path,\n",
    "    'with_gcps': ortho_with_gcps_path\n",
    "}\n",
    "\n",
    "reprojected_paths = {}\n",
    "for ortho_name, ortho_path in ortho_paths.items():\n",
    "    if not ortho_path.exists():\n",
    "        print(f\"\u26a0\ufe0f  Ortho not found: {ortho_path}\")\n",
    "        continue\n",
    "    \n",
    "    # Check for existing reprojected file from test_matching\n",
    "    existing_reprojected = existing_reprojected_dir / f\"{ortho_name}_reprojected.tif\"\n",
    "    if existing_reprojected.exists():\n",
    "        print(f\"\\nFound existing reprojected file: {existing_reprojected}\")\n",
    "        # Copy to our directory\n",
    "        import shutil\n",
    "        reprojected_path = reprojected_dir / f\"{ortho_name}_reprojected.tif\"\n",
    "        if not reprojected_path.exists():\n",
    "            shutil.copy(existing_reprojected, reprojected_path)\n",
    "            print(f\"  \u2713 Copied to: {reprojected_path}\")\n",
    "        else:\n",
    "            print(f\"  \u2713 Already exists: {reprojected_path}\")\n",
    "        reprojected_paths[ortho_name] = reprojected_path\n",
    "        continue\n",
    "    \n",
    "    # Otherwise, reproject\n",
    "    print(f\"\\nReprojecting {ortho_name}...\")\n",
    "    reprojected_path = reproject_ortho_to_basemap(\n",
    "        ortho_path,\n",
    "        basemap_path,\n",
    "        reprojected_dir / f\"{ortho_name}_reprojected.tif\"\n",
    "    )\n",
    "    reprojected_paths[ortho_name] = reprojected_path\n",
    "\n",
    "print(f\"\\n\u2713 Reprojection complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Find GCP Patches in Orthomosaics Using Template Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Finding GCPs in no_gcps orthomosaic\n",
      "============================================================\n",
      "  Patch size 29x29: 22/23 matches\n",
      "  Patch size 39x39: 21/23 matches\n",
      "  Patch size 49x49: 21/23 matches\n",
      "  Patch size 59x59: 21/23 matches\n",
      "\n",
      "  \u2713 Best patch size: 29x29 (22 matches)\n",
      "  Saving matching patches to outputs/gcp_matching/matching_patches/no_gcps...\n",
      "  \u2713 Saved 22 matching patches\n",
      "\n",
      "============================================================\n",
      "Finding GCPs in with_gcps orthomosaic\n",
      "============================================================\n",
      "  Patch size 29x29: 22/23 matches\n",
      "  Patch size 39x39: 22/23 matches\n",
      "  Patch size 49x49: 21/23 matches\n",
      "  Patch size 59x59: 21/23 matches\n",
      "\n",
      "  \u2713 Best patch size: 29x29 (22 matches)\n",
      "  Saving matching patches to outputs/gcp_matching/matching_patches/with_gcps...\n",
      "  \u2713 Saved 22 matching patches\n",
      "\n",
      "\u2713 Patch matching complete!\n",
      "\n",
      "Creating visualization of GCP matches...\n",
      "  \u2713 Visualization already exists: outputs/gcp_matching/matches/gcp_matching_visualization_no_gcps.png\n",
      "  Skipping visualization creation...\n",
      "  \u2713 Visualization already exists: outputs/gcp_matching/matches/gcp_matching_visualization_with_gcps.png\n",
      "  Skipping visualization creation...\n"
     ]
    }
   ],
   "source": [
    "# Find GCP patches in orthomosaics using template matching\n",
    "def find_patch_in_ortho(\n",
    "    template_patch: np.ndarray,\n",
    "    ortho_path: Path,\n",
    "    search_center_col: int,\n",
    "    search_center_row: int,\n",
    "    search_radius: int = 500  # Search within this radius (pixels)\n",
    ") -> Optional[Tuple[int, int, float]]:\n",
    "    \"\"\"\n",
    "    Find template patch in orthomosaic using template matching.\n",
    "    \n",
    "    Returns:\n",
    "        (col, row, confidence) or None if not found\n",
    "    \"\"\"\n",
    "    # Convert template to grayscale if needed\n",
    "    if len(template_patch.shape) == 3:\n",
    "        template_gray = cv2.cvtColor(template_patch.astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        template_gray = template_patch.astype(np.uint8)\n",
    "    \n",
    "    with rasterio.open(ortho_path) as ortho_src:\n",
    "        # Define search window\n",
    "        search_col_start = max(0, search_center_col - search_radius)\n",
    "        search_col_end = min(ortho_src.width, search_center_col + search_radius)\n",
    "        search_row_start = max(0, search_center_row - search_radius)\n",
    "        search_row_end = min(ortho_src.height, search_center_row + search_radius)\n",
    "        \n",
    "        # Read search region\n",
    "        search_window = rasterio.windows.Window(\n",
    "            search_col_start,\n",
    "            search_row_start,\n",
    "            search_col_end - search_col_start,\n",
    "            search_row_end - search_row_start\n",
    "        )\n",
    "        \n",
    "        search_region = ortho_src.read(window=search_window)\n",
    "        \n",
    "        # Convert to (H, W, C) and then grayscale\n",
    "        if len(search_region.shape) == 3:\n",
    "            search_region = np.transpose(search_region, (1, 2, 0))\n",
    "            if search_region.shape[2] == 1:\n",
    "                search_gray = search_region[:, :, 0]\n",
    "            else:\n",
    "                search_gray = cv2.cvtColor(search_region.astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "        else:\n",
    "            search_gray = search_region\n",
    "        \n",
    "        # Normalize to uint8\n",
    "        if search_gray.dtype != np.uint8:\n",
    "            search_min = search_gray.min()\n",
    "            search_max = search_gray.max()\n",
    "            if search_max > search_min:\n",
    "                search_gray = ((search_gray - search_min) / (search_max - search_min) * 255).astype(np.uint8)\n",
    "            else:\n",
    "                search_gray = np.zeros_like(search_gray, dtype=np.uint8)\n",
    "        \n",
    "        # Template matching\n",
    "        result = cv2.matchTemplate(search_gray, template_gray, cv2.TM_CCOEFF_NORMED)\n",
    "        \n",
    "        # Find best match\n",
    "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "        \n",
    "        # Convert back to global coordinates\n",
    "        match_col = search_col_start + max_loc[0] + template_gray.shape[1] // 2\n",
    "        match_row = search_row_start + max_loc[1] + template_gray.shape[0] // 2\n",
    "        \n",
    "        # Return if confidence is high enough\n",
    "        if max_val > 0.5:  # Threshold for match confidence\n",
    "            return (match_col, match_row, float(max_val))\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "# Find GCPs in each orthomosaic\n",
    "# Create directory for matching patches\n",
    "matching_patches_dir = gcp_matching_dir / \"matching_patches\"\n",
    "matching_patches_dir.mkdir(exist_ok=True)\n",
    "matching_patches_dir.mkdir(exist_ok=True)\n",
    "\n",
    "matching_results = {}\n",
    "\n",
    "for ortho_name, reprojected_path in reprojected_paths.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Finding GCPs in {ortho_name} orthomosaic\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    matching_results[ortho_name] = {}\n",
    "    \n",
    "                # Convert GCP UTM coordinates to pixel coordinates in THIS ortho\n",
    "                # The ortho may have different dimensions/transform than basemap\n",
    "    with rasterio.open(reprojected_path) as ortho_src:\n",
    "        ortho_transform = ortho_src.transform\n",
    "    \n",
    "    # Try different patch sizes\n",
    "    best_patch_size = None\n",
    "    best_matches = 0\n",
    "    \n",
    "    for patch_size in patch_sizes:\n",
    "        matches_found = 0\n",
    "        \n",
    "        for gcp_id, coords in gcp_pixel_coords.items():\n",
    "            if gcp_id not in basemap_patches[patch_size]:\n",
    "                continue\n",
    "            \n",
    "            template = basemap_patches[patch_size][gcp_id]\n",
    "            \n",
    "            # Convert GCP UTM coordinates to pixel coordinates in THIS ortho\n",
    "            # The ortho may have different dimensions/transform than basemap\n",
    "            gcp_utm_x = coords.get('utm_x') or coords.get('x_utm')\n",
    "            gcp_utm_y = coords.get('utm_y') or coords.get('y_utm')\n",
    "            \n",
    "            if gcp_utm_x is not None and gcp_utm_y is not None:\n",
    "                # Convert UTM to pixel coordinates using ortho's transform\n",
    "                expected_col, expected_row = ~ortho_transform * (gcp_utm_x, gcp_utm_y)\n",
    "                expected_col = int(expected_col)\n",
    "                expected_row = int(expected_row)\n",
    "            else:\n",
    "                # Fallback: use pixel coordinates from basemap (less accurate)\n",
    "                expected_col = coords['pixel_col']\n",
    "                expected_row = coords['pixel_row']\n",
    "                \n",
    "                if gcp_utm_x is not None and gcp_utm_y is not None:\n",
    "                    # Convert UTM to pixel coordinates using ortho's transform\n",
    "                    expected_col, expected_row = ~ortho_transform * (gcp_utm_x, gcp_utm_y)\n",
    "                    expected_col = int(expected_col)\n",
    "                    expected_row = int(expected_row)\n",
    "                else:\n",
    "                    # Fallback: use pixel coordinates from basemap (less accurate)\n",
    "                    expected_row = coords['pixel_row']\n",
    "            \n",
    "            # Search for patch\n",
    "            match = find_patch_in_ortho(\n",
    "                template,\n",
    "                reprojected_path,\n",
    "                expected_col,\n",
    "                expected_row,\n",
    "                search_radius=500\n",
    "            )\n",
    "            \n",
    "            if match:\n",
    "                match_col, match_row, confidence = match\n",
    "                matches_found += 1\n",
    "                \n",
    "                if gcp_id not in matching_results[ortho_name]:\n",
    "                    matching_results[ortho_name][gcp_id] = {}\n",
    "                \n",
    "                matching_results[ortho_name][gcp_id][patch_size] = {\n",
    "                    'expected_col': expected_col,\n",
    "                    'expected_row': expected_row,\n",
    "                    'matched_col': match_col,\n",
    "                    'matched_row': match_row,\n",
    "                    'offset_col': match_col - expected_col,\n",
    "                    'offset_row': match_row - expected_row,\n",
    "                    'confidence': confidence\n",
    "                }\n",
    "        \n",
    "        print(f\"  Patch size {patch_size}x{patch_size}: {matches_found}/{len(gcp_pixel_coords)} matches\")\n",
    "        \n",
    "        if matches_found > best_matches:\n",
    "            best_matches = matches_found\n",
    "            best_patch_size = patch_size\n",
    "    \n",
    "    print(f\"\\n  \u2713 Best patch size: {best_patch_size}x{best_patch_size} ({best_matches} matches)\")\n",
    "\n",
    "    # Create subdirectory for this ortho's matching patches\n",
    "    ortho_patches_dir = matching_patches_dir / ortho_name\n",
    "    ortho_patches_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # Save matching patches for visual verification\n",
    "    print(f\"  Saving matching patches to {ortho_patches_dir}...\")\n",
    "    for gcp_id, match_data in matching_results[ortho_name].items():\n",
    "        if best_patch_size in match_data:\n",
    "            match = match_data[best_patch_size]\n",
    "            \n",
    "            # Extract patch from ortho at matched location\n",
    "            matched_col = match['matched_col']\n",
    "            matched_row = match['matched_row']\n",
    "            \n",
    "            # Extract patch (same size as template)\n",
    "            patch = extract_patch(\n",
    "                reprojected_path,\n",
    "                matched_col,\n",
    "                matched_row,\n",
    "                best_patch_size\n",
    "            )\n",
    "            \n",
    "            if patch is not None:\n",
    "                # Normalize patch for saving\n",
    "                if patch.dtype != np.uint8:\n",
    "                    patch_min = patch.min()\n",
    "                    patch_max = patch.max()\n",
    "                    if patch_max > patch_min:\n",
    "                        patch = ((patch - patch_min) / (patch_max - patch_min) * 255).astype(np.uint8)\n",
    "                    else:\n",
    "                        patch = np.zeros_like(patch, dtype=np.uint8)\n",
    "                \n",
    "                # Save matching patch\n",
    "                match_patch_path = ortho_patches_dir / f\"{gcp_id}_{best_patch_size}x{best_patch_size}_matched.png\"\n",
    "                plt.imsave(match_patch_path, patch)\n",
    "                \n",
    "                # Also create visualization with GCP location marked\n",
    "                vis_patch_path = ortho_patches_dir / f\"{gcp_id}_{best_patch_size}x{best_patch_size}_matched_vis.png\"\n",
    "                create_gcp_patch_visualization(patch, best_patch_size, vis_patch_path)\n",
    "    \n",
    "    print(f\"  \u2713 Saved {len([g for g in matching_results[ortho_name].keys() if best_patch_size in matching_results[ortho_name][g]])} matching patches\")\n",
    "\n",
    "print(f\"\\n\u2713 Patch matching complete!\")\n",
    "\n",
    "# Create comprehensive visualization\n",
    "print(f\"\\nCreating visualization of GCP matches...\")\n",
    "\n",
    "def create_gcp_matching_visualization(\n",
    "    basemap_path: Path,\n",
    "    ortho_paths: Dict[str, Path],\n",
    "    gcp_pixel_coords: Dict,\n",
    "    matching_results: Dict,\n",
    "    output_path: Path,\n",
    "    max_dimension: int = 4000\n",
    "):\n",
    "    \"\"\"\n",
    "    Create visualization showing basemap with GCPs and orthos with matched patches.\n",
    "    \"\"\"\n",
    "    # Load basemap\n",
    "    with rasterio.open(basemap_path) as src:\n",
    "        basemap_data = src.read()\n",
    "        basemap_transform = src.transform\n",
    "        \n",
    "        # Convert to (H, W, C)\n",
    "        if len(basemap_data.shape) == 3:\n",
    "            basemap_img = np.transpose(basemap_data, (1, 2, 0))\n",
    "            if basemap_img.shape[2] == 1:\n",
    "                basemap_img = np.stack([basemap_img[:, :, 0]] * 3, axis=-1)\n",
    "            elif basemap_img.shape[2] == 4:\n",
    "                basemap_img = basemap_img[:, :, :3]  # Take RGB\n",
    "        else:\n",
    "            basemap_img = np.stack([basemap_data] * 3, axis=-1)\n",
    "        \n",
    "        # Normalize to uint8\n",
    "        if basemap_img.dtype != np.uint8:\n",
    "            basemap_min = basemap_img.min()\n",
    "            basemap_max = basemap_img.max()\n",
    "            if basemap_max > basemap_min:\n",
    "                basemap_img = ((basemap_img - basemap_min) / (basemap_max - basemap_min) * 255).astype(np.uint8)\n",
    "            else:\n",
    "                basemap_img = np.zeros_like(basemap_img, dtype=np.uint8)\n",
    "    \n",
    "    # Downsample if too large\n",
    "    h, w = basemap_img.shape[:2]\n",
    "    if max(h, w) > max_dimension:\n",
    "        scale = max_dimension / max(h, w)\n",
    "        new_h, new_w = int(h * scale), int(w * scale)\n",
    "        basemap_img = cv2.resize(basemap_img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "        scale_factor = scale\n",
    "    else:\n",
    "        scale_factor = 1.0\n",
    "    \n",
    "    # Load orthos and create panels\n",
    "    num_orthos = len(ortho_paths)\n",
    "    fig, axes = plt.subplots(1, num_orthos + 1, figsize=(8 * (num_orthos + 1), 8))\n",
    "    \n",
    "    # Basemap panel (left)\n",
    "    ax = axes[0]\n",
    "    basemap_display = basemap_img.copy()\n",
    "    \n",
    "    # Draw GCP positions on basemap\n",
    "    for gcp_id, coords in gcp_pixel_coords.items():\n",
    "        # Scale coordinates\n",
    "        col = int(coords['pixel_col'] * scale_factor)\n",
    "        row = int(coords['pixel_row'] * scale_factor)\n",
    "        \n",
    "        if 0 <= row < basemap_display.shape[0] and 0 <= col < basemap_display.shape[1]:\n",
    "            # Draw red circle\n",
    "            cv2.circle(basemap_display, (col, row), 10, (255, 0, 0), 3)\n",
    "    \n",
    "    ax.imshow(basemap_display)\n",
    "    ax.set_title('Basemap with GCP Locations', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Add GCP labels\n",
    "    for gcp_id, coords in gcp_pixel_coords.items():\n",
    "        col = int(coords['pixel_col'] * scale_factor)\n",
    "        row = int(coords['pixel_row'] * scale_factor)\n",
    "        if 0 <= row < basemap_display.shape[0] and 0 <= col < basemap_display.shape[1]:\n",
    "            ax.text(col, row - 15, gcp_id, color='red', fontsize=8, fontweight='bold',\n",
    "                   ha='center', va='bottom')\n",
    "    \n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Ortho panels (right)\n",
    "    for ortho_idx, (ortho_name, ortho_path) in enumerate(ortho_paths.items(), 1):\n",
    "        ax = axes[ortho_idx]\n",
    "        \n",
    "        # Load ortho\n",
    "        with rasterio.open(ortho_path) as src:\n",
    "            ortho_data = src.read()\n",
    "            \n",
    "            # Convert to (H, W, C)\n",
    "            if len(ortho_data.shape) == 3:\n",
    "                ortho_img = np.transpose(ortho_data, (1, 2, 0))\n",
    "                if ortho_img.shape[2] == 1:\n",
    "                    ortho_img = np.stack([ortho_img[:, :, 0]] * 3, axis=-1)\n",
    "                elif ortho_img.shape[2] == 4:\n",
    "                    ortho_img = ortho_img[:, :, :3]\n",
    "            else:\n",
    "                ortho_img = np.stack([ortho_data] * 3, axis=-1)\n",
    "            \n",
    "            # Normalize\n",
    "            if ortho_img.dtype != np.uint8:\n",
    "                ortho_min = ortho_img.min()\n",
    "                ortho_max = ortho_img.max()\n",
    "                if ortho_max > ortho_min:\n",
    "                    ortho_img = ((ortho_img - ortho_min) / (ortho_max - ortho_min) * 255).astype(np.uint8)\n",
    "                else:\n",
    "                    ortho_img = np.zeros_like(ortho_img, dtype=np.uint8)\n",
    "        \n",
    "        # Downsample if too large\n",
    "        h, w = ortho_img.shape[:2]\n",
    "        if max(h, w) > max_dimension:\n",
    "            scale = max_dimension / max(h, w)\n",
    "            new_h, new_w = int(h * scale), int(w * scale)\n",
    "            ortho_img = cv2.resize(ortho_img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "            ortho_scale = scale\n",
    "        else:\n",
    "            ortho_scale = 1.0\n",
    "        \n",
    "        ortho_display = ortho_img.copy()\n",
    "        \n",
    "        # Draw matched patch centers\n",
    "        if ortho_name in matching_results:\n",
    "            for gcp_id, match_data in matching_results[ortho_name].items():\n",
    "                # Get best patch size match\n",
    "                best_patch_size = max(match_data.keys()) if match_data else None\n",
    "                if best_patch_size:\n",
    "                    match = match_data[best_patch_size]\n",
    "                    matched_col = int(match['matched_col'] * ortho_scale)\n",
    "                    matched_row = int(match['matched_row'] * ortho_scale)\n",
    "                    \n",
    "                    if 0 <= matched_row < ortho_display.shape[0] and 0 <= matched_col < ortho_display.shape[1]:\n",
    "                        # Draw yellow circle\n",
    "                        cv2.circle(ortho_display, (matched_col, matched_row), 10, (255, 255, 0), 3)\n",
    "        \n",
    "        ax.imshow(ortho_display)\n",
    "        ax.set_title(f'{ortho_name.replace(\"_\", \" \").title()} with Matched Patches', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Add labels\n",
    "        if ortho_name in matching_results:\n",
    "            for gcp_id, match_data in matching_results[ortho_name].items():\n",
    "                best_patch_size = max(match_data.keys()) if match_data else None\n",
    "                if best_patch_size:\n",
    "                    match = match_data[best_patch_size]\n",
    "                    matched_col = int(match['matched_col'] * ortho_scale)\n",
    "                    matched_row = int(match['matched_row'] * ortho_scale)\n",
    "                    if 0 <= matched_row < ortho_display.shape[0] and 0 <= matched_col < ortho_display.shape[1]:\n",
    "                        ax.text(matched_col, matched_row - 15, gcp_id, color='yellow', fontsize=8, fontweight='bold',\n",
    "                               ha='center', va='bottom')\n",
    "        \n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight', format='PNG')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"\u2713 Visualization saved: {output_path}\")\n",
    "\n",
    "# Create visualization for each ortho\n",
    "for ortho_name in reprojected_paths.keys():\n",
    "    if ortho_name not in matching_results:\n",
    "        continue\n",
    "    \n",
    "    vis_path = matches_dir / f\"gcp_matching_visualization_{ortho_name}.png\"\n",
    "\n",
    "    # Check if visualization already exists\n",
    "    if vis_path.exists():\n",
    "        print(f\"  \u2713 Visualization already exists: {vis_path}\")\n",
    "        print(f\"  Skipping visualization creation...\")\n",
    "        continue\n",
    "\n",
    "    \n",
    "    create_gcp_matching_visualization(\n",
    "        basemap_path,\n",
    "        {ortho_name: reprojected_paths[ortho_name]},\n",
    "        gcp_pixel_coords,\n",
    "        matching_results,\n",
    "        vis_path,\n",
    "        max_dimension=4000\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Compute 2D Shift or Affine Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 matching_results found in memory\n",
      "\n",
      "Match pixel locations:\n",
      "  GCP1: Expected=(40448.0, 12515.0), \n",
      "         Matched=(40283.0, 12461.0), \n",
      "         Offset=(-165.0, -54.0) px\n",
      "         Distance: 2.074 m (207.40 cm)\n",
      "  GCP2: Expected=(18991.0, 30556.0), \n",
      "         Matched=(18917.0, 30106.0), \n",
      "         Offset=(-74.0, -450.0) px\n",
      "         Distance: 5.448 m (544.81 cm)\n",
      "  GCP3: Expected=(12293.0, 51482.0), \n",
      "         Matched=(12039.0, 51450.0), \n",
      "         Offset=(-254.0, -32.0) px\n",
      "         Distance: 3.058 m (305.84 cm)\n",
      "  GCP4: Expected=(27968.0, 43227.0), \n",
      "         Matched=(28406.0, 42917.0), \n",
      "         Offset=(438.0, -310.0) px\n",
      "         Distance: 6.410 m (641.05 cm)\n",
      "  GCP5: Expected=(41453.0, 31732.0), \n",
      "         Matched=(41275.0, 31680.0), \n",
      "         Offset=(-178.0, -52.0) px\n",
      "         Distance: 2.215 m (221.53 cm)\n",
      "  GCP6: Expected=(53656.0, 8570.0), \n",
      "         Matched=(53528.0, 8495.0), \n",
      "         Offset=(-128.0, -75.0) px\n",
      "         Distance: 1.772 m (177.23 cm)\n",
      "  GCP7: Expected=(55120.0, 25180.0), \n",
      "         Matched=(54975.0, 25113.0), \n",
      "         Offset=(-145.0, -67.0) px\n",
      "         Distance: 1.908 m (190.82 cm)\n",
      "  GCP8: Expected=(74004.0, 31574.0), \n",
      "         Matched=(73877.0, 31460.0), \n",
      "         Offset=(-127.0, -114.0) px\n",
      "         Distance: 2.039 m (203.88 cm)\n",
      "  GCP10: Expected=(53665.0, 49782.0), \n",
      "         Matched=(53491.0, 49702.0), \n",
      "         Offset=(-174.0, -80.0) px\n",
      "         Distance: 2.288 m (228.79 cm)\n",
      "  GCP11: Expected=(49314.0, 41832.0), \n",
      "         Matched=(49141.0, 41766.0), \n",
      "         Offset=(-173.0, -66.0) px\n",
      "         Distance: 2.212 m (221.20 cm)\n",
      "  GCP12: Expected=(38086.0, 62646.0), \n",
      "         Matched=(38091.0, 62940.0), \n",
      "         Offset=(5.0, 294.0) px\n",
      "         Distance: 3.513 m (351.27 cm)\n",
      "  GCP13: Expected=(13043.0, 64568.0), \n",
      "         Matched=(12795.0, 64508.0), \n",
      "         Offset=(-248.0, -60.0) px\n",
      "         Distance: 3.048 m (304.82 cm)\n",
      "  GCP14: Expected=(26447.0, 59975.0), \n",
      "         Matched=(26223.0, 59914.0), \n",
      "         Offset=(-224.0, -61.0) px\n",
      "         Distance: 2.773 m (277.34 cm)\n",
      "  GCP15: Expected=(39522.0, 75450.0), \n",
      "         Matched=(39282.0, 75325.0), \n",
      "         Offset=(-240.0, -125.0) px\n",
      "         Distance: 3.233 m (323.27 cm)\n",
      "  GCP16: Expected=(45711.0, 82470.0), \n",
      "         Matched=(45460.0, 82311.0), \n",
      "         Offset=(-251.0, -159.0) px\n",
      "         Distance: 3.550 m (354.95 cm)\n",
      "  CP1: Expected=(52711.0, 62769.0), \n",
      "         Matched=(52934.0, 62323.0), \n",
      "         Offset=(223.0, -446.0) px\n",
      "         Distance: 5.957 m (595.70 cm)\n",
      "  CP2: Expected=(40261.0, 49247.0), \n",
      "         Matched=(40065.0, 49189.0), \n",
      "         Offset=(-196.0, -58.0) px\n",
      "         Distance: 2.442 m (244.19 cm)\n",
      "  CP3: Expected=(32707.0, 67154.0), \n",
      "         Matched=(32478.0, 67072.0), \n",
      "         Offset=(-229.0, -82.0) px\n",
      "         Distance: 2.906 m (290.58 cm)\n",
      "  CP4: Expected=(60050.0, 32052.0), \n",
      "         Matched=(59843.0, 31887.0), \n",
      "         Offset=(-207.0, -165.0) px\n",
      "         Distance: 3.162 m (316.24 cm)\n",
      "  CP5: Expected=(30967.0, 19720.0), \n",
      "         Matched=(30932.0, 19556.0), \n",
      "         Offset=(-35.0, -164.0) px\n",
      "         Distance: 2.003 m (200.33 cm)\n",
      "  OMON 6076: Expected=(36267.0, 64366.0), \n",
      "         Matched=(36196.0, 64097.0), \n",
      "         Offset=(-71.0, -269.0) px\n",
      "         Distance: 3.324 m (332.36 cm)\n",
      "  OMON 6066: Expected=(61342.0, 31691.0), \n",
      "         Matched=(60889.0, 31688.0), \n",
      "         Offset=(-453.0, -3.0) px\n",
      "         Distance: 5.412 m (541.18 cm)\n",
      "\n",
      "============================================================\n",
      "Computing transformation for no_gcps\n",
      "============================================================\n",
      "\n",
      "2D Shift:\n",
      "  Shift X: -165.89 px\n",
      "  Shift Y: -81.22 px\n",
      "  RMSE: 30.68 px\n",
      "  Points: 9\n",
      "\n",
      "Affine Transformation:\n",
      "  RMSE: 28.65 px\n",
      "  Points: 9\n",
      "  \u2713 Using affine transformation (lower RMSE)\n",
      "\n",
      "Match pixel locations:\n",
      "  GCP1: Expected=(40548.0, 12515.0), \n",
      "         Matched=(40385.0, 12461.0), \n",
      "         Offset=(-163.0, -54.0) px\n",
      "         Distance: 2.051 m (205.13 cm)\n",
      "  GCP2: Expected=(19092.0, 30556.0), \n",
      "         Matched=(19092.0, 30300.0), \n",
      "         Offset=(0.0, -256.0) px\n",
      "         Distance: 3.058 m (305.83 cm)\n",
      "  GCP3: Expected=(12393.0, 51482.0), \n",
      "         Matched=(12140.0, 51449.0), \n",
      "         Offset=(-253.0, -33.0) px\n",
      "         Distance: 3.048 m (304.80 cm)\n",
      "  GCP4: Expected=(28068.0, 43227.0), \n",
      "         Matched=(28507.0, 42916.0), \n",
      "         Offset=(439.0, -311.0) px\n",
      "         Distance: 6.427 m (642.71 cm)\n",
      "  GCP5: Expected=(41553.0, 31732.0), \n",
      "         Matched=(41377.0, 31680.0), \n",
      "         Offset=(-176.0, -52.0) px\n",
      "         Distance: 2.192 m (219.24 cm)\n",
      "  GCP6: Expected=(53757.0, 8570.0), \n",
      "         Matched=(53630.0, 8495.0), \n",
      "         Offset=(-127.0, -75.0) px\n",
      "         Distance: 1.762 m (176.20 cm)\n",
      "  GCP7: Expected=(55220.0, 25180.0), \n",
      "         Matched=(55076.0, 25114.0), \n",
      "         Offset=(-144.0, -66.0) px\n",
      "         Distance: 1.892 m (189.24 cm)\n",
      "  GCP8: Expected=(74105.0, 31574.0), \n",
      "         Matched=(73978.0, 31461.0), \n",
      "         Offset=(-127.0, -113.0) px\n",
      "         Distance: 2.031 m (203.08 cm)\n",
      "  GCP10: Expected=(53766.0, 49782.0), \n",
      "         Matched=(53591.0, 49702.0), \n",
      "         Offset=(-175.0, -80.0) px\n",
      "         Distance: 2.299 m (229.87 cm)\n",
      "  GCP11: Expected=(49415.0, 41832.0), \n",
      "         Matched=(49242.0, 41766.0), \n",
      "         Offset=(-173.0, -66.0) px\n",
      "         Distance: 2.212 m (221.20 cm)\n",
      "  GCP12: Expected=(38187.0, 62646.0), \n",
      "         Matched=(38192.0, 62939.0), \n",
      "         Offset=(5.0, 293.0) px\n",
      "         Distance: 3.501 m (350.08 cm)\n",
      "  GCP13: Expected=(13144.0, 64568.0), \n",
      "         Matched=(12897.0, 64506.0), \n",
      "         Offset=(-247.0, -62.0) px\n",
      "         Distance: 3.042 m (304.23 cm)\n",
      "  GCP14: Expected=(26548.0, 59975.0), \n",
      "         Matched=(26324.0, 59913.0), \n",
      "         Offset=(-224.0, -62.0) px\n",
      "         Distance: 2.777 m (277.66 cm)\n",
      "  GCP15: Expected=(39623.0, 75450.0), \n",
      "         Matched=(39383.0, 75324.0), \n",
      "         Offset=(-240.0, -126.0) px\n",
      "         Distance: 3.238 m (323.82 cm)\n",
      "  GCP16: Expected=(45811.0, 82470.0), \n",
      "         Matched=(45560.0, 82310.0), \n",
      "         Offset=(-251.0, -160.0) px\n",
      "         Distance: 3.556 m (355.60 cm)\n",
      "  CP1: Expected=(52812.0, 62769.0), \n",
      "         Matched=(53034.0, 62323.0), \n",
      "         Offset=(222.0, -446.0) px\n",
      "         Distance: 5.952 m (595.17 cm)\n",
      "  CP2: Expected=(40362.0, 49247.0), \n",
      "         Matched=(40167.0, 49189.0), \n",
      "         Offset=(-195.0, -58.0) px\n",
      "         Distance: 2.430 m (243.04 cm)\n",
      "  CP3: Expected=(32807.0, 67154.0), \n",
      "         Matched=(32579.0, 67071.0), \n",
      "         Offset=(-228.0, -83.0) px\n",
      "         Distance: 2.899 m (289.86 cm)\n",
      "  CP4: Expected=(60150.0, 32052.0), \n",
      "         Matched=(59944.0, 31888.0), \n",
      "         Offset=(-206.0, -164.0) px\n",
      "         Distance: 3.146 m (314.56 cm)\n",
      "  CP5: Expected=(31067.0, 19720.0), \n",
      "         Matched=(31034.0, 19556.0), \n",
      "         Offset=(-33.0, -164.0) px\n",
      "         Distance: 1.998 m (199.85 cm)\n",
      "  OMON 6076: Expected=(36368.0, 64366.0), \n",
      "         Matched=(36803.0, 64380.0), \n",
      "         Offset=(435.0, 14.0) px\n",
      "         Distance: 5.199 m (519.94 cm)\n",
      "  OMON 6066: Expected=(61443.0, 31691.0), \n",
      "         Matched=(60990.0, 31689.0), \n",
      "         Offset=(-453.0, -2.0) px\n",
      "         Distance: 5.412 m (541.18 cm)\n",
      "\n",
      "============================================================\n",
      "Computing transformation for with_gcps\n",
      "============================================================\n",
      "\n",
      "2D Shift:\n",
      "  Shift X: -145.89 px\n",
      "  Shift Y: -80.89 px\n",
      "  RMSE: 40.24 px\n",
      "  Points: 9\n",
      "\n",
      "Affine Transformation:\n",
      "  RMSE: 48.93 px\n",
      "  Points: 9\n",
      "  \u2713 Using 2D shift (lower RMSE)\n",
      "\n",
      "\u2713 Transformations saved to: outputs/gcp_matching/matches/transformations.json\n"
     ]
    }
   ],
   "source": [
    "# Check for required variables and set defaults if needed\n",
    "try:\n",
    "    _ = output_dir\n",
    "except NameError:\n",
    "    from pathlib import Path\n",
    "    output_dir = Path(\"outputs\")\n",
    "    print(f\"output_dir not defined, using default: {output_dir}\")\n",
    "\n",
    "try:\n",
    "    _ = matches_dir\n",
    "except NameError:\n",
    "    try:\n",
    "        _ = gcp_matching_dir\n",
    "    except NameError:\n",
    "        gcp_matching_dir = output_dir / \"gcp_matching\"\n",
    "    matches_dir = gcp_matching_dir / \"matches\"\n",
    "    matches_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"matches_dir not defined, using default: {matches_dir}\")\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "from typing import Tuple, Dict\n",
    "\n",
    "# Compute transformation from matches\n",
    "\n",
    "def remove_outliers_ransac(src_points: np.ndarray, dst_points: np.ndarray, threshold: float = 50.0, min_samples: int = 3) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Remove outliers using RANSAC-based approach.\n",
    "    \n",
    "    Returns:\n",
    "        (inlier_src, inlier_dst, inlier_mask)\n",
    "    \"\"\"\n",
    "    if len(src_points) < 3:\n",
    "        # Return original arrays with all True mask\n",
    "        mask = np.ones(len(src_points), dtype=bool)\n",
    "        return src_points, dst_points, mask\n",
    "        return src_points, dst_points, np.ones(len(src_points), dtype=bool)\n",
    "    \n",
    "    # Compute initial shift (mean offset)\n",
    "    offsets = dst_points - src_points\n",
    "    mean_offset = np.mean(offsets, axis=0)\n",
    "    \n",
    "    # Compute distances from mean offset\n",
    "    distances = np.linalg.norm(offsets - mean_offset, axis=1)\n",
    "    \n",
    "    # Use IQR method to identify outliers\n",
    "    q1 = np.percentile(distances, 25)\n",
    "    q3 = np.percentile(distances, 75)\n",
    "    iqr = q3 - q1\n",
    "    \n",
    "    # Outlier threshold: Q3 + 1.5 * IQR\n",
    "    outlier_threshold = q3 + 1.5 * iqr\n",
    "    \n",
    "    # Also use absolute threshold\n",
    "    inlier_mask = (distances <= outlier_threshold) & (distances <= threshold)\n",
    "    \n",
    "    # Ensure we have at least min_samples inliers\n",
    "    if np.sum(inlier_mask) < min_samples:\n",
    "        # Keep the min_samples points closest to the mean\n",
    "        sorted_indices = np.argsort(distances)\n",
    "        inlier_mask = np.zeros(len(src_points), dtype=bool)\n",
    "        inlier_mask[sorted_indices[:min_samples]] = True\n",
    "    \n",
    "    # Ensure inlier_mask is a proper boolean array\n",
    "    inlier_mask = np.asarray(inlier_mask, dtype=bool)\n",
    "    \n",
    "    # Return filtered points\n",
    "    return src_points[inlier_mask], dst_points[inlier_mask], inlier_mask\n",
    "\n",
    "def compute_transformation(matches: Dict, use_affine: bool = False) -> Dict:\n",
    "    \"\"\"\n",
    "    Compute 2D shift or affine transformation from GCP matches.\n",
    "    \n",
    "    Args:\n",
    "        matches: Dictionary with GCP matches\n",
    "        use_affine: If True, compute affine transformation; otherwise 2D shift\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with transformation parameters\n",
    "    \"\"\"\n",
    "    # Collect source and destination points\n",
    "    src_points = []\n",
    "    dst_points = []\n",
    "    \n",
    "    for gcp_id, match_data in matches.items():\n",
    "        # Use the best patch size match\n",
    "        best_patch_size = max(match_data.keys())\n",
    "        match = match_data[best_patch_size]\n",
    "        \n",
    "        src_points.append([match['expected_col'], match['expected_row']])\n",
    "        dst_points.append([match['matched_col'], match['matched_row']])\n",
    "    \n",
    "    src_points = np.array(src_points, dtype=np.float32)\n",
    "\n",
    "    dst_points = np.array(dst_points, dtype=np.float32)\n",
    "\n",
    "    # Remove outliers\n",
    "    src_points, dst_points, inlier_mask = remove_outliers_ransac(src_points, dst_points, threshold=100.0, min_samples=3)\n",
    "    \n",
    "    num_outliers = len(src_points) - np.sum(inlier_mask) if 'inlier_mask' in locals() else 0\n",
    "    num_outliers = len(src_points) - np.sum(inlier_mask) if inlier_mask is not None else 0\n",
    "    if num_outliers > 0:\n",
    "        print(f\"  Removed {num_outliers} outlier(s)\")\n",
    "    dst_points = np.array(dst_points, dtype=np.float32)\n",
    "    \n",
    "    if len(src_points) < 3:\n",
    "        # Return original arrays with all True mask\n",
    "        mask = np.ones(len(src_points), dtype=bool)\n",
    "        return {'type': 'insufficient_points', 'error': 'Need at least 2 matches'}\n",
    "    \n",
    "    if use_affine and len(src_points) >= 3:\n",
    "        # Compute affine transformation (6 parameters)\n",
    "        # Requires at least 3 points\n",
    "        transform_matrix = cv2.getAffineTransform(\n",
    "            src_points[:3],\n",
    "            dst_points[:3]\n",
    "        )\n",
    "        \n",
    "        # Apply to all points to compute error\n",
    "        ones = np.ones((len(src_points), 1))\n",
    "        src_homogeneous = np.hstack([src_points, ones])\n",
    "        transformed = (transform_matrix @ src_homogeneous.T).T\n",
    "        \n",
    "        errors = dst_points - transformed\n",
    "        rmse = float(np.sqrt(np.mean(errors**2)))\n",
    "        \n",
    "        return {\n",
    "            'type': 'affine',\n",
    "            'matrix': transform_matrix.tolist(),\n",
    "            'rmse': rmse,\n",
    "            'num_points': len(src_points)\n",
    "        }\n",
    "    else:\n",
    "        # Compute 2D shift (mean offset)\n",
    "        offsets = dst_points - src_points\n",
    "        shift_x = float(np.mean(offsets[:, 0]))\n",
    "        shift_y = float(np.mean(offsets[:, 1]))\n",
    "        \n",
    "        # Compute RMSE\n",
    "        errors = offsets - np.array([shift_x, shift_y])\n",
    "        rmse = float(np.sqrt(np.mean(errors**2)))\n",
    "        \n",
    "        return {\n",
    "            'type': 'shift',\n",
    "            'shift_x': shift_x,\n",
    "            'shift_y': shift_y,\n",
    "            'rmse': rmse,\n",
    "            'num_points': len(src_points)\n",
    "        }\n",
    "\n",
    "# Compute transformations for each ortho\n",
    "transformations = {}\n",
    "\n",
    "\n",
    "# Check if matching_results is defined, load from file if not\n",
    "try:\n",
    "    _ = matching_results\n",
    "    print(\"\u2713 matching_results found in memory\")\n",
    "except NameError:\n",
    "    print(\"matching_results not in memory, attempting to load from file...\")\n",
    "    try:\n",
    "        matches_json = matches_dir / \"matching_results.json\"\n",
    "        if matches_json.exists():\n",
    "            with open(matches_json, 'r') as f:\n",
    "                matching_results = json.load(f)\n",
    "            print(f\"\u2713 Loaded matching_results from {matches_json}\")\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"matching_results.json not found at {matches_json}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\u274c Could not load matching_results: {e}\")\n",
    "        print(\"Please run Step 6 (patch matching) first.\")\n",
    "        raise\n",
    "\n",
    "for ortho_name in matching_results.keys():\n",
    "\n",
    "    # Print match pixel locations for verification\n",
    "\n",
    "    # Get ortho transform for distance calculation\n",
    "    with rasterio.open(reprojected_paths[ortho_name]) as ortho_src:\n",
    "        ortho_transform = ortho_src.transform\n",
    "\n",
    "    print(f\"\\nMatch pixel locations:\")\n",
    "    for gcp_id, match_data in matching_results[ortho_name].items():\n",
    "        best_patch_size = max(match_data.keys()) if match_data else None\n",
    "        if best_patch_size:\n",
    "            match = match_data[best_patch_size]\n",
    "            print(f\"  {gcp_id}: Expected=({match['expected_col']:.1f}, {match['expected_row']:.1f}), \")\n",
    "            print(f\"         Matched=({match['matched_col']:.1f}, {match['matched_row']:.1f}), \")\n",
    "            print(f\"         Offset=({match['offset_col']:.1f}, {match['offset_row']:.1f}) px\")\n",
    "\n",
    "            # Calculate Euclidean distance in meters\n",
    "            # Convert pixel coordinates to UTM coordinates\n",
    "            from rasterio.transform import xy\n",
    "            \n",
    "            # Expected position in UTM\n",
    "            expected_utm_x, expected_utm_y = xy(ortho_transform, match['expected_row'], match['expected_col'])\n",
    "            \n",
    "            # Matched position in UTM\n",
    "            matched_utm_x, matched_utm_y = xy(ortho_transform, match['matched_row'], match['matched_col'])\n",
    "            \n",
    "            # Calculate Euclidean distance in meters\n",
    "            distance_m = np.sqrt((matched_utm_x - expected_utm_x)**2 + (matched_utm_y - expected_utm_y)**2)\n",
    "            distance_cm = distance_m * 100\n",
    "            \n",
    "            print(f\"         Distance: {distance_m:.3f} m ({distance_cm:.2f} cm)\")\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Computing transformation for {ortho_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Try 2D shift first\n",
    "    shift_result = compute_transformation(matching_results[ortho_name], use_affine=False)\n",
    "    print(f\"\\n2D Shift:\")\n",
    "    shift_x_val = shift_result.get('shift_x', 'N/A')\n",
    "    shift_x_str = f\"{shift_x_val:.2f}\" if isinstance(shift_x_val, (int, float)) else str(shift_x_val)\n",
    "    print(f\"  Shift X: {shift_x_str} px\")\n",
    "    shift_y_val = shift_result.get('shift_y', 'N/A')\n",
    "    shift_y_str = f\"{shift_y_val:.2f}\" if isinstance(shift_y_val, (int, float)) else str(shift_y_val)\n",
    "    print(f\"  Shift Y: {shift_y_str} px\")\n",
    "    rmse_val = shift_result.get('rmse', 'N/A')\n",
    "    rmse_str = f\"{rmse_val:.2f}\" if isinstance(rmse_val, (int, float)) else str(rmse_val)\n",
    "    print(f\"  RMSE: {rmse_str} px\")\n",
    "    print(f\"  Points: {shift_result.get('num_points', 0)}\")\n",
    "    \n",
    "    # Try affine if we have enough points\n",
    "    # Try affine if we have enough points\n",
    "    if len(matching_results[ortho_name]) >= 3:\n",
    "        affine_result = compute_transformation(matching_results[ortho_name], use_affine=True)\n",
    "        print(f\"\\nAffine Transformation:\")\n",
    "        affine_rmse_val = affine_result.get('rmse', 'N/A')\n",
    "\n",
    "        affine_rmse_str = f\"{affine_rmse_val:.2f}\" if isinstance(affine_rmse_val, (int, float)) else str(affine_rmse_val)\n",
    "\n",
    "        print(f\"  RMSE: {affine_rmse_str} px\")\n",
    "        print(f\"  Points: {affine_result.get('num_points', 0)}\")\n",
    "\n",
    "        # Use the one with lower RMSE\n",
    "        if affine_result.get('rmse', float('inf')) < shift_result.get('rmse', float('inf')):\n",
    "            transformations[ortho_name] = affine_result\n",
    "            print(f\"  \u2713 Using affine transformation (lower RMSE)\")\n",
    "        else:\n",
    "            transformations[ortho_name] = shift_result\n",
    "            print(f\"  \u2713 Using 2D shift (lower RMSE)\")\n",
    "    else:\n",
    "        transformations[ortho_name] = shift_result\n",
    "        print(f\"  \u2713 Using 2D shift (insufficient points for affine)\")\n",
    "\n",
    "transformations_file = matches_dir / \"transformations.json\"\n",
    "\n",
    "with open(transformations_file, 'w') as f:\n",
    "    json.dump(transformations, f, indent=2)\n",
    "\n",
    "print(f\"\\n\u2713 Transformations saved to: {transformations_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Apply Transformation and Register Orthomosaics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Registering no_gcps...\n"
     ]
    }
   ],
   "source": [
    "# Apply transformation to orthomosaic\n",
    "def apply_transformation(\n",
    "    ortho_path: Path,\n",
    "    transformation: Dict,\n",
    "    output_path: Path,\n",
    "    basemap_path: Path\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    Apply transformation to register orthomosaic to basemap.\n",
    "    \"\"\"\n",
    "    with rasterio.open(basemap_path) as basemap_src:\n",
    "        target_width = basemap_src.width\n",
    "        target_height = basemap_src.height\n",
    "        target_transform = basemap_src.transform\n",
    "        target_crs = basemap_src.crs\n",
    "    \n",
    "    with rasterio.open(ortho_path) as ortho_src:\n",
    "        source_data = ortho_src.read()\n",
    "        source_count = ortho_src.count\n",
    "        \n",
    "        # Apply transformation\n",
    "        if transformation['type'] == 'shift':\n",
    "            # Apply 2D shift using scipy\n",
    "            shift_x = transformation['shift_x']\n",
    "            shift_y = transformation['shift_y']\n",
    "            \n",
    "            registered_data = np.zeros((source_count, target_height, target_width), dtype=source_data.dtype)\n",
    "            \n",
    "            for band_idx in range(source_count):\n",
    "                shifted = ndimage.shift(\n",
    "                    source_data[band_idx],\n",
    "                    (shift_y, shift_x),\n",
    "                    mode='constant',\n",
    "                    cval=0,\n",
    "                    order=1\n",
    "                )\n",
    "                \n",
    "                # Crop or pad to match target dimensions\n",
    "                if shifted.shape[0] > target_height:\n",
    "                    shifted = shifted[:target_height, :]\n",
    "                elif shifted.shape[0] < target_height:\n",
    "                    padded = np.zeros((target_height, shifted.shape[1]), dtype=shifted.dtype)\n",
    "                    padded[:shifted.shape[0], :] = shifted\n",
    "                    shifted = padded\n",
    "                \n",
    "                if shifted.shape[1] > target_width:\n",
    "                    shifted = shifted[:, :target_width]\n",
    "                elif shifted.shape[1] < target_width:\n",
    "                    padded = np.zeros((target_height, target_width), dtype=shifted.dtype)\n",
    "                    padded[:, :shifted.shape[1]] = shifted\n",
    "                    shifted = padded\n",
    "                \n",
    "                registered_data[band_idx] = shifted\n",
    "        \n",
    "        elif transformation['type'] == 'affine':\n",
    "            transform_matrix = np.array(transformation['matrix'], dtype=np.float32)\n",
    "            \n",
    "            # Extract transformation components\n",
    "            # OpenCV format: [[a, b, c], [d, e, f]]\n",
    "            # scipy.ndimage uses matrix format: [[a, b], [d, e]] and offset [c, f]\n",
    "            matrix_2x2 = transform_matrix[:2, :2]  # [[a, b], [d, e]]\n",
    "            offset = transform_matrix[:2, 2]  # [c, f]\n",
    "            \n",
    "            # Create output array\n",
    "            registered_data = np.zeros((source_count, target_height, target_width), dtype=source_data.dtype)\n",
    "            \n",
    "            # Apply transformation per band\n",
    "            for band_idx in range(source_count):\n",
    "                # scipy.ndimage.affine_transform expects (matrix, offset)\n",
    "                # Note: scipy uses (row, col) convention, so we need to transpose\n",
    "                transformed = ndimage.affine_transform(\n",
    "                    source_data[band_idx],\n",
    "                    matrix=matrix_2x2.T,  # Transpose for (row, col) convention\n",
    "                    offset=offset[::-1],  # Reverse for (row, col): [f, c]\n",
    "                    output_shape=(target_height, target_width),\n",
    "                    order=1,  # Bilinear interpolation\n",
    "                    mode='constant',\n",
    "                    cval=0\n",
    "                )\n",
    "                registered_data[band_idx] = transformed\n",
    "        \n",
    "        \n",
    "        # Save registered orthomosaic\n",
    "        with rasterio.open(\n",
    "            output_path,\n",
    "            'w',\n",
    "            driver='GTiff',\n",
    "            height=target_height,\n",
    "            width=target_width,\n",
    "            count=source_count,\n",
    "            dtype=registered_data.dtype,\n",
    "            crs=target_crs,\n",
    "            transform=target_transform,\n",
    "            compress='lzw',\n",
    "            BIGTIFF='YES',\n",
    "            tiled=True\n",
    "        ) as dst:\n",
    "            dst.write(registered_data)\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "# Register orthos\n",
    "registered_paths = {}\n",
    "\n",
    "for ortho_name, transformation in transformations.items():\n",
    "\n",
    "    # Check if registered file already exists\n",
    "        with rasterio.open(\n",
    "            output_path,\n",
    "            'w',\n",
    "            driver='GTiff',\n",
    "            height=target_height,\n",
    "            width=target_width,\n",
    "            count=source_count,\n",
    "            dtype=registered_data.dtype,\n",
    "            crs=target_crs,\n",
    "            transform=target_transform,\n",
    "            compress='lzw',\n",
    "            BIGTIFF='YES',\n",
    "            tiled=True\n",
    "        ) as dst:\n",
    "            dst.write(registered_data)\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "# Register orthos\n",
    "registered_paths = {}\n",
    "\n",
    "for ortho_name, transformation in transformations.items():\n",
    "\n",
    "    # Check if registered file already exists\n",
    "    registered_path = registered_dir / f\"{ortho_name}_registered.tif\"\n",
    "    if registered_path.exists():\n",
    "        print(f\"  \u2713 Registered ortho already exists: {registered_path}\")\n",
    "        print(f\"    Skipping registration for {ortho_name}...\")\n",
    "        registered_paths[ortho_name] = registered_path\n",
    "        continue\n",
    "\n",
    "    if 'error' in transformation:\n",
    "        print(f\"\u26a0\ufe0f  Skipping {ortho_name}: {transformation['error']}\")\n",
    "        continue\n",
    "    \n",
    "\n",
    "    # Check if registered file already exists\n",
    "    registered_path = registered_dir / f\"{ortho_name}_registered.tif\"\n",
    "    if registered_path.exists():\n",
    "        print(f\"  \u2713 Registered ortho already exists: {registered_path}\")\n",
    "        print(f\"    Skipping registration for {ortho_name}...\")\n",
    "        registered_paths[ortho_name] = registered_path\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nRegistering {ortho_name}...\")\n",
    "    \n",
    "    registered_path = apply_transformation(\n",
    "        reprojected_paths[ortho_name],\n",
    "        transformation,\n",
    "        registered_dir / f\"{ortho_name}_registered.tif\",\n",
    "        basemap_path\n",
    "    )\n",
    "    \n",
    "    registered_paths[ortho_name] = registered_path\n",
    "    print(f\"  \u2713 Saved: {registered_path}\")\n",
    "\n",
    "print(f\"\\n\u2713 Registration complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Evaluate Accuracy Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare registered orthos to basemap\n",
    "\n",
    "# Import required modules\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import rasterio\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_accuracy(ortho_path: Path, basemap_path: Path, gcps: List[Dict]) -> Dict:\n",
    "    \"\"\"\n",
    "    Evaluate accuracy by comparing pixel values at GCP locations.\n",
    "    \"\"\"\n",
    "    with rasterio.open(basemap_path) as basemap_src:\n",
    "        basemap_data = basemap_src.read()\n",
    "    \n",
    "    with rasterio.open(ortho_path) as ortho_src:\n",
    "        ortho_data = ortho_src.read()\n",
    "    \n",
    "    errors = []\n",
    "    \n",
    "    for gcp in gcps:\n",
    "        pixel_coords = gcp_to_pixel_coords_from_utm(gcp['x_utm'], gcp['y_utm'], basemap_path)\n",
    "        if not pixel_coords:\n",
    "            continue\n",
    "        \n",
    "        col, row = pixel_coords\n",
    "        \n",
    "        if 0 <= row < basemap_data.shape[1] and 0 <= col < basemap_data.shape[2]:\n",
    "            basemap_pixel = basemap_data[:, row, col]\n",
    "            \n",
    "            if 0 <= row < ortho_data.shape[1] and 0 <= col < ortho_data.shape[2]:\n",
    "                ortho_pixel = ortho_data[:, row, col]\n",
    "                \n",
    "                # Compute error (Euclidean distance in pixel space)\n",
    "                error = np.sqrt(np.sum((basemap_pixel.astype(float) - ortho_pixel.astype(float))**2))\n",
    "                errors.append(error)\n",
    "    \n",
    "    if errors:\n",
    "        return {\n",
    "            'mean_error': float(np.mean(errors)),\n",
    "            'rmse': float(np.sqrt(np.mean(np.array(errors)**2))),\n",
    "            'max_error': float(np.max(errors)),\n",
    "            'min_error': float(np.min(errors)),\n",
    "            'num_points': len(errors)\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            'mean_error': 0.0,\n",
    "            'rmse': 0.0,\n",
    "            'max_error': 0.0,\n",
    "            'min_error': 0.0,\n",
    "            'num_points': 0\n",
    "        }\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}